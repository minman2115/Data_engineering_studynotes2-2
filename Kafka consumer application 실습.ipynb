{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "Data_Engineering_TIL(20200826)\n",
    "\n",
    "학습한 프로그램 : T아카데미 Apache Kafka 입문과 활용\n",
    "\n",
    "URL : https://tacademy.skplanet.com/live/player/onlineLectureDetail.action?seq=183\n",
    "\n",
    "이전내용 참고자료 : https://minman2115.github.io/DE_TIL116\n",
    "\n",
    "\n",
    "#### # consumer 란\n",
    "\n",
    "- 데이터를 가져가는(polling) 주체\n",
    "\n",
    "\n",
    "브로커가 보내는게 아니라 컨슈머가 달라고 할때만 그때 polling해서 가져간다.\n",
    "\n",
    "\n",
    "따라서 카프카 컨슈머가 데이터 처리하는 속도가 느리다면 느리게 폴링할 것이고, 빠르다면 빠르게 폴링해서 데이터를 가져갈 것이다.\n",
    "\n",
    "\n",
    "\n",
    "- commit을 통해 읽은 consumer offset을 카프카에 기록\n",
    "\n",
    "\n",
    "카프카 컨슈머 그룹이 내가 어디까지 읽었는지 consumer offset을 카프카에 기록한다는 것이다.\n",
    "\n",
    "\n",
    "- Java Kafka-client 제공\n",
    "\n",
    "그 외 3rd party language의 경우 아래 링크 참고\n",
    "\n",
    "https://cwiki.apache.org/confluence/display/KAFKA/Clients\n",
    "\n",
    "- 어디에 데이터를 저장하나요?\n",
    "\n",
    "\n",
    "FileSystem(.csv .log .tsv)\n",
    "\n",
    "\n",
    "Object Storage(S3, Minio)\n",
    "\n",
    "\n",
    "Hadoop(Hdfs, Hive)\n",
    "\n",
    "\n",
    "RDBMS(Oracle, Mysql)\n",
    "\n",
    "\n",
    "NoSql(MongoDB, CouchDB)\n",
    "\n",
    "\n",
    "기타 다양한 저장소들(Elasticsearch, influxDB)\n",
    "\n",
    "\n",
    "#### # 주의사항\n",
    "\n",
    "컨슈머 코드에도 클라이언트가 들어가기 때문에 버전 호환성을 반드시 체크해줘야 한다.\n",
    "\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/41605276/91256804-42863a80-e7a3-11ea-975b-ab836ee6436a.png)\n",
    "\n",
    "[실습내용]\n",
    "\n",
    "#### 실습 1. 기본적인 consumer application 실습\n",
    "\n",
    "\n",
    "- client ec2에 접속해서 아래와 같이 명령어들을 실행해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저 Client ec2에서 아래와 같이 console producer를 띄우고 데이터를 넣어준다.\n",
    "# ./kafka-console-producer.sh --bootstrap-server {broker ec2 public ip}:9092 --topic test\n",
    "[ec2-user@ip-10-1-10-115 bin]$ ./kafka-console-producer.sh --bootstrap-server 13.209.84.144:9092 --topic test\n",
    ">aaa\n",
    ">bbb\n",
    ">ccc\n",
    ">ddd\n",
    ">eee\n",
    ">fff\n",
    ">\n",
    "\n",
    "# 그 다음에 다른 클라이언트 ec2에서 터미널을 하나 더 열고 거기에서 아래와 같이 머캔드를 실행해준다.\n",
    "[ec2-user@ip-10-1-10-115 tacademy-kafka]$ ls\n",
    "image                        kafka-producer-exact-partition          simple-kafka-producer\n",
    "kafka-consumer-auto-commit   kafka-producer-key-value                telegraf.conf\n",
    "kafka-consumer-multi-thread  아파치 카프카 입문과 활용 강의자료.pdf  실습 커맨드 리스트.txt\n",
    "kafka-consumer-save-metric   README.md\n",
    "kafka-consumer-sync-commit   simple-kafka-consumer\n",
    "\n",
    "[ec2-user@ip-10-1-10-115 tacademy-kafka]$ cd simple-kafka-consumer\n",
    "\n",
    "[ec2-user@ip-10-1-10-115 simple-kafka-consumer]$ ls\n",
    "build.gradle  gradle  gradlew  gradlew.bat  settings.gradle  src\n",
    "\n",
    "# 아래와 같이 소스를 열어서 broker ec2 public ip 부분을 브로커 퍼블릭 아이피로 치환해준다.\n",
    "[ec2-user@ip-10-1-10-115 simple-kafka-consumer]$ sudo vim /home/ec2-user/tacademy-kafka/simple-kafka-consumer/src/main/java/com/tacademy/SimpleConsumer.java\n",
    "package com.tacademy;\n",
    "\n",
    "import org.apache.kafka.clients.consumer.ConsumerConfig;\n",
    "import org.apache.kafka.clients.consumer.ConsumerRecord;\n",
    "import org.apache.kafka.clients.consumer.ConsumerRecords;\n",
    "import org.apache.kafka.clients.consumer.KafkaConsumer;\n",
    "import org.apache.kafka.common.serialization.StringDeserializer;\n",
    "\n",
    "import java.time.Duration;\n",
    "import java.util.Arrays;\n",
    "import java.util.Properties;\n",
    "\n",
    "public class SimpleConsumer {\n",
    "    private static String TOPIC_NAME = \"test\";\n",
    "    private static String GROUP_ID = \"testgroup\";\n",
    "    private static String BOOTSTRAP_SERVERS = \"{broker ec2 public ip}:9092\";\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        # 아래와 같이 properties를 설정한다.\n",
    "        Properties configs = new Properties();\n",
    "        # 부트스트랩, 그룹 아이디, key 디시리얼라이저, value 디시리얼라이저가 들어가줘야 한다.\n",
    "        # producer로 직렬화 한것을 역직렬화 해줘야 하기 때문이다.\n",
    "        # 콘솔 프로듀서도 기본적으로 직렬화해서 데이터가 들어간다.\n",
    "        configs.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);\n",
    "        configs.put(ConsumerConfig.GROUP_ID_CONFIG, GROUP_ID);\n",
    "        configs.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n",
    "        configs.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n",
    "\n",
    "        # 카프카 컨슈머 인스턴스를 생성\n",
    "        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);\n",
    "'\n",
    "        # 특정 토픽을 구독하겠다고 선언\n",
    "        consumer.subscribe(Arrays.asList(TOPIC_NAME));\n",
    "\n",
    "        while (true) {\n",
    "            # consumer.poll 메서드를 통해서 1초동안 기다리면서 데이터를 가져오게 된다.\n",
    "            # 데이터를 배치형태로 가져오기 때문에 데이터를 여러개를 가져온다. \n",
    "            # 그리고 for 문을 통해서 가져오는 데이터를 출력해준다.\n",
    "            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n",
    "            for (ConsumerRecord<String, String> record : records) {\n",
    "                System.out.println(record.value());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# sudo vim을 이용하여 build.gradle을 아래와 같이 수정해준다.\n",
    "[ec2-user@ip-10-1-10-115 simple-kafka-consumer]$ sudo vim build.gradle\n",
    "apply plugin: 'application'\n",
    "\n",
    "mainClassName = 'com.tacademy.SimpleConsumer'\n",
    "\n",
    "group 'com.tacademy'\n",
    "version '1.0'\n",
    "\n",
    "repositories {\n",
    "    mavenCentral()\n",
    "}\n",
    "\n",
    "dependencies {\n",
    "    testCompile group: 'junit', name: 'junit', version: '4.12'\n",
    "    compile group: 'org.apache.kafka', name: 'kafka-clients', version: '2.5.0'\n",
    "}\n",
    "\n",
    "[ec2-user@ip-10-1-10-115 simple-kafka-consumer]$ gradle wrapper\n",
    "\n",
    "BUILD SUCCESSFUL in 0s\n",
    "1 actionable task: 1 executed\n",
    "    \n",
    "[ec2-user@ip-10-1-10-115 simple-kafka-consumer]$ ./gradlew build\n",
    "\n",
    "BUILD SUCCESSFUL in 1s\n",
    "5 actionable tasks: 5 executed\n",
    "\n",
    "# 빌드하고 run을 하면 아까 프로듀서로 넣었던 데이터를 정상적으로 가져오는 것을 확인할 수 있다.\n",
    "[ec2-user@ip-10-1-10-115 simple-kafka-consumer]$ ./gradlew run\n",
    "\n",
    "> Task :run\n",
    "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
    "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
    "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
    "aaa\n",
    "bbb\n",
    "eee\n",
    "fff\n",
    "ccc\n",
    "ddd\n",
    "<=========----> 75% EXECUTING [16s]\n",
    "> :run\n",
    "    \n",
    "# 계속 컨슈머 어플리케이션을 켠 상태로 다시 콘솔 프로듀서를 띄운 터미널로 넘어가서 데이터를 넣으면\n",
    "# 넣는 순간 컨슈머 어플리케이션에서 캐치해가는 것을 확인할 수 있을 것이다.\n",
    "\n",
    "\n",
    "# 그리고 컨트롤+c로 컨슈머 어플리케이션을 종료해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실습 2. consumer commit 동작원리 이해를 위한 어플리케이션 실습\n",
    "\n",
    "kafka-consumer-auto-commit 라는 어플리케이션을 통해 commit의 동작원리를 이해하고 데이터가 중복처리 되는 케이스를 경험해본다.\n",
    "\n",
    "- 마찬가지로 client ec2에 접속해서 아래와 같이 명령어들을 실행해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ec2-user@ip-10-1-10-115 tacademy-kafka]$ ls\n",
    "image                        kafka-consumer-sync-commit              README.md              실습 커맨드 리스트.txt\n",
    "kafka-consumer-auto-commit   kafka-producer-exact-partition          simple-kafka-consumer\n",
    "kafka-consumer-multi-thread  kafka-producer-key-value                simple-kafka-producer\n",
    "kafka-consumer-save-metric   아파치 카프카 입문과 활용 강의자료.pdf  telegraf.conf\n",
    "\n",
    "[ec2-user@ip-10-1-10-115 tacademy-kafka]$ cd kafka-consumer-auto-commit/\n",
    "\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-auto-commit]$ ls\n",
    "build.gradle  gradle  gradlew  gradlew.bat  settings.gradle  src\n",
    "\n",
    "# 마찬가지로 아래 브로커 ec2 아이피에 브로커 아이피를 넣어준다.\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-auto-commit]$ sudo vim /home/ec2-user/tacademy-kafka/kafka-consumer-auto-commit/src/main/java/com/tacademy/ConsumerWithAutoCommit.java\n",
    "package com.tacademy;\n",
    "\n",
    "import org.apache.kafka.clients.consumer.ConsumerConfig;\n",
    "import org.apache.kafka.clients.consumer.ConsumerRecord;\n",
    "import org.apache.kafka.clients.consumer.ConsumerRecords;\n",
    "import org.apache.kafka.clients.consumer.KafkaConsumer;\n",
    "import org.apache.kafka.common.serialization.StringDeserializer;\n",
    "\n",
    "import java.time.Duration;\n",
    "import java.util.Arrays;\n",
    "import java.util.Properties;\n",
    "\n",
    "public class ConsumerWithAutoCommit {\n",
    "    private static String TOPIC_NAME = \"test\";\n",
    "    private static String GROUP_ID = \"testgroup\";\n",
    "    private static String BOOTSTRAP_SERVERS = \"{broker ec2 public ip}:9092\";\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        Properties configs = new Properties();\n",
    "        configs.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);\n",
    "        configs.put(ConsumerConfig.GROUP_ID_CONFIG, GROUP_ID);\n",
    "        configs.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n",
    "        configs.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n",
    "        \n",
    "        # 위의 config들은 아까 했던 simple kafka consumer 어플리케이션과 동일하지만\n",
    "        # 아래에 보면 commit을 오토로 할것인가에 대해 true,false로 지정해줄 수 있다.\n",
    "        # 즉 commit이 자동으로 된다는 것이다. 아까는 명시적으로 커밋해주는 부분이 없었는데 이 말은 polling할때\n",
    "        # 내부적으로 commit을 한다는 것이다. 60초 간격으로 컨슈머가 어디까지 읽었는지 브로커에게 알려준다는 것이다.\n",
    "        # 또한 auto commit interval을 몇초 간격으로 할것인가에 대한 옵션도 지정해준다.\n",
    "        configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);\n",
    "        configs.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 60000);\n",
    "\n",
    "        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);\n",
    "        consumer.subscribe(Arrays.asList(TOPIC_NAME));\n",
    "\n",
    "        while (true) {\n",
    "            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n",
    "            for (ConsumerRecord<String, String> record : records) {\n",
    "                System.out.println(record.value());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# 마찬가지로 아래와 같이 build.gradle을 수정해준다.\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-auto-commit]$ sudo vim build.gradle\n",
    "apply plugin: 'application'\n",
    "mainClassName = 'com.tacademy.ConsumerWithAutoCommit'\n",
    "\n",
    "group 'com.tacademy'\n",
    "version '1.0'\n",
    "\n",
    "repositories {\n",
    "    mavenCentral()\n",
    "}\n",
    "\n",
    "dependencies {\n",
    "    testCompile group: 'junit', name: 'junit', version: '4.12'\n",
    "    compile group: 'org.apache.kafka', name: 'kafka-clients', version: '2.5.0'\n",
    "}\n",
    "\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-auto-commit]$ gradle wrapper\n",
    "\n",
    "BUILD SUCCESSFUL in 0s\n",
    "1 actionable task: 1 executed\n",
    "    \n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-auto-commit]$ ./gradlew build\n",
    "\n",
    "BUILD SUCCESSFUL in 1s\n",
    "5 actionable tasks: 5 executed\n",
    "    \n",
    "# 마찬가지로 어플리케이션을 run하고 콘솔 프로듀서에서 123 456 등 데이터를 넣으면 아래와 같이 전시될 것이다.\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-auto-commit]$ ./gradlew run\n",
    "\n",
    "> Task :run\n",
    "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
    "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
    "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
    "123\n",
    "456\n",
    "789\n",
    "10101010\n",
    "11111111\n",
    "<=========----> 75% EXECUTING [29s]\n",
    "> :run\n",
    "\n",
    "\n",
    "# 소스에서 testgroup이라는 그룹아이디를 갖은게 현재 입력한 123 456 등 데이터만 전시하고 이전 데이터에 대해서는 전시를 하지 않는다.\n",
    "\n",
    "# 그리고 컨트롤+c로 컨슈머 어플리케이션을 종료해준다.\n",
    "\n",
    "# 그리고 다시 run을 하면 입력했던\n",
    "123\n",
    "456\n",
    "789\n",
    "10101010\n",
    "11111111\n",
    "# 가 다시 전시가 된다. \n",
    "\n",
    "# 이게 무슨말이냐면 데이터가 중복처리 되었다는 것이다. 어플리케이션을 실행하고 60초 전에 kill 시켰기 때문에 인터벌 60초 전에 꺼진것이고\n",
    "# 따라서 commit이 안되었기 때문이다. 데이터가 중복처리되면 이슈가 발생할 수 있다.\n",
    "# 그래서 autocommit은 인터벌 간격에 따라 데이터가 유실되거나 중복처리될 수도 있다.\n",
    "\n",
    "\n",
    "# 그리고 컨트롤+c로 컨슈머 어플리케이션을 종료해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # consumer commit\n",
    "\n",
    "- enable.auto.commit=true\n",
    "\n",
    "일정 간격(auto.commit.interval.ms), poll() 메서드 호출시 자동 commit\n",
    "\n",
    "\n",
    "commit 관련 코드를 작성할 필요없음. 편리함.\n",
    "\n",
    "\n",
    "명시적으로 commit 하는거 대비해서 속도가 매우 빠름\n",
    "\n",
    "\n",
    "중복 또는 유실이 발생할 수 있음\n",
    "\n",
    "\n",
    "--> 중복/유실을 허용하지 않는 곳(은행, 카드 등)에서는 사용하면 안됨!!\n",
    "\n",
    "\n",
    "--> 일부 데이터가 중복/유실되도 상관 없는 곳(센서, GPS 등)에서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);\n",
    "configs.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 60000);\n",
    "\n",
    "KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);\n",
    "consumer.subscribe(Arrays.asList(TOPIC_NAME));\n",
    "\n",
    "while (true) {\n",
    "    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n",
    "    for (ConsumerRecord<String, String> record : records) {\n",
    "        System.out.println(record.value());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/41605276/91267351-2936bb80-e7ae-11ea-9789-81d0bf5bf98a.png)\n",
    "\n",
    "#### # 데이터 중복처리? 무슨 문제지?\n",
    "\n",
    "- 커머스의 장바구니 시스템에서 중복 이슈 발생\n",
    "\n",
    "나는 장바구니에 1개 상품을 담았는데 2개 상품이 담김\n",
    "\n",
    "- 카드사의 결제 시스템에서 중복 이슈 발생\n",
    "\n",
    "편의점에서 아이스크림 결제를 했는데 2번 결재됨\n",
    "\n",
    "\n",
    "- 택배사 SMS 발송 시스템에서 중복 이슈 발생\n",
    "\n",
    "집에 도착 했다는 SMS가 2번 발송\n",
    "\n",
    "\n",
    "#### # 데이터 중복을 막을 수 있는 방법\n",
    "\n",
    "1) 오토 커밋을 사용하되, 컨슈머가 죽지 않도록 잘 돌봐준다\n",
    "\n",
    "불가능. 서버/애플리케이션은 언젠가 죽을 수 있다. ex. 배포\n",
    "\n",
    "2) 오토 커밋을 사용하지 않는다\n",
    "\n",
    "\n",
    "Kafka consumer의 commitSync(), commitAsync() 사용\n",
    "\n",
    "\n",
    "#### # enable.auto.commit=false\n",
    "\n",
    "1) commitSync() : 동기 커밋\n",
    "\n",
    "\n",
    "- ConsumerRecord 처리 순서를 보장함\n",
    "\n",
    "\n",
    "- 가장 느림(커밋이 완료될 때 까지 block하기 때문임)\n",
    "\n",
    "\n",
    "- poll() 메서드로 반환된 ConsumerRecord의 마지막 offset을 커밋\n",
    "\n",
    "\n",
    "그런데 만약에 컨슈머 레코드를 예를들어 50개를 받게 되면 중간중간마다 계속 커밋을 할 수 있는데 이때 Map 자료구조를 사용해서 토픽파티션과 offsetandmetadata를 이용해서 한개가 처리될때마다 한번씩 offset을 커밋할 수 있다. \n",
    "\n",
    "\n",
    "즉 50개 데이터가 들어왔을때 polling 처리가 완료된 이후에 commit sync를 명시적으로 적어서 50개마다 50개가 데이터가 잘 처리되었다고 구현할 수도 있고, 혹은 offset 1개 처리될때마다 커밋 한번을 처리할 수도 있다. \n",
    "\n",
    "\n",
    "- Map<TopicPartition, OffsetAndMetadata> 을 통해 오프셋 지정 커밋 가능\n",
    "\n",
    "\n",
    "실제 사용 예시\n",
    "\n",
    "- commitSync() : 동기 커밋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (true) {\n",
    "    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n",
    "    for (ConsumerRecord<String, String> record : records) {\n",
    "        System.out.println(record.value());\n",
    "    }\n",
    "    try {\n",
    "        consumer.commitSync();\n",
    "    } catch (CommitFailedException e) {\n",
    "        System.err.println(\"commit failed\");\n",
    "    }\n",
    "}\n",
    "\n",
    "# consumer.commitSync()할때 CommitFailedException는 반드시 받아줘야 한다. 왜냐하면 네트워크 장애 등 상황에서 대처를 할수 있기 때문이다.\n",
    "# 커밋을 재시도를 하던지 멈추던지 대처를 해줄때 꼭 필요하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- commitSync(Map<TopicPartition, OffsetAndMetadata>) : offset 지정 커밋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map<TopicPartition, OffsetAndMetadata> offset = new HashMap<>();\n",
    "# record.topic() 은 내 토픽, record.partition()은 파티션을 몇번했는지 말하는 것이다.\n",
    "offset.put(new TopicPartition(record.topic(), record.partition()), null);\n",
    "\n",
    "# 그다음에 아래와 같이 오프셋 번호를 지정하면 몇번 오프셋까지 처리를 했는지 commit을 할 수 있다.\n",
    "try {\n",
    "    consumer.commitSync(offset);\n",
    "} catch (CommitFailedException e) {\n",
    "    System.err.println(\"commit failed\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) commitAsync() : 비동기 커밋\n",
    "\n",
    "커밋이 될때까지 기다리는 메서드는 아님\n",
    "\n",
    "커밋을 요청하는 시간동안 폴링을 기다리지 않고 바로 진행해버림\n",
    "\n",
    "그래서 일시적인 통신문제로 비동기 커밋이 커밋이 안되었을때 당연히 카프카 브로커는 처리가 안된것으로 인지하여 데이터를 다시 보낼수도 있다. 그래서 중복처리에 대한 여지가 있는 메서드다.\n",
    "\n",
    "- 동기 커밋보다 빠름\n",
    "\n",
    "\n",
    "- 중복이 발생할 수 있음\n",
    "\n",
    "\n",
    "일시적인 통신 문제로 이전 offset보다 이후 offset이 먼저 커밋 될 때\n",
    "\n",
    "\n",
    "- ConsumerRecord 처리 순서를 보장하지 못함\n",
    "\n",
    "\n",
    "처리 순서가 중요한 서비스(주문, 재고관리 등)에서는 사용 제한\n",
    "\n",
    "\n",
    "#### 결론적으로는 commitSync()가 가장 안전하다.\n",
    "\n",
    "실제 사용 예시\n",
    "\n",
    "- commitAsync() : 비동기 커밋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (true) {\n",
    "    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n",
    "    for (ConsumerRecord<String, String> record : records) {\n",
    "        System.out.println(record.value());\n",
    "    }\n",
    "    consumer.commitASync();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- commitAsync() + commitSync() : 비동기, 동기 커밋 같이 쓰는 경우도 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try {\n",
    "    while (true) {\n",
    "        ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n",
    "        for (ConsumerRecord<String, String> record : records) {\n",
    "            System.out.println(record.value());\n",
    "        }\n",
    "        consumer.commitAsync();\n",
    "    }\n",
    "} catch (CommitFailedException e) {\n",
    "    System.err.println(\"commit failed\");\n",
    "}finally {\n",
    "    consumer.commitSync();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실습 3. kafka-consumer-sync-commit\n",
    "\n",
    "- 마찬가지로 client ec2에 접속해서 아래와 같이 명령어들을 실행해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ec2-user@ip-10-1-10-115 tacademy-kafka]$ ls\n",
    "image                        kafka-consumer-sync-commit              README.md              실습 커맨드 리스트.txt\n",
    "kafka-consumer-auto-commit   kafka-producer-exact-partition          simple-kafka-consumer\n",
    "kafka-consumer-multi-thread  kafka-producer-key-value                simple-kafka-producer\n",
    "kafka-consumer-save-metric   아파치 카프카 입문과 활용 강의자료.pdf  telegraf.conf\n",
    "\n",
    "[ec2-user@ip-10-1-10-115 tacademy-kafka]$ cd kafka-consumer-sync-commit/\n",
    "\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-sync-commit]$ ls\n",
    "build.gradle  gradle  gradlew  gradlew.bat  settings.gradle  src\n",
    "\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-sync-commit]$ sudo vim /home/ec2-user/tacademy-kafka/kafka-consumer-sync-commit/src/main/java/com/tacademy/ConsumerWithSyncCommit.java\n",
    "package com.tacademy;\n",
    "\n",
    "import org.apache.kafka.clients.consumer.ConsumerConfig;\n",
    "import org.apache.kafka.clients.consumer.ConsumerRecord;\n",
    "import org.apache.kafka.clients.consumer.ConsumerRecords;\n",
    "import org.apache.kafka.clients.consumer.KafkaConsumer;\n",
    "import org.apache.kafka.common.serialization.StringDeserializer;\n",
    "\n",
    "import java.time.Duration;\n",
    "import java.util.Arrays;\n",
    "import java.util.Properties;\n",
    "\n",
    "public class ConsumerWithSyncCommit {\n",
    "    private static String TOPIC_NAME = \"test\";\n",
    "    private static String GROUP_ID = \"testgroup\";\n",
    "    private static String BOOTSTRAP_SERVERS = \"{broker ec2 public ip}:9092\";\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        Properties configs = new Properties();\n",
    "        configs.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);\n",
    "        configs.put(ConsumerConfig.GROUP_ID_CONFIG, GROUP_ID);\n",
    "        configs.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n",
    "        configs.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n",
    "        \n",
    "        # 아래와 같이 auto commit 이 false로 설정이 되어있다.\n",
    "        # 즉 오토커밋을 하지 않겠다. sync 커밋이나 async 커밋으로 하겠다는 것이다.\n",
    "        configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);\n",
    "\n",
    "        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(configs);\n",
    "        consumer.subscribe(Arrays.asList(TOPIC_NAME));\n",
    "\n",
    "        while (true) {\n",
    "            ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n",
    "            for (ConsumerRecord<String, String> record : records) {\n",
    "                System.out.println(record.value());\n",
    "                # 아래와 같이 consumer.commitSync(); 라고 명시적으로 sync 커밋을 쓰겠다는 것이다.\n",
    "                consumer.commitSync();\n",
    "                record.offset();\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# 마찬가지로 build.gradle을 아래와 같이 수정\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-sync-commit]$ sudo vim build.gradle\n",
    "apply plugin: 'application'\n",
    "mainClassName = 'com.tacademy.ConsumerWithSyncCommit'\n",
    "\n",
    "group 'com.tacademy'\n",
    "version '1.0'\n",
    "\n",
    "repositories {\n",
    "    mavenCentral()\n",
    "}\n",
    "\n",
    "dependencies {\n",
    "    testCompile group: 'junit', name: 'junit', version: '4.12'\n",
    "    compile group: 'org.apache.kafka', name: 'kafka-clients', version: '2.5.0'\n",
    "}\n",
    "\n",
    "# 아래 명령어과 같이 어플리케이션 빌드 및 실행\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-sync-commit]$ gradle wrapper\n",
    "Starting a Gradle Daemon (subsequent builds will be faster)\n",
    "\n",
    "BUILD SUCCESSFUL in 5s\n",
    "1 actionable task: 1 executed\n",
    "\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-sync-commit]$ ./gradlew build\n",
    "\n",
    "BUILD SUCCESSFUL in 2s\n",
    "5 actionable tasks: 5 executed\n",
    "\n",
    "# 컨슈머 어플리케이션 실행하기 전에 콘솔 프로듀서로 kkk aaa bbb 를 넣어준다.\n",
    "# 그리고 실행하면 아래와 같이 전시가 될 것이다.\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-sync-commit]$ ./gradlew run\n",
    "\n",
    "> Task :run\n",
    "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
    "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
    "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
    "kkk\n",
    "aaa\n",
    "bbb\n",
    "<=========----> 75% EXECUTING [47s]\n",
    "> :run\n",
    "    \n",
    "# 다시 콘솔 프로듀서가 띄워진 터미널로 넘어가서 1 2 3 4 5 6 을 추가적으로 넣어준다\n",
    "# 그런다음에 다시 컨슈머 어플리케이션이 띄워진 터미널로 넘어가면 아래와 같이 전시가 될 것이다.\n",
    "# 1부터 6까지 폴링해서 가져간 것을 알 수 있다. 그러면서 데이터 하나씩 처리할때마다 commit을 했다.\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-sync-commit]$ ./gradlew run\n",
    "\n",
    "> Task :run\n",
    "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
    "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
    "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
    "kkk\n",
    "aaa\n",
    "bbb\n",
    "1\n",
    "2\n",
    "3\n",
    "4\n",
    "5\n",
    "6\n",
    "<=========----> 75% EXECUTING [4m 58s]\n",
    "> :run\n",
    "    \n",
    "# 그러면 여기서 컨슈머 어플리케이션을 kill 시킨 다음에 콘솔 프로듀서로 korea japan china usa 데이터를 넣어본다.\n",
    "# 이전까지의 데이터를 폴링하고 commit을 했기때문에 이제는 다시 컨슈머 어플리케이션을 실행한다면 korea 부터 데이터를 받아와야 할 것이다.\n",
    "# 그러면 다시 컨슈머 어플리케이션을 아래와 같이 run 하면 6 데이터 이후부터 잘 받아온것을 확인할 수 있다.\n",
    "# 아까처럼 중복처리 되지않고 정상적으로 후속데이터를 처리한 것을 알 수 있다.\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-sync-commit]$ ./gradlew run\n",
    "\n",
    "> Task :run\n",
    "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
    "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
    "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
    "japan\n",
    "usa\n",
    "china\n",
    "korea\n",
    "<=========----> 75% EXECUTING [21s]\n",
    "> :run\n",
    "    \n",
    "# 그리고 컨트롤+c로 컨슈머 어플리케이션을 종료해준다.\n",
    "# 컨슈머는 데이터를 폴링해서 가져가기 때문에 사용하지 않으면 반드시 잘 꺼줘야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # Consumer rebalance\n",
    "\n",
    "리밸런스 - 컨슈머 그룹의 파티션 소유권이 변경될 때 일어나는 현상\n",
    "\n",
    "컨슈머가 장애가 나면 리밸런스라는게 발생할 수도 있다.\n",
    "\n",
    "컨슈머 그룹의 파티션 소유권 즉, 컨슈머와 파티션 할당이 변경될때 일어나는 현상\n",
    "\n",
    "- 리밸런스를 하는 동안 일시적으로 메시지를 가져올 수 없음\n",
    "\n",
    "\n",
    "- 리밸런스 발생시 데이터 유실/중복 발생 가능성 있음\n",
    "\n",
    "왜냐면 데이터를 처리할때 synccommit을 하지 않았는데 다른걸로 할당해버리면 어디까지 commit했는지 명시적으로 확인할 수 없다. 그래서 commitsync를 꼭 리밸런스 리스터를 통해서 선언해서 사용하면 좋다.\n",
    "\n",
    "\n",
    "또는 추가적인 방법(unique key)으로 데이터 유실/중복 방지 할 수 있다.\n",
    "\n",
    "\n",
    "- 언제 리밸런스 발생?\n",
    "\n",
    "\n",
    "consumer.close() 호출시 또는 consumer의 세션이 끊어졌을 때, 장애가 발생했을때\n",
    "\n",
    "예를 들어서 컨슈머 세션이 끊겼을때의 상황을 가정해보자.\n",
    "\n",
    "컨슈머 세션이 끊기면 카프카 클라이언스 --> 카프카 브로커로 아래와 같이 동작할 것이다.\n",
    "\n",
    "1) (디폴트 옵션으로) 3초마다 크룹 코디네이터(브로커 중 1대)에게 하트비트 전송\n",
    "\n",
    "2) 10초의 세션 타임아웃 시간안에 하트비트가 왔는지 확인\n",
    "\n",
    "3) 만약 하트비트가 없으면 코디네이터가 해당 컨슈머는 죽은것으로 마킹해버림\n",
    "\n",
    "4) 세션이 끊어졌다고 판단했으니 리밸런스가 시작됨\n",
    "\n",
    "아래와 같이 세션시간에 대해서 하트비트 시간 x 3을 보통 하나의 세션시간으로 설정하는 편이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 3000);\n",
    "configs.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # Consumer rebalance listener\n",
    "\n",
    "- 코드 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "# 토픽에 뉴리밸런스리스너 메소드를 넣어서 정의가 가능하다.\n",
    "consumer.subscribe(Arrays.asList(\"test\"), new RebalanceListener());\n",
    "while (true) {\n",
    "    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n",
    "    for (ConsumerRecord<String, String> record : records) {\n",
    "        System.out.println(record.value());\n",
    "    }\n",
    "}\n",
    "}\n",
    "# 위에서 정의한 뉴리밸런스 리스너를 implement해서 \n",
    "# 리보크 혹은 어싸인 할 수 있다. 그래서 파티션이 끊어졌거나 새로 할당되었을때\n",
    "# 각각의 경우에 대해 처리를 할 수 있다.\n",
    "static class RebalanceListener implements ConsumerRebalanceListener {\n",
    "    @Override\n",
    "    public void onPartitionsRevoked(Collection<TopicPartition> partitions) {\n",
    "        System.out.println(\"Lost partitions.\");\n",
    "    }\n",
    "    @Override\n",
    "    public void onPartitionsAssigned(Collection<TopicPartition> partitions) {\n",
    "        System.out.println(\"Assigned partitions.\");\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 리벨런스 리스너는 언제 사용할까?\n",
    "\n",
    "리밸런스 발생에 따른 offset commit을 하거나 \n",
    "\n",
    "또는 컨슈머가 많을때 할당되는 시간이 오래걸릴 수 있기 때문에 운영상 참고를 위해 리밸런스 시간 측정을 통한 컨슈머 모니터링을 하기도 한다.\n",
    "\n",
    "시간측정을 위해 로그를 남겨주거나 할 수 있다.\n",
    "\n",
    "#### # Consumer wakeup\n",
    "\n",
    "컨슈머를 정상적으로 종료를 해야하는데 그럴때는 wakeup이라는 메서드를 사용한다. \n",
    "\n",
    "이걸 사용하면 wakeup session이 발생한다. \n",
    "\n",
    "이 세션을 통해 안전하게 빠져나올 수 있다.\n",
    "\n",
    "- 정상동작 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while (true) {\n",
    "    # poll() 호출하고, records 100개 반환 : offset 101번 ~ 200번\n",
    "    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n",
    "    # for 구문으로 100개의 records loop 구문 수행\n",
    "    for (ConsumerRecord<String, String> record : records) {\n",
    "        # record.value() system print\n",
    "        System.out.println(record.value());\n",
    "    }\n",
    "    # offset 200 커밋\n",
    "    consumer.commitSync();\n",
    "}\n",
    "# while문이므로 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SIGKILL로 인한 중복처리 발생 예시\n",
    "\n",
    "SIGKILL : 강제로 어플리케이션을 죽인것\n",
    "\n",
    "1) poll() 호출\n",
    "\n",
    "\n",
    "마지막 커밋된 오프셋이 100\n",
    "\n",
    "\n",
    "records 100개 반환 : 오프셋 101 ~ 200\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/41605276/91299228-41bdca80-e7dc-11ea-97bd-6bcd2d98a699.png)\n",
    "\n",
    "\n",
    "2) records loop 구문 수행\n",
    "\n",
    "\n",
    "3) record.value() system 150번 오프셋 print 중, SIGKILL 호출\n",
    "\n",
    "\n",
    "101번~150번 오프셋 처리완료, 151번 오프셋~200번 오프셋 미처리\n",
    "\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/41605276/91299282-57cb8b00-e7dc-11ea-9c27-97b77d958c3f.png)\n",
    "\n",
    "\n",
    "4) offset 200 커밋 불가\n",
    "\n",
    "\n",
    "브로커에는 100번 오프셋이 마지막 커밋\n",
    "\n",
    "\n",
    "컨슈머 재시작, 다시 오프셋 101부터 처리 시작, 101번~150번 중복처리\n",
    "\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/41605276/91299349-6f0a7880-e7dc-11ea-902d-88b8a86ecebd.png)\n",
    "\n",
    "\n",
    "위와 같은 문제를 막고 안전하게 exception 처리해서 나오기 위해 wakeup을 발생하면 된다.\n",
    "\n",
    "아래코드와 같이 자바에서는 셧다운 훅을 받을 수 있다.\n",
    "\n",
    "sigterm을 통해서 셧다운 시그널을 자바 어플리케이션에 날릴 수 있다. 이거를 통해서 데이터 commit이 완료할 수 있도록 서포트해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# java code\n",
    "Runtime.getRuntime().addShutdownHook(new Thread() {\n",
    "    public void run() {\n",
    "        consumer.wakeup();\n",
    "    }\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 메서드를 응용해서 아래와 같이 컨슈머 어플리케이션을 짤 수 있다.\n",
    "\n",
    "폴링구문에서 트라이, 캐치 부분에서 웨이크업 exception을 받을 수 있다. \n",
    "\n",
    "다시말해서 어플리케이션을 바로 끄는게 아니라 위에 코드와 같이 셧다운 훅을 받아서 웨이크업 메소드를 호출하거나 아니면 아래 코드와 같이 wakeupexception을 받아서 WakeupException이 발생했다는 것을 인지하여 finally에 commitsync하고 consumer close를 통해서 안전하게 종료하게 된다.\n",
    "\n",
    "이를 통해서 리밸런싱 하는 것을 명시적으로 브로커에게 알려줄 수 있다.\n",
    "\n",
    "아까처럼 그냥 강제로 죽이면 하트비트가 사라진 상태에서 브로커는 그냥 사라졌다고 인식해서 리밸런싱이 발생하기 때문에 안정적으로 상황이 처리되었다고 할 수 없다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try {\n",
    "    while (true) {\n",
    "        ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n",
    "        for (ConsumerRecord<String, String> record : records) {\n",
    "            System.out.println(record.value());\n",
    "        }\n",
    "        consumer.commitSync();\n",
    "    }\n",
    "} catch (WakeupException e) {\n",
    "    System.out.println(\"poll() method trigger WakeupException\");\n",
    "}finally {\n",
    "    consumer.commitSync();\n",
    "    consumer.close();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wakeup()을 통한 graceful shutdown 필수!\n",
    "\n",
    "\n",
    "SIGTERM을 통한 shutdown signal로 kill하여 처리한 데이터 커밋 필요\n",
    "\n",
    "\n",
    "SIGKILL(9)는 프로세스 강제 종료로 커밋 불가 --> 중복/유실 발생\n",
    "\n",
    "\n",
    "#### # Consumer thread 전략\n",
    "\n",
    "컨슈머의 쓰레드를 어떻게 가져갈것이냐에 관한 것이다.\n",
    "\n",
    "1안) 1 프로세스 + 1 스레드(컨슈머)\n",
    "\n",
    "\n",
    "간략한 코드\n",
    "\n",
    "\n",
    "프로세스 단위 실행/종료\n",
    "\n",
    "\n",
    "다수의 컨슈머 실행 필요시 다수의 프로세스 실행 필요\n",
    "\n",
    "\n",
    "어떤 어플리케이션을 자르파일로 압축해서 실행한다고 하면 아래와 같이 실행할 수 있다.\n",
    "\n",
    "토픽이나 그룹아이디를 받아서 config를 집어넣고 자르파일을 돌릴 수 있고, 이 어플리케이션을 하나만 실행할 수도 있고 여러개를 실행할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ cat consumer.conf\n",
    "{\"topic\":\"click_log\", \"group.id\":\"hadoop-consumers\"}\n",
    "\n",
    "$ java -jar one-process-one-consumer.jar --path consumer.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/41605276/91300808-da554a00-e7de-11ea-80cb-ec823422b2ef.png)\n",
    "\n",
    "2안) 1 프로세스 + n 스레드(동일 컨슈머 그룹)\n",
    "\n",
    "\n",
    "복잡한 코드\n",
    "\n",
    "\n",
    "스레드 단위 실행/종료\n",
    "\n",
    "\n",
    "스레드간 간섭 주의(세마포어, 데드락 등)\n",
    "\n",
    "\n",
    "다수 컨슈머 실행시 다수 스레드 실행 가능\n",
    "\n",
    "\n",
    "예를 들어서 아래와 같이 `\"consumer.no\":20` 를 받아서 20개의 컨슈머를 만들어 달라고 설정할 수도 있다.\n",
    "\n",
    "\n",
    "그래서 이런 옵션을 줘서 자르파일이 실행될때 config로 부여하여 20개의 쓰레드가 생성되도록 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ cat consumer.conf\n",
    "{\"topic\":\"click_log\", \"group.id\":\"hadoop-consumers\", \"consumer.no\":20}\n",
    "\n",
    "$ java -jar one-process-multiple-consumer.jar --path consumer.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 프로세스 (20 스레드) -------> Kafka\n",
    "\n",
    "3안) 1 프로세스 + n 스레드(다수 컨슈머 그룹)\n",
    "\n",
    "\n",
    "복잡한 코드\n",
    "\n",
    "\n",
    "컨슈머 그룹별 스레드 개수 조절 주의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ cat consumer.conf\n",
    "[\n",
    "    {\"topic\":\"click_log\", \"group.id\":\"hadoop-consumers\", \"consumer.no\":20},\n",
    "    {\"topic\":\"click_log\", \"group.id\":\"elasticsearch-consumers\", \"consumer.no\":1},\n",
    "    {\"topic\":\"application_log\", \"group.id\":\"hadoop-consumers\", \"consumer.no\":5}\n",
    "]\n",
    "\n",
    "$ java -jar one-process-multiple-consumer-multiple-group.jar --path consumer.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 프로세스 (26 스레드) -------> Kafka\n",
    "\n",
    "위와 같이 총 26개가 띄워지는 어플리케이션도 만들 수 있다.\n",
    "\n",
    "단, 쓰레드 갯수 조절이나 디버깅 중에 이슈가 발생할 수도 있다.\n",
    "\n",
    "#### # PRACTICE - Consumer multiple thread pool\n",
    "\n",
    "한개의 프로세스에 멀티플 쓰레드를 가져가는 실습을 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ec2-user@ip-10-1-10-115 tacademy-kafka]$ ls\n",
    "image                        kafka-consumer-sync-commit              README.md              실습 커맨드 리스트.txt\n",
    "kafka-consumer-auto-commit   kafka-producer-exact-partition          simple-kafka-consumer\n",
    "kafka-consumer-multi-thread  kafka-producer-key-value                simple-kafka-producer\n",
    "kafka-consumer-save-metric   아파치 카프카 입문과 활용 강의자료.pdf  telegraf.conf\n",
    "\n",
    "[ec2-user@ip-10-1-10-115 tacademy-kafka]$ cd kafka-consumer-multi-thread/\n",
    "\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-multi-thread]$ ls\n",
    "build.gradle  gradle  gradlew  gradlew.bat  settings.gradle  src\n",
    "\n",
    "# 위에 코드와는 다르게 메인쓰레드와 워크쓰레드 두개의 소스가 따로 있다.\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-multi-thread]$ ls /home/ec2-user/tacademy-kafka/kafka-consumer-multi-thread/src/main/java/com/tacademy\n",
    "ConsumerWithMultiThread.java  ConsumerWorker.java\n",
    "\n",
    "# 아래 브로커 ec2 아이피 부분을 브로커의 아이피 주소로 바꿔준다.\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-multi-thread]$ sudo vim /home/ec2-user/tacademy-kafka/kafka-consumer-multi-thread/src/main/java/com/tacademy/ConsumerWithMultiThread.java\n",
    "# ConsumerWorker.java를 실행하는 메인 쓰레드이다.\n",
    "\n",
    "package com.tacademy;\n",
    "\n",
    "import org.apache.kafka.clients.consumer.ConsumerConfig;\n",
    "import org.apache.kafka.common.serialization.StringDeserializer;\n",
    "\n",
    "import java.util.ArrayList;\n",
    "import java.util.List;\n",
    "import java.util.Properties;\n",
    "import java.util.concurrent.ExecutorService;\n",
    "import java.util.concurrent.Executors;\n",
    "\n",
    "public class ConsumerWithMultiThread {\n",
    "    private static String TOPIC_NAME = \"test\";\n",
    "    private static String GROUP_ID = \"testgroup\";\n",
    "    private static String BOOTSTRAP_SERVERS = \"{broker ec2 public ip}:9092\";\n",
    "    private static int CONSUMER_COUNT = 3;\n",
    "    # 워커쓰레드라는 것을 미리 리스트로 지정하여 추후 사용할 수 있도록 정의함\n",
    "    private static List<ConsumerWorker> workerThreads = new ArrayList<>();\n",
    "\n",
    "    public static void main(String[] args) {\n",
    "        # 아래에 ShutdownThread을 지정하여 shutdown hook을 받았다는 것을 명시적으로 할 수 있다.\n",
    "        Runtime.getRuntime().addShutdownHook(new ShutdownThread());\n",
    "        Properties configs = new Properties();\n",
    "        configs.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVERS);\n",
    "        configs.put(ConsumerConfig.GROUP_ID_CONFIG, GROUP_ID);\n",
    "        configs.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n",
    "        configs.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n",
    "        # 오토커밋 false\n",
    "        configs.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);\n",
    "\n",
    "        # newCachedThreadPool는 쓰레드가 완료되면 쓰레드가 죽는 구조이다.\n",
    "        # 그래서 아래 ConsumerWorker.java에서 while true를 통해서 계속 폴링하다가 안전하게 close되면, 쓰레드가 죽도록 하였다.\n",
    "        ExecutorService executorService = Executors.newCachedThreadPool();\n",
    "        for (int i = 0; i < CONSUMER_COUNT; i++) {\n",
    "            # 컨슈머 워커를 지정하고\n",
    "            # workerThreads에 저장을 한다.\n",
    "            # 왜냐하면 workerThreads를 기준으로 각각 shutdown 시켜서 종료할 것이기 때문이다.\n",
    "            ConsumerWorker worker = new ConsumerWorker(configs, TOPIC_NAME, i);\n",
    "            workerThreads.add(worker);\n",
    "            # 각각 생성된 worker를 executorService 쓰레드 풀을 통해 쓰레드를 실행시킨다.\n",
    "            # 이렇게 하면 쓰레드 3개가 안전하게 실행될 것이다.\n",
    "            executorService.execute(worker);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 아래 ConsumerWorker.java에서 shutdown 메서드를 호출\n",
    "    static class ShutdownThread extends Thread {\n",
    "        public void run() {\n",
    "            workerThreads.forEach(ConsumerWorker::shutdown);\n",
    "            System.out.println(\"Bye\");\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-multi-thread]$ cat /home/ec2-user/tacademy-kafka/kafka-consumer-multi-thread/src/main/java/com/tacademy/ConsumerWorker.java\n",
    "# 카프카 컨슈머가 실행되고, subscribe해서 polling을 계속하다가 wakeup이 발생하면 안전하게 어플리케이션을 종료하는 로직이다.\n",
    "\n",
    "package com.tacademy;\n",
    "\n",
    "import org.apache.kafka.clients.consumer.ConsumerRecord;\n",
    "import org.apache.kafka.clients.consumer.ConsumerRecords;\n",
    "import org.apache.kafka.clients.consumer.KafkaConsumer;\n",
    "import org.apache.kafka.common.errors.WakeupException;\n",
    "\n",
    "import java.time.Duration;\n",
    "import java.util.Arrays;\n",
    "import java.util.Properties;\n",
    "\n",
    "# 컨슈머 워커 쓰레드는 runnable로 implement 되어 있다.\n",
    "# 쓰레드 풀에서 쓰레드로 실행시킬때 사용된다. \n",
    "public class ConsumerWorker implements Runnable {\n",
    "    # 카프카 컨슈머가 한개의 쓰레드를 실행시키도록 할떄는 properties도 필요하고, 토픽이나 쓰레드 네임이 필요하기 때문에\n",
    "    # 아래와 같이 private를 지정했다.\n",
    "    private Properties prop;\n",
    "    private String topic;\n",
    "    private String threadName;\n",
    "    private KafkaConsumer<String, String> consumer;\n",
    "\n",
    "    # 그리고 생성될때 properties와 토픽 가져오도록 하였고,\n",
    "    # 쓰레드 네임을 통해서 이 쓰레드가 어떤 쓰레드인지, 어떤 데이터를 가져왔는지 확인할 수 있도록 하였다.\n",
    "    ConsumerWorker(Properties prop, String topic, int number) {\n",
    "        this.prop = prop;\n",
    "        this.topic = topic;\n",
    "        this.threadName = \"consumer-thread-\" + number;\n",
    "    }\n",
    "    \n",
    "    # 아래에 run도 override 되어 있는 것도 확인할 수 있다.\n",
    "    @Override\n",
    "    public void run() {\n",
    "        # 쓰레드가 run될때 KafkaConsumer가 instance를 새로 생성하고\n",
    "        # 그리고 topic을 구독하므로써 토픽을 가져오게 된다.\n",
    "        consumer = new KafkaConsumer<>(prop);\n",
    "        consumer.subscribe(Arrays.asList(topic));\n",
    "        try {\n",
    "            # 그리고 while true문을 통해서 poll이 지속적으로 진행되도록 했다.\n",
    "            # 출력하고 출력이 되면 컨슈머가 commitsync까지 하는 걸로 했다.\n",
    "            while (true) {\n",
    "                ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n",
    "                for (ConsumerRecord<String, String> record : records) {\n",
    "                    System.out.println(threadName + \" >> \" + record.value());\n",
    "                }\n",
    "                consumer.commitSync();\n",
    "            }\n",
    "        } catch (WakeupException e) {\n",
    "            System.out.println(threadName + \" trigger WakeupException\");\n",
    "        } finally {\n",
    "            consumer.commitSync();\n",
    "            consumer.close();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 컨슈머 워커의 셧다운 메서드를 호출하게 되면 consumer.wakeup을 호출하게 된다. \n",
    "    # 이 호출을 통해서 poll을 실행할때 wakeupexception이 발생하게 된다.\n",
    "    # 그리고 바로 위에 코드처럼 wakeupexcption이 발생된 걸 확인하고\n",
    "    # commitSync하고 close까지 하므로써 안전하게 어플리케이션을 종료하게 된다.\n",
    "    public void shutdown() {\n",
    "        consumer.wakeup();\n",
    "    }\n",
    "}\n",
    "\n",
    "# 마찬가지로 아래와 같이 build.gradle를 수정해준다.\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-multi-thread]$ sudo vim build.gradle\n",
    "apply plugin: 'application'\n",
    "mainClassName = 'com.tacademy.ConsumerWithMultiThread'\n",
    "\n",
    "group 'com.tacademy'\n",
    "version '1.0'\n",
    "\n",
    "repositories {\n",
    "    mavenCentral()\n",
    "}\n",
    "\n",
    "dependencies {\n",
    "    testCompile group: 'junit', name: 'junit', version: '4.12'\n",
    "    compile group: 'org.apache.kafka', name: 'kafka-clients', version: '2.5.0'\n",
    "}\n",
    "\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-multi-thread]$ gradle wrapper\n",
    "\n",
    "BUILD SUCCESSFUL in 0s\n",
    "1 actionable task: 1 executed\n",
    "    \n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-multi-thread]$ ./gradlew build\n",
    "\n",
    "BUILD SUCCESSFUL in 1s\n",
    "5 actionable tasks: 5 executed\n",
    "\n",
    "# 아래와 같이 어플리케이션을 띄우면 아무것도 안나올것이다.\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-multi-thread]$ ./gradlew run\n",
    "\n",
    "> Task :run\n",
    "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
    "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
    "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
    "<=========----> 75% EXECUTING [1m 6s]\n",
    "> :run\n",
    "    \n",
    "# 콘솔 프로듀서가 띄워진 터미널로 이동해서 아래와 같이 데이터를 임의로 막 입력해본다.\n",
    "[ec2-user@ip-10-1-10-115 bin]$ ./kafka-console-producer.sh --bootstrap-server 13.209.84.144:9092 --topic test\n",
    ">a\n",
    ">b\n",
    ">c\n",
    ">d\n",
    ">e\n",
    ">f\n",
    ">aaa\n",
    ">bbb\n",
    ">cc\n",
    ">ddddd\n",
    ">1\n",
    ">2\n",
    ">3\n",
    ">4\n",
    ">5\n",
    ">\n",
    "\n",
    "# 그런 다음에 다시 어플리케이션이 띄워진 터미널로 돌아오면 아래와 같이 전시된 것을 확인할 수 있다.\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-multi-thread]$ ./gradlew run\n",
    "\n",
    "> Task :run\n",
    "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
    "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
    "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
    "consumer-thread-1 >> a\n",
    "consumer-thread-1 >> b\n",
    "consumer-thread-1 >> c\n",
    "consumer-thread-1 >> d\n",
    "consumer-thread-2 >> e\n",
    "consumer-thread-2 >> f\n",
    "consumer-thread-1 >> aaa\n",
    "consumer-thread-1 >> bbb\n",
    "consumer-thread-0 >> cc\n",
    "consumer-thread-1 >> ddddd\n",
    "consumer-thread-1 >> 1\n",
    "consumer-thread-1 >> 2\n",
    "consumer-thread-0 >> 3\n",
    "consumer-thread-0 >> 4\n",
    "consumer-thread-0 >> 5\n",
    "<=========----> 75% EXECUTING [3m 26s]\n",
    "> :run\n",
    "    \n",
    "# 워커 어플리케이션 소스를 보면 쓰레드 네임과 벨류를 출력하게 되어 있다. \n",
    "# 그래서 위와 같이 쓰레드 3개가 폴링해서 데이터를 처리하고 있는 것을 확인할 수 있다.\n",
    "# 각각의 쓰레드 0,1,2가 파티션 0,1,2에 각각 할당되어 폴링하고 있는 것이다.\n",
    "\n",
    "# 어플리케이션을 안전하게 종료하고 싶을때는 어떻게 해야하나\n",
    "# 먼저 클라이언트 ec2 터미널을 하나 새로 띄운다\n",
    "# 그리고 아래와 같은 명령어를 실행시킨다.\n",
    "\n",
    "# ConsumerWithMultiThread가 돌고 있는 것을 확인할 수 있다.\n",
    "[ec2-user@ip-10-1-10-115 ~]$ jps\n",
    "16930 GradleDaemon\n",
    "27762 ConsumerWithMultiThread\n",
    "27720 GradleWrapperMain\n",
    "14058 ConsoleProducer\n",
    "28267 Jps\n",
    "\n",
    "[ec2-user@ip-10-1-10-115 ~]$ kill -term 27762\n",
    "\n",
    "# 그런다음에 다시 컨슈머 어플리케이션이 띄워진 터미널로 이동해보면\n",
    "# bye가 나오고 각각의 쓰레드가 trigger가 걸리면서 wakeupexception이 발동한 것을 확인할 수 있다.\n",
    "# 이러면 브로커도 안전하게 종료가 되었다는것을 인지하게 된다.\n",
    "# 상당한 시간이 걸리는 데이터 처리작업이 있을수록 이렇게 안전하게 종료하는게 중요하다\n",
    "# 이런식으로 wakeupexception, shutdown, close까지 완벽하게 해줘야 한다.\n",
    "[ec2-user@ip-10-1-10-115 kafka-consumer-multi-thread]$ ./gradlew run\n",
    "\n",
    "> Task :run\n",
    "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
    "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
    "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
    "consumer-thread-1 >> a\n",
    "consumer-thread-1 >> b\n",
    "consumer-thread-1 >> c\n",
    "consumer-thread-1 >> d\n",
    "consumer-thread-2 >> e\n",
    "consumer-thread-2 >> f\n",
    "consumer-thread-1 >> aaa\n",
    "consumer-thread-1 >> bbb\n",
    "consumer-thread-0 >> cc\n",
    "consumer-thread-1 >> ddddd\n",
    "consumer-thread-1 >> 1\n",
    "consumer-thread-1 >> 2\n",
    "consumer-thread-0 >> 3\n",
    "consumer-thread-0 >> 4\n",
    "consumer-thread-0 >> 5\n",
    "Bye\n",
    "consumer-thread-0 trigger WakeupException\n",
    "consumer-thread-1 trigger WakeupException\n",
    "consumer-thread-2 trigger WakeupException\n",
    "\n",
    "> Task :run FAILED\n",
    "\n",
    "FAILURE: Build failed with an exception.\n",
    "\n",
    "* What went wrong:\n",
    "Execution failed for task ':run'.\n",
    "> Process 'command '/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.252.b09-2.amzn2.0.1.x86_64/bin/java'' finished with non-zero exit value 143\n",
    "\n",
    "* Try:\n",
    "Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.\n",
    "\n",
    "* Get more help at https://help.gradle.org\n",
    "\n",
    "BUILD FAILED in 10m 13s\n",
    "2 actionable tasks: 1 executed, 1 up-to-date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### # Consumer lag\n",
    "\n",
    "컨슈머의 마지막 커밋 offset과 토픽의 마지막 offset을 말한다. 즉, 아래 그림과 같이 토픽의 마지막 offset이 123이고, 컨슈머가 처리한 offset이 117이면 그 둘의 차이인 6이 컨슈머 랙이다.\n",
    "\n",
    "만약에 producer가 보내는 데이터가 컨슈머가 처리하는 양보다 많다면 lag이 늘어날 것이다. 그러면 producer는 주구장창 계속 데이터를 보내기만 하는데 컨슈머가 못따라가면 lag이 늘어날 것이다. 지연을 어느정도 허용하는 비지니스 환경이라면 상관없지만 예를 들어 이벤트, 선착순 이런 비지니스 환경에 적용해야 할때는 적합하지 않다.\n",
    "\n",
    "\n",
    "따라서 컨슈머 랙을 모니터링 하는 것은 정말 중요하다.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/41605276/91384425-86437780-e869-11ea-9f8d-81f43021b370.png)\n",
    "\n",
    "- 컨슈머 랙은 컨슈머의 상태를 나타내는 지표.\n",
    "\n",
    "\n",
    "- 컨슈머 랙의 최대값은 컨슈머 인스턴스를 통해 직접 확인할 수 있음\n",
    "\n",
    "\n",
    "직접 확인할 수 있다는 것은 코드에서 확인할 수 있다는 것이다. \n",
    "\n",
    "\n",
    "consumer.metrics()를 통해 확인할 수 있는 지표가 있는데 그 중에 하나가 records-lag-max라는 것이다. 이는 토픽의 파티션 중 최대 랙을 의미한다. 다시말해서 파티션이 3개가 있든 20개가 있든 그 중에서 최대 랙을 확인할 수 있다. 이외에도 fetch-size-avg(1번 polling하여 가져올 때 레코드 byte평균), fetch-rate(1초 동안 레코드 가져오는 회수) 등을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 아래와 같이 consumer.metrics() 메서드를 통해서 메트릭 네임을 통해 \n",
    "## 각각의 벨류를 확인할 수 있다.\n",
    "\n",
    "while (true) {\n",
    "    ConsumerRecords<String, String> records = consumer.poll(Duration.ofSeconds(1));\n",
    "    Map<MetricName, ? extends Metric> metrics = consumer.metrics();\n",
    "    for (MetricName metric : metrics.keySet()) {\n",
    "        System.out.println(metric.name() + \" is \" + metrics.get(metric).metricValue());\n",
    "    }\n",
    "    for (ConsumerRecord<String, String> record : records) {\n",
    "        System.out.println(record.value());\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러나 이렇게 인스턴스를 통해 확인하는 것은 문제가 있다.\n",
    "\n",
    "\n",
    "왜냐하면 파티션은 여러개고 렉이 다양하게 발생할 것이기 때문에\n",
    "\n",
    "\n",
    "인스턴스에 장애가 발생하면 지표수집자체가 불가능하다.\n",
    "\n",
    "\n",
    "왜냐하면 지표를 수집하는 어플리케이션 자체가 죽어버리면 컨슈머 렉이 어디까지 잡혀있는지 알 수 없기 때문이다. 수집도 안되고, 폴링도 안되고, 메트릭에 대한 로그도 안남을거기 때문이다.\n",
    "\n",
    "\n",
    "- 컨슈머 컨슈머 인스턴스를 통한 컨슈머 랙 수집의 문제점\n",
    "\n",
    "\n",
    "- 컨슈머 인스턴스 장애가 발생하면 지표 수집 불가능\n",
    "\n",
    "\n",
    "- 구현하는 컨슈머마다 지표를 수집하는 로직 개발 필요\n",
    "\n",
    "\n",
    "구현하는 컨슈머마다 렉을 수집해야 한다. 예들들어서 내가 하둡에 저장하는 컨슈머를 만들었는데 이 컨슈머 렉을 수집하는 혹은 기록하는 어플을 따로 만들어줘야 하고, 일라스틱 서치에 저장하는 컨슈머를 만들면 이 컨슈머 렉을 수집하는 어플을 따로 만들어줘야 한다.\n",
    "\n",
    "\n",
    "- 컨슈머 랙 최대값(records-lag-max) 만 알 수 있음\n",
    "\n",
    "\n",
    "토픽에 파티션은 n개가 있을 수 있음.\n",
    "\n",
    "\n",
    "최대값을 제외한 나머지 파티션의 컨슈머 랙은 알 수 없음\n",
    "\n",
    "\n",
    "실제로는 파티션별로 렉이 얼만큼 되는지 알고 싶은 경우가 많을 것이다. 왜냐하면 프로듀서가 특정파티션에만 데이터를 넣을수도 있기 때문이다. 이 경우에 파티션별로 컨슈머 렉을 알고 싶으니까 이를 해결하기 위해서 나온게 외부의 모니터링 어플리케이션이 있다. \n",
    "\n",
    "![image](https://user-images.githubusercontent.com/41605276/91385231-644af480-e86b-11ea-95b7-7fe014d0b1f1.png)\n",
    "\n",
    "\n",
    "#### # 컨슈머 랙 모니터링\n",
    "\n",
    "- 외부 모니터링 애플리케이션을 사용권장\n",
    "\n",
    "대표주자\n",
    "\n",
    "Confluent Platform, Datadog, Kafka Burrow(Open source)\n",
    "\n",
    "\n",
    "\n",
    "- 카프카 버로우\n",
    "\n",
    "sk 플레닛에서 활용하고 있는 툴\n",
    "\n",
    "https://github.com/linkedin/Burrow\n",
    "\n",
    "인스턴스 통해서 각각의 렉을 수집을 안해도 되고, 카프카 브로커와 붙어서 전체렉을 수집할 수 있다.\n",
    "\n",
    "\n",
    "Linkedin에서 오픈소스로 제공하는 컨슈머 랙 체크 툴\n",
    "\n",
    "\n",
    "버로우 실행 시 Kafka, Zookeeper정보를 통해 랙 정보 자체 수집\n",
    "\n",
    "\n",
    "슬라이딩 윈도우를 통한 컨슈머 상태 정의\n",
    "\n",
    "\n",
    "1) OK : 정상\n",
    "\n",
    "\n",
    "2) ERROR : 컨슈머가 polling을 멈춤\n",
    "\n",
    "\n",
    "3) WARNING : 컨슈머가 polling을 수행하지만 lag이 계속 증가\n",
    "\n",
    "\n",
    "위와 같은 지표를 통해서 컨슈머의 상태를 파악할 수 있다.\n",
    "\n",
    "\n",
    "- 버로우 설치 및 운영방법\n",
    "\n",
    "\n",
    "https://blog.voidmainvoid.net/279\n",
    "\n",
    "\n",
    "#### # 기타 주의사항\n",
    "\n",
    "토픽의 파티션은 늘리는 건 가능하지만, 줄이는 건 불가능하다. \n",
    "\n",
    "\n",
    "무작정 파티션을 늘리는 것도 바람직하지는 않다. 왜냐하면 파티션이 컨슈머랑 할당되는 리벨런싱 과정에서 파티션이 늘어나면 늘어날수록 시간이 더 많이 걸린다.\n",
    "\n",
    "\n",
    "관련해서 컨플루언트에서 article을 많이 발표하고 있으니까 적절한 파티션 갯수, 적절한 컨슈머 갯수를 지정하는 것이 중요하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
