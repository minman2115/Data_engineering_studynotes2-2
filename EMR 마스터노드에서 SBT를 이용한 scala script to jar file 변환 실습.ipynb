{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". \n",
    "\n",
    "Data_Engineering_TIL(20201122)\n",
    "\n",
    "[실습시 참고자료]\n",
    "\n",
    "베스핀글로벌 최정민님 'Scala script 를 Jar file로 변환 및 실행하기' 자료\n",
    "\n",
    "[실습내용]\n",
    "\n",
    "step 1) 임의의 EMR 생성, master node로 ssh 접속\n",
    "\n",
    "step 2) EMR master node에 SBT 설치\n",
    "\n",
    "마스터노드에서 아래와 같이 명령어 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Last login: Sun Nov 22 05:36:43 2020\n",
    "\n",
    "       __|  __|_  )\n",
    "       _|  (     /   Amazon Linux 2 AMI\n",
    "      ___|\\___|___|\n",
    "\n",
    "https://aws.amazon.com/amazon-linux-2/\n",
    "71 package(s) needed for security, out of 105 available\n",
    "Run \"sudo yum update\" to apply all updates.\n",
    "\n",
    "EEEEEEEEEEEEEEEEEEEE MMMMMMMM           MMMMMMMM RRRRRRRRRRRRRRR\n",
    "E::::::::::::::::::E M:::::::M         M:::::::M R::::::::::::::R\n",
    "EE:::::EEEEEEEEE:::E M::::::::M       M::::::::M R:::::RRRRRR:::::R\n",
    "  E::::E       EEEEE M:::::::::M     M:::::::::M RR::::R      R::::R\n",
    "  E::::E             M::::::M:::M   M:::M::::::M   R:::R      R::::R\n",
    "  E:::::EEEEEEEEEE   M:::::M M:::M M:::M M:::::M   R:::RRRRRR:::::R\n",
    "  E::::::::::::::E   M:::::M  M:::M:::M  M:::::M   R:::::::::::RR\n",
    "  E:::::EEEEEEEEEE   M:::::M   M:::::M   M:::::M   R:::RRRRRR::::R\n",
    "  E::::E             M:::::M    M:::M    M:::::M   R:::R      R::::R\n",
    "  E::::E       EEEEE M:::::M     MMM     M:::::M   R:::R      R::::R\n",
    "EE:::::EEEEEEEE::::E M:::::M             M:::::M   R:::R      R::::R\n",
    "E::::::::::::::::::E M:::::M             M:::::M RR::::R      R::::R\n",
    "EEEEEEEEEEEEEEEEEEEE MMMMMMM             MMMMMMM RRRRRRR      RRRRRR\n",
    "\n",
    "[hadoop@ip-10-0-1-70 ~]$ curl https://bintray.com/sbt/rpm/rpm | sudo tee /etc/yum.repos.d/bintraysbt-rpm.repo\n",
    "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
    "                                 Dload  Upload   Total   Spent    Left  Speed\n",
    "100   160    0   160    0     0    212      0 --:--:-- --:--:-- --:--:--   212\n",
    "#bintray--sbt-rpm - packages by  from Bintray\n",
    "[bintray--sbt-rpm]\n",
    "name=bintray--sbt-rpm\n",
    "baseurl=https://sbt.bintray.com/rpm\n",
    "gpgcheck=0\n",
    "repo_gpgcheck=0\n",
    "enabled=1\n",
    "            \n",
    "[hadoop@ip-10-0-1-70 ~]$ sudo yum install sbt -y\n",
    "Loaded plugins: extras_suggestions, langpacks, priorities, update-motd\n",
    "amzn2-core                                                                                                        | 3.7 kB  00:00:00\n",
    "bintray--sbt-rpm                                                                                                  | 1.3 kB  00:00:00\n",
    "bintray--sbt-rpm/primary                                                                                          | 6.0 kB  00:00:00\n",
    "bintray--sbt-rpm                                                                                                                   55/55\n",
    "9 packages excluded due to repository priority protections\n",
    "No package sbtsudo available.\n",
    "Package yum-3.4.3-158.amzn2.0.4.noarch already installed and latest version\n",
    "No package install available.\n",
    "Resolving Dependencies\n",
    "--> Running transaction check\n",
    "---> Package sbt.noarch 0:1.4.3-0 will be installed\n",
    "--> Finished Dependency Resolution\n",
    "\n",
    "Dependencies Resolved\n",
    "\n",
    "=========================================================================================================================================\n",
    " Package                    Arch                          Version                          Repository                               Size\n",
    "=========================================================================================================================================\n",
    "Installing:\n",
    " sbt                        noarch                        1.4.3-0                          bintray--sbt-rpm                        1.2 M\n",
    "\n",
    "Transaction Summary\n",
    "=========================================================================================================================================\n",
    "Install  1 Package\n",
    "\n",
    "Total download size: 1.2 M\n",
    "Installed size: 1.4 M\n",
    "Downloading packages:\n",
    "sbt-1.4.3.rpm                                                                                                     | 1.2 MB  00:00:00\n",
    "Running transaction check\n",
    "Running transaction test\n",
    "Transaction test succeeded\n",
    "Running transaction\n",
    "  Installing : sbt-1.4.3-0.noarch                                                                                                    1/1\n",
    "  Verifying  : sbt-1.4.3-0.noarch                                                                                                    1/1\n",
    "\n",
    "Installed:\n",
    "  sbt.noarch 0:1.4.3-0\n",
    "\n",
    "Complete!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 3) SBT project 구성\n",
    "\n",
    "- .sbt 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[hadoop@ip-10-0-1-70 my_scala_pj]$ pwd\n",
    "/home/hadoop\n",
    "\n",
    "[hadoop@ip-10-0-1-70 ~]$ mkdir my_scala_pj\n",
    "\n",
    "[hadoop@ip-10-0-1-70 ~]$ cd my_scala_pj/\n",
    "\n",
    "[hadoop@ip-10-0-1-70 my_scala_pj]$ sudo vim ./simple.sbt\n",
    "# 자유롭게 임의로 작성\n",
    "name := \"My scala Project\"\n",
    "    \n",
    "# 자유롭게 임의로 작성\n",
    "version := \"0.1\"\n",
    "    \n",
    "# 아래의 내용은 script의 종속성과 연관되어 있기 때문에 스크립트에 필요한 라이브러리에 맞게 작성되어야 함\n",
    "scalaVersion := \"2.12.12\"\n",
    "libraryDependencies += \"org.apache.spark\" %% \"spark-sql\" % \"3.0.0\"\n",
    "\n",
    "[hadoop@ip-10-0-1-70 my_scala_pj]$ find .\n",
    ".\n",
    "./simple.sbt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TestApp.scala 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[hadoop@ip-10-0-1-70 my_scala_pj]$ mkdir src\n",
    "\n",
    "[hadoop@ip-10-0-1-70 my_scala_pj]$ ls\n",
    "simple.sbt  src\n",
    "\n",
    "[hadoop@ip-10-0-1-70 my_scala_pj]$ cd src\n",
    "\n",
    "[hadoop@ip-10-0-1-70 src]$ mkdir main\n",
    "\n",
    "[hadoop@ip-10-0-1-70 src]$ cd main\n",
    "\n",
    "[hadoop@ip-10-0-1-70 main]$ mkdir scala\n",
    "\n",
    "[hadoop@ip-10-0-1-70 main]$ cd scala\n",
    "\n",
    "[hadoop@ip-10-0-1-70 scala]$ pwd\n",
    "/home/hadoop/my_scala_pj/src/main/scala\n",
    "\n",
    "[hadoop@ip-10-0-1-70 scala]$ sudo vim TestApp.scala\n",
    "\n",
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "object TestApp {\n",
    "\n",
    "  def main(args: Array[String]): Unit = {\n",
    "\n",
    "    val spark = SparkSession.builder.master(\"yarn\").appName(\"my_app\").getOrCreate()\n",
    "    \n",
    "    val rdd = spark.read.textFile(\"s3://pms-bucket-test/README.txt\")\n",
    "\n",
    "    rdd.write.format(\"parquet\").save(\"s3://pms-bucket-test/test_folder\")\n",
    "\n",
    "    println(\"Job done\")\n",
    "    spark.stop()\n",
    "\n",
    "    System.exit(0)\n",
    "\n",
    "  }\n",
    "}\n",
    "\n",
    "[hadoop@ip-10-0-1-70 scala]$ cd /home/hadoop/my_scala_pj\n",
    "\n",
    "[hadoop@ip-10-0-1-70 my_scala_pj]$ find .\n",
    ".\n",
    "./simple.sbt\n",
    "./src\n",
    "./src/main\n",
    "./src/main/scala\n",
    "./src/main/scala/TestApp.scala\n",
    "\n",
    "[hadoop@ip-10-0-1-70 my_scala_pj]$ tree\n",
    ".\n",
    "├── simple.sbt\n",
    "└── src\n",
    "    └── main\n",
    "        └── scala\n",
    "            └── TestApp.scala\n",
    "\n",
    "3 directories, 2 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 4) scala script to jar file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로젝트 최상단 폴더로 이동\n",
    "[hadoop@ip-10-0-1-70 my_scala_pj]$ cd /home/hadoop/my_scala_pj\n",
    "\n",
    "[hadoop@ip-10-0-1-70 my_scala_pj]$ sbt package\n",
    "[info] [launcher] getting org.scala-sbt sbt 1.4.3  (this may take some time)...\n",
    "downloading https://repo1.maven.org/maven2/org/scala-sbt/sbt/1.4.3/sbt-1.4.3.jar ...\n",
    ":: loading settings :: url = jar:file:/usr/share/sbt/bin/sbt-launch.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
    "downloading https://repo1.maven.org/maven2/org/scala-lang/scala-library/2.12.12/scala-library-2.12.12.jar ...\n",
    ":: loading settings :: url = jar:file:/usr/share/sbt/bin/sbt-launch.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
    "downloading https://repo1.maven.org/maven2/org/scala-sbt/io_2.12/1.4.0/io_2.12-1.4.0.jar ...\n",
    ":: loading settings :: url = jar:file:/usr/share/sbt/bin/sbt-launch.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
    "downloading https://repo1.maven.org/maven2/org/scala-sbt/main_2.12/1.4.3/main_2.12-1.4.3.jar ...\n",
    ":: loading settings :: url = jar:file:/usr/share/sbt/bin/sbt-launch.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
    "        [SUCCESSFUL ] org.scala-sbt#sbt;1.4.3!sbt.jar (615ms)\n",
    "downloading https://repo1.maven.org/maven2/org/scala-sbt/logic_2.12/1.4.3/logic_2.12-1.4.3.jar ...\n",
    "        [SUCCESSFUL ] org.scala-sbt#logic_2.12;1.4.3!logic_2.12.jar (579ms)\n",
    "downloading https://repo1.maven.org/maven2/org/scala-sbt/actions_2.12/1.4.3/actions_2.12-1.4.3.jar ...\n",
    "        [SUCCESSFUL ] org.scala-sbt#io_2.12;1.4.0!io_2.12.jar (1461ms)\n",
    "downloading https://repo1.maven.org/maven2/org/scala-sbt/main-settings_2.12/1.4.3/main-settings_2.12-1.4.3.jar ...\n",
    "        [SUCCESSFUL ] org.scala-sbt#actions_2.12;1.4.3!actions_2.12.jar (732ms)\n",
    "    \n",
    "    ...\n",
    "       \n",
    "https://repo1.maven.org/maven2/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar\n",
    "  100.0% [##########] 634.7 KiB (2.7 MiB / s)\n",
    "[info] Fetched artifacts of\n",
    "[warn] There may be incompatibilities among your library dependencies; run 'evicted' to see detailed eviction warnings.\n",
    "[info] compiling 1 Scala source to /home/hadoop/my_scala_pj/target/scala-2.12/classes ...\n",
    "https://repo1.maven.org/maven2/org/scala-sbt/compiler-bridge_2.12/1.4.3/compiler-bridge_2.12-1.4.3.pom\n",
    "  100.0% [##########] 2.7 KiB (17.5 KiB / s)\n",
    "https://repo1.maven.org/maven2/org/scala-sbt/compiler-interface/1.4.3/compiler-interface-1.4.3.pom\n",
    "  100.0% [##########] 2.9 KiB (19.3 KiB / s)\n",
    "https://repo1.maven.org/maven2/org/scala-sbt/compiler-bridge_2.12/1.4.3/compiler-bridge_2.12-1.4.3-sources.jar\n",
    "  100.0% [##########] 52.4 KiB (376.8 KiB / s)\n",
    "https://repo1.maven.org/maven2/org/scala-sbt/util-interface/1.4.0/util-interface-1.4.0.jar\n",
    "  100.0% [##########] 2.6 KiB (19.0 KiB / s)\n",
    "[info] Non-compiled module 'compiler-bridge_2.12' for Scala 2.12.12. Compiling...\n",
    "[info]   Compilation completed in 9.657s.\n",
    "[success] Total time: 32 s, completed Nov 22, 2020 6:33:34 AM\n",
    "      \n",
    "# /home/hadoop/my_scala_pj/target/scala-2.12 폴더에 my-scala-project_2.12-0.1.jar 생성\n",
    "[hadoop@ip-10-0-1-70 my_scala_pj]$ tree\n",
    ".\n",
    "├── project\n",
    "│   ├── build.properties\n",
    "│   └── target\n",
    "│       ├── config-classes\n",
    "│       │   ├── $26557af1960df2d28302.cache\n",
    "│       │   ├── $26557af1960df2d28302.class\n",
    "│       │   ├── $26557af1960df2d28302$.class\n",
    "│       │   ├── $2c66babbd77e41c16c42.cache\n",
    "│       │   ├── $2c66babbd77e41c16c42.class\n",
    "│       │   ├── $2c66babbd77e41c16c42$.class\n",
    "│       │   ├── $3f5e9b4c00ec2e641532.cache\n",
    "│       │   ├── $3f5e9b4c00ec2e641532.class\n",
    "│       │   ├── $3f5e9b4c00ec2e641532$.class\n",
    "│       │   ├── $f4aa3cb48b96f0931374.cache\n",
    "│       │   ├── $f4aa3cb48b96f0931374.class\n",
    "│       │   └── $f4aa3cb48b96f0931374$.class\n",
    "│       ├── scala-2.12\n",
    "│       │   └── sbt-1.0\n",
    "│       │       └── update\n",
    "│       │           └── update_cache_2.12\n",
    "│       │               ├── inputs\n",
    "│       │               └── output\n",
    "│       └── streams\n",
    "│           ├── compile\n",
    "│           │   ├── bspReporter\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           └── out\n",
    "│           │   ├── compile\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           └── out\n",
    "│           │   ├── compileIncremental\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           ├── export\n",
    "│           │   │           └── out\n",
    "│           │   ├── copyResources\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           ├── copy-resources\n",
    "│           │   │           └── out\n",
    "│           │   ├── dependencyClasspath\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           └── export\n",
    "│           │   ├── exportedProducts\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           └── export\n",
    "│           │   ├── externalDependencyClasspath\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           └── export\n",
    "│           │   ├── _global\n",
    "│           │   │   └── _global\n",
    "│           │   │       ├── compileOutputs\n",
    "│           │   │       │   └── previous\n",
    "│           │   │       └── discoveredMainClasses\n",
    "│           │   │           └── data\n",
    "│           │   ├── incOptions\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           └── out\n",
    "│           │   ├── internalDependencyClasspath\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           ├── export\n",
    "│           │   │           └── out\n",
    "│           │   ├── managedClasspath\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           └── export\n",
    "│           │   ├── scalacOptions\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           └── out\n",
    "│           │   ├── unmanagedClasspath\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           ├── export\n",
    "│           │   │           └── out\n",
    "│           │   └── unmanagedJars\n",
    "│           │       └── _global\n",
    "│           │           └── streams\n",
    "│           │               └── export\n",
    "│           ├── _global\n",
    "│           │   ├── csrConfiguration\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           └── out\n",
    "│           │   ├── csrProject\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           └── out\n",
    "│           │   ├── dependencyPositions\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           └── update_cache_2.12\n",
    "│           │   │               ├── input_dsp\n",
    "│           │   │               └── output_dsp\n",
    "│           │   ├── _global\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           └── out\n",
    "│           │   ├── ivyConfiguration\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           └── out\n",
    "│           │   ├── ivySbt\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           └── out\n",
    "│           │   ├── moduleSettings\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           └── out\n",
    "│           │   ├── projectDescriptors\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           └── out\n",
    "│           │   ├── scalaCompilerBridgeScope\n",
    "│           │   │   └── _global\n",
    "│           │   │       └── streams\n",
    "│           │   │           └── out\n",
    "│           │   └── update\n",
    "│           │       └── _global\n",
    "│           │           └── streams\n",
    "│           │               └── out\n",
    "│           └── runtime\n",
    "│               ├── dependencyClasspath\n",
    "│               │   └── _global\n",
    "│               │       └── streams\n",
    "│               │           └── export\n",
    "│               ├── exportedProducts\n",
    "│               │   └── _global\n",
    "│               │       └── streams\n",
    "│               │           └── export\n",
    "│               ├── externalDependencyClasspath\n",
    "│               │   └── _global\n",
    "│               │       └── streams\n",
    "│               │           └── export\n",
    "│               ├── fullClasspath\n",
    "│               │   └── _global\n",
    "│               │       └── streams\n",
    "│               │           └── export\n",
    "│               ├── internalDependencyClasspath\n",
    "│               │   └── _global\n",
    "│               │       └── streams\n",
    "│               │           ├── export\n",
    "│               │           └── out\n",
    "│               ├── managedClasspath\n",
    "│               │   └── _global\n",
    "│               │       └── streams\n",
    "│               │           └── export\n",
    "│               ├── unmanagedClasspath\n",
    "│               │   └── _global\n",
    "│               │       └── streams\n",
    "│               │           ├── export\n",
    "│               │           └── out\n",
    "│               └── unmanagedJars\n",
    "│                   └── _global\n",
    "│                       └── streams\n",
    "│                           └── export\n",
    "├── simple.sbt\n",
    "├── src\n",
    "│   └── main\n",
    "│       └── scala\n",
    "│           └── TestApp.scala\n",
    "└── target\n",
    "    ├── global-logging\n",
    "    ├── scala-2.12\n",
    "    │   ├── classes\n",
    "    │   │   ├── TestApp.class\n",
    "    │   │   └── TestApp$.class\n",
    "    │   ├── my-scala-project_2.12-0.1.jar\n",
    "    │   ├── update\n",
    "    │   │   └── update_cache_2.12\n",
    "    │   │       ├── inputs\n",
    "    │   │       └── output\n",
    "    │   └── zinc\n",
    "    │       └── inc_compile_2.12.zip\n",
    "    ├── streams\n",
    "    │   ├── compile\n",
    "    │   │   ├── bspReporter\n",
    "    │   │   │   └── _global\n",
    "    │   │   │       └── streams\n",
    "    │   │   │           └── out\n",
    "    │   │   ├── compile\n",
    "    │   │   │   └── _global\n",
    "    │   │   │       └── streams\n",
    "    │   │   │           └── out\n",
    "    │   │   ├── compileIncremental\n",
    "    │   │   │   └── _global\n",
    "    │   │   │       └── streams\n",
    "    │   │   │           ├── export\n",
    "    │   │   │           └── out\n",
    "    │   │   ├── copyResources\n",
    "    │   │   │   └── _global\n",
    "    │   │   │       └── streams\n",
    "    │   │   │           ├── copy-resources\n",
    "    │   │   │           └── out\n",
    "    │   │   ├── dependencyClasspath\n",
    "    │   │   │   └── _global\n",
    "    │   │   │       └── streams\n",
    "    │   │   │           └── export\n",
    "    │   │   ├── externalDependencyClasspath\n",
    "    │   │   │   └── _global\n",
    "    │   │   │       └── streams\n",
    "    │   │   │           └── export\n",
    "    │   │   ├── _global\n",
    "    │   │   │   └── _global\n",
    "    │   │   │       ├── compileOutputs\n",
    "    │   │   │       │   └── previous\n",
    "    │   │   │       └── discoveredMainClasses\n",
    "    │   │   │           └── data\n",
    "    │   │   ├── incOptions\n",
    "    │   │   │   └── _global\n",
    "    │   │   │       └── streams\n",
    "    │   │   │           └── out\n",
    "    │   │   ├── internalDependencyClasspath\n",
    "    │   │   │   └── _global\n",
    "    │   │   │       └── streams\n",
    "    │   │   │           ├── export\n",
    "    │   │   │           └── out\n",
    "    │   │   ├── mainClass\n",
    "    │   │   │   └── _global\n",
    "    │   │   │       └── streams\n",
    "    │   │   │           └── out\n",
    "    │   │   ├── managedClasspath\n",
    "    │   │   │   └── _global\n",
    "    │   │   │       └── streams\n",
    "    │   │   │           └── export\n",
    "    │   │   ├── packageBin\n",
    "    │   │   │   └── _global\n",
    "    │   │   │       └── streams\n",
    "    │   │   │           ├── inputs\n",
    "    │   │   │           ├── out\n",
    "    │   │   │           └── output\n",
    "    │   │   ├── scalacOptions\n",
    "    │   │   │   └── _global\n",
    "    │   │   │       └── streams\n",
    "    │   │   │           └── out\n",
    "    │   │   ├── unmanagedClasspath\n",
    "    │   │   │   └── _global\n",
    "    │   │   │       └── streams\n",
    "    │   │   │           ├── export\n",
    "    │   │   │           └── out\n",
    "    │   │   └── unmanagedJars\n",
    "    │   │       └── _global\n",
    "    │   │           └── streams\n",
    "    │   │               └── export\n",
    "    │   └── _global\n",
    "    │       ├── csrConfiguration\n",
    "    │       │   └── _global\n",
    "    │       │       └── streams\n",
    "    │       │           └── out\n",
    "    │       ├── csrProject\n",
    "    │       │   └── _global\n",
    "    │       │       └── streams\n",
    "    │       │           └── out\n",
    "    │       ├── dependencyPositions\n",
    "    │       │   └── _global\n",
    "    │       │       └── streams\n",
    "    │       │           └── update_cache_2.12\n",
    "    │       │               ├── input_dsp\n",
    "    │       │               └── output_dsp\n",
    "    │       ├── _global\n",
    "    │       │   └── _global\n",
    "    │       │       └── streams\n",
    "    │       │           └── out\n",
    "    │       ├── ivyConfiguration\n",
    "    │       │   └── _global\n",
    "    │       │       └── streams\n",
    "    │       │           └── out\n",
    "    │       ├── ivySbt\n",
    "    │       │   └── _global\n",
    "    │       │       └── streams\n",
    "    │       │           └── out\n",
    "    │       ├── moduleSettings\n",
    "    │       │   └── _global\n",
    "    │       │       └── streams\n",
    "    │       │           └── out\n",
    "    │       ├── projectDescriptors\n",
    "    │       │   └── _global\n",
    "    │       │       └── streams\n",
    "    │       │           └── out\n",
    "    │       ├── scalaCompilerBridgeScope\n",
    "    │       │   └── _global\n",
    "    │       │       └── streams\n",
    "    │       │           └── out\n",
    "    │       └── update\n",
    "    │           └── _global\n",
    "    │               └── streams\n",
    "    │                   └── out\n",
    "    └── task-temp-directory\n",
    "\n",
    "200 directories, 96 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 5) spark-submit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[hadoop@ip-10-0-1-70 ~]$ spark-submit --deploy-mode client /home/hadoop/my_scala_pj/target/scala-2.12/my-scala-project_2.12-0.1.jar\n",
    "20/11/22 06:51:35 INFO SparkContext: Running Spark version 3.0.0-amzn-0\n",
    "20/11/22 06:51:35 INFO ResourceUtils: ==============================================================\n",
    "20/11/22 06:51:35 INFO ResourceUtils: Resources for spark.driver:\n",
    "\n",
    "20/11/22 06:51:35 INFO ResourceUtils: ==============================================================\n",
    "20/11/22 06:51:35 INFO SparkContext: Submitted application: my_app\n",
    "20/11/22 06:51:35 INFO SecurityManager: Changing view acls to: hadoop\n",
    "20/11/22 06:51:35 INFO SecurityManager: Changing modify acls to: hadoop\n",
    "20/11/22 06:51:35 INFO SecurityManager: Changing view acls groups to:\n",
    "20/11/22 06:51:35 INFO SecurityManager: Changing modify acls groups to:\n",
    "20/11/22 06:51:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoop); groups with view permissions: Set(); users  with modify permissions: Set(hadoop); groups with modify permissions: Set()\n",
    "20/11/22 06:51:35 INFO Utils: Successfully started service 'sparkDriver' on port 46701.\n",
    "20/11/22 06:51:35 INFO SparkEnv: Registering MapOutputTracker\n",
    "20/11/22 06:51:35 INFO SparkEnv: Registering BlockManagerMaster\n",
    "20/11/22 06:51:35 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
    "20/11/22 06:51:35 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
    "20/11/22 06:51:36 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
    "20/11/22 06:51:36 INFO DiskBlockManager: Created local directory at /mnt/tmp/blockmgr-1dbf36f4-4555-4043-8b2d-xxxxxxxxxxxx\n",
    "20/11/22 06:51:36 INFO MemoryStore: MemoryStore started with capacity 1028.8 MiB\n",
    "20/11/22 06:51:36 INFO SparkEnv: Registering OutputCommitCoordinator\n",
    "20/11/22 06:51:36 INFO log: Logging initialized @2638ms to org.sparkproject.jetty.util.log.Slf4jLog\n",
    "20/11/22 06:51:36 INFO Server: jetty-9.4.20.v20190813; built: 2019-08-13T21:28:18.144Z; git: xxxxxxxxxxxxxxxxxxx; jvm 1.8.0_252-b09\n",
    "20/11/22 06:51:36 INFO Server: Started @2748ms\n",
    "20/11/22 06:51:36 INFO AbstractConnector: Started ServerConnector@4f7c0be3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}\n",
    "20/11/22 06:51:36 INFO Utils: Successfully started service 'SparkUI' on port 4040.\n",
    "20/11/22 06:51:36 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4a1e3ac1{/jobs,null,AVAILABLE,@Spark}\n",
    "\n",
    "            ...\n",
    "            \n",
    "20/11/22 06:52:00 INFO MultipartUploadOutputStream: close closed:false s3://pms-bucket-test/test_folder/_SUCCESS\n",
    "20/11/22 06:52:01 INFO BlockManagerInfo: Removed broadcast_1_piece0 on ip-10-0-1-70.ap-northeast-2.compute.internal:44339 in memory (size: 76.6 KiB, free: 1028.8 MiB)\n",
    "20/11/22 06:52:01 INFO BlockManagerInfo: Removed broadcast_1_piece0 on ip-10-0-1-70.ap-northeast-2.compute.internal:41353 in memory (size: 76.6 KiB, free: 2.6 GiB)\n",
    "20/11/22 06:52:01 INFO FileFormatWriter: Write Job 75e58e92-278e-4bd0-8ec4-ff25d5a95b4f committed.\n",
    "20/11/22 06:52:01 INFO FileFormatWriter: Finished processing stats for write job 75e58e92-278e-4bd0-8ec4-xxxxxxxxxx.\n",
    "Job done\n",
    "20/11/22 06:52:01 INFO AbstractConnector: Stopped Spark@4f7c0be3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}\n",
    "20/11/22 06:52:01 INFO SparkUI: Stopped Spark web UI at http://ip-10-0-1-70.ap-northeast-2.compute.internal:4040\n",
    "20/11/22 06:52:01 INFO YarnClientSchedulerBackend: Interrupting monitor thread\n",
    "20/11/22 06:52:01 INFO YarnClientSchedulerBackend: Shutting down all executors\n",
    "20/11/22 06:52:01 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\n",
    "20/11/22 06:52:01 INFO YarnClientSchedulerBackend: YARN client scheduler backend Stopped\n",
    "20/11/22 06:52:01 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
    "20/11/22 06:52:01 INFO MemoryStore: MemoryStore cleared\n",
    "20/11/22 06:52:01 INFO BlockManager: BlockManager stopped\n",
    "20/11/22 06:52:01 INFO BlockManagerMaster: BlockManagerMaster stopped\n",
    "20/11/22 06:52:01 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
    "20/11/22 06:52:01 INFO SparkContext: Successfully stopped SparkContext\n",
    "20/11/22 06:52:01 INFO ShutdownHookManager: Shutdown hook called\n",
    "20/11/22 06:52:01 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-54537dcf-0233-4fd6-a929-46767d90b6e0\n",
    "20/11/22 06:52:01 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-f1de40ef-1032-4235-b334-39078403f24e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
