{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "Data_Engineering_TIL(20200624)\n",
    "\n",
    "[참고사항]\n",
    "\n",
    "- study program : Fastcampus Data Engineering 온라인\n",
    "\n",
    "** URL : https://www.fastcampus.co.kr/data_online_engineering\n",
    "\n",
    "\n",
    "- 'Lambda를 이용한 데이터 파이프라이닝 구축'를 이어서 참고할 것\n",
    "\n",
    "\n",
    "- URL : https://minman2115.github.io/DE_TIL95\n",
    "\n",
    "[학습내용]\n",
    "\n",
    "- spotify API로 부터 오디오 피쳐 데이터를 가져왔는데 이 오디오 피쳐를 가지고 아티스트들끼리의 유사도를 구하는 모델을 만드려고 한다.\n",
    "\n",
    "\n",
    "- 먼저 아래의 코드를 실행하여 s3에 파일을 떨군다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import boto3\n",
    "import requests\n",
    "import base64\n",
    "import json\n",
    "import pymysql\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import jsonpath\n",
    "\n",
    "host = \"pms-rdstest-rds.xxxxxxxxxxxxxxxxxxx.ap-northeast-2.rds.amazonaws.com\"\n",
    "port = 3306\n",
    "username = \"admin\"\n",
    "database = \"pmstest\"\n",
    "password = \"xxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "client_id = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "client_secret = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        conn = pymysql.connect(host, user=username, passwd=password, db=database, port=port, use_unicode=True, charset='utf8')\n",
    "        cursor = conn.cursor()\n",
    "    except:\n",
    "        logging.error(\"could not connect to rds\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    headers = get_headers(client_id, client_secret)\n",
    "\n",
    "    ## RDS에서 10명의 아티스트 ID data를 Load\n",
    "    cursor.execute(\"SELECT id FROM artists LIMIT 10\")\n",
    "\n",
    "    ## jsonpath를 이용해서 해당 path안에 어떤 data를 insert를 했을때 그 안에서 key path를 찾는다.\n",
    "    ## 그 path를 찾아서 그 value값을 사용자에게 줄 수도 있다. 이거를 아래와 같이 활용할 수 있다.\n",
    "    top_track_keys = {\n",
    "        \"id\": \"id\",\n",
    "        \"name\": \"name\",\n",
    "        \"popularity\": \"popularity\",\n",
    "        \"external_url\": \"external_urls.spotify\"\n",
    "    }\n",
    "\n",
    "    ## Top Tracks 정보를 Spotify API로 부터 Load\n",
    "    top_tracks = []\n",
    "    for (id, ) in cursor.fetchall():\n",
    "        URL = \"https://api.spotify.com/v1/artists/{}/top-tracks\".format(id)\n",
    "        params = {'country': 'US'}\n",
    "        r = requests.get(URL, params=params, headers=headers)\n",
    "        raw = json.loads(r.text)\n",
    "\n",
    "        for i in raw['tracks']:\n",
    "            ## track 하나하마나다 딕셔너리 형태의 데이터가 떨어질 것이다.\n",
    "            top_track = {}\n",
    "            for k, v in top_track_keys.items():\n",
    "                top_track.update({k: jsonpath.jsonpath(i, v)})\n",
    "                ## k는 top_track_keys에서 key를 얘기하는 것이다.\n",
    "                ## v는 top_track_keys에서 value를 얘기하는 것이다.\n",
    "                ## jsonpath.jsonpath(i, v)는 i 딕셔너리 데이터에서\n",
    "                ## v에 해당하는 path의 데이터를 가져오라는 것이다.\n",
    "                ## 예를 들어 위와 같이 제이스 패스를 이용해서 id만\n",
    "                ## 가져온다고 치면 아래와 같이\n",
    "                ## \"id\" : \"aksdnc20202192029\" 처럼 들어올것이다.\n",
    "                top_track.update({'artist_id': id})\n",
    "                top_tracks.append(top_track)\n",
    "\n",
    "    ## track_ids 가져오기\n",
    "    track_ids = [i['id'][0] for i in top_tracks]\n",
    "\n",
    "    top_tracks = pd.DataFrame(top_tracks)\n",
    "    top_tracks.to_parquet('top-tracks.parquet', engine='pyarrow', compression='snappy')\n",
    "\n",
    "    dt = datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    s3 = boto3.resource('s3')\n",
    "    object = s3.Object('pms-bucket-test', 'top-tracks/dt={}/top-tracks.parquet'.format(dt))\n",
    "    data = open('top-tracks.parquet', 'rb')\n",
    "    object.put(Body=data)\n",
    "\n",
    "\n",
    "    ## audio features 데이터도 파케이 파일로 만들어보자\n",
    "\n",
    "    ## tracks_batch 정의하기\n",
    "    tracks_batch = [track_ids[i:i+100] for i in range(0,len(track_ids),100)]\n",
    "\n",
    "    audio_features = []\n",
    "    for i in tracks_batch:\n",
    "        ids = ','.join(i)\n",
    "        URL = 'https://api.spotify.com/v1/audio-features/?ids={}'.format(ids)\n",
    "        r = requests.get(URL, headers=headers)\n",
    "        raw = json.loads(r.text)\n",
    "        audio_features.extend(raw['audio_features'])\n",
    "\n",
    "    audio_features = pd.DataFrame(audio_features)\n",
    "    audio_features.to_parquet('audio-features.parquet', engine='pyarrow', compression='snappy')\n",
    "\n",
    "    s3 = boto3.resource('s3')\n",
    "    object = s3.Object('pms-bucket-test', 'audio-features/dt={}/audio-features.parquet'.format(dt))\n",
    "    data = open('audio-features.parquet', 'rb')\n",
    "    object.put(Body=data)\n",
    "\n",
    "    return None\n",
    "\n",
    "def get_headers(client_id, client_secret):\n",
    "    endpoint = \"https://accounts.spotify.com/api/token\"\n",
    "    encoded = base64.b64encode(\"{}:{}\".format(client_id, client_secret).encode('utf-8')).decode('ascii')\n",
    "    headers = {\"Authorization\": \"Basic {}\".format(encoded)}\n",
    "    payload = {\"grant_type\": \"client_credentials\"}\n",
    "    r = requests.post(endpoint, data=payload, headers=headers)\n",
    "    access_token = json.loads(r.text)['access_token']\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(access_token)}\n",
    "    return headers\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위에 코드를 실행하면 아래 그림과 같이 s3에 top_tracks와 audio_features 파케이 파일이 떨궈진다. 우리는 이 데이터를 활용할 것이다.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/41605276/85505833-2a226400-b62a-11ea-891d-537cd2c2d466.png)\n",
    "\n",
    "\n",
    "- 그 다음에 글루에서 데이터베이스 하나 만들어주고, 아테나로 이동해서 아래와 같은 코드를 날려서 아테나 테이블 top_tracks와 audio_features를 만들어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE EXTERNAL TABLE IF NOT EXISTS top_tracks(\n",
    "  id string,\n",
    "  artist_id string,\n",
    "  name string,\n",
    "  popularity int,\n",
    "  external_url string\n",
    ") PARTITIONED BY (dt string) \n",
    "STORED AS PARQUET LOCATION 's3://pms-bucket-test/top-tracks/' tblproperties(\"parquet.compress\"=\"SNAPPY\");\n",
    "\n",
    "MSCK REPAIR TABLE top_tracks;\n",
    "\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS audio_features(\n",
    "  id string,\n",
    "  danceability DOUBLE,\n",
    "  energy DOUBLE,\n",
    "  key int,\n",
    "  loudness DOUBLE,\n",
    "  mode int,\n",
    "  speechiness DOUBLE,\n",
    "  accusticness DOUBLE,\n",
    "  instrumentalness DOUBLE\n",
    ") PARTITIONED BY (dt string) \n",
    "STORED AS PARQUET LOCATION 's3://pms-bucket-test/audio-features/' tblproperties(\"parquet.compress\"=\"SNAPPY\");\n",
    "\n",
    "MSCK REPAIR TABLE audio_features;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그리고 우리가 일전에 생성했던 RDS에 접속해서 아래와 같은 쿼리 명령으로 새로운 RDS 테이블을 하나 만들어준다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE TABLE related_artists (artist_id VARCHAR(255), y_artist VARCHAR(255), distance FLOAT, PRIMARY KEY(artist_id,y_artist)) \n",
    "ENGINE=InnoDB DEFAULT CHARSET=utf8;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그리고 아래와 같이 유사도 모델링을 구현한 코드를 실행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import boto3\n",
    "import pymysql\n",
    "import time\n",
    "import math\n",
    "\n",
    "host = \"pms-rdstest-rds.xxxxxxxxxxxxxxxxxxx.ap-northeast-2.rds.amazonaws.com\"\n",
    "port = 3306\n",
    "username = \"admin\"\n",
    "database = \"pmstest\"\n",
    "password = \"xxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "client_id = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "client_secret = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "\n",
    "def main():\n",
    "\n",
    "    try:\n",
    "        conn = pymysql.connect(host, user=username, passwd=password, db=database, port=port, use_unicode=True, charset='utf8')\n",
    "        cursor = conn.cursor()\n",
    "    except:\n",
    "        logging.error(\"could not connect to rds\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    athena = boto3.client('athena')\n",
    "\n",
    "    query = \"\"\"\n",
    "        SELECT\n",
    "         artist_id,\n",
    "         AVG(danceability) AS danceability,\n",
    "         AVG(energy) AS energy,\n",
    "         AVG(loudness) AS loudness,\n",
    "         AVG(speechiness) AS speechiness,\n",
    "         AVG(instrumentalness) AS instrumentalness\n",
    "        FROM\n",
    "         top_tracks t1\n",
    "        JOIN\n",
    "         audio_features t2 ON t2.id = t1.id AND CAST(t1.dt AS DATE) = DATE('2020-06-24') AND CAST(t2.dt AS DATE) = DATE('2020-06-24')\n",
    "        GROUP BY t1.artist_id\n",
    "        LIMIT 10\n",
    "    \"\"\"\n",
    "\n",
    "    r = query_athena(query, athena)\n",
    "    results = get_query_result(r['QueryExecutionId'], athena)\n",
    "    artists = process_data(results)\n",
    "\n",
    "    query = \"\"\"\n",
    "        SELECT\n",
    "         MIN(danceability) AS danceability_min,\n",
    "         MAX(danceability) AS danceability_max,\n",
    "         MIN(energy) AS energy_min,\n",
    "         MAX(energy) AS energy_max,\n",
    "         MIN(loudness) AS loudness_min,\n",
    "         MAX(loudness) AS loudness_max,\n",
    "         MIN(speechiness) AS speechiness_min,\n",
    "         MAX(speechiness) AS speechiness_max,\n",
    "         MIN(instrumentalness) AS instrumentalness_min,\n",
    "         MAX(instrumentalness) AS instrumentalness_max\n",
    "        FROM\n",
    "         audio_features\n",
    "    \"\"\"\n",
    "    r = query_athena(query, athena)\n",
    "    results = get_query_result(r['QueryExecutionId'], athena)\n",
    "    avgs = process_data(results)[0]\n",
    "\n",
    "    metrics = ['danceability', 'energy', 'loudness', 'speechiness', 'instrumentalness']\n",
    "\n",
    "    for i in artists:\n",
    "        for j in artists:\n",
    "            dist = 0\n",
    "            for k in metrics:\n",
    "                x = float(i[k])\n",
    "                x_norm = normalize(x, float(avgs[k+'_min']), float(avgs[k+'_max']))\n",
    "                y = float(j[k])\n",
    "                y_norm = normalize(y, float(avgs[k+'_min']), float(avgs[k+'_max']))\n",
    "                dist += (x_norm-y_norm)**2\n",
    "\n",
    "            dist = math.sqrt(dist) ## euclidean distance\n",
    "\n",
    "            data = {\n",
    "                'artist_id': i['artist_id'],\n",
    "                'y_artist': j['artist_id'],\n",
    "                'distance': dist\n",
    "            }\n",
    "\n",
    "            insert_row(cursor, data, 'related_artists')\n",
    "\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "\n",
    "    return None\n",
    "\n",
    "def normalize(x, x_min, x_max):\n",
    "    normalized = (x-x_min) / (x_max-x_min)\n",
    "    return normalized\n",
    "\n",
    "def query_athena(query, athena):\n",
    "    response = athena.start_query_execution(\n",
    "        QueryString=query,\n",
    "        QueryExecutionContext={'Database': 'pms_gluedb_test'},\n",
    "        ResultConfiguration={\n",
    "            'OutputLocation': \"s3://pms-bucket-test/repair/\",\n",
    "            'EncryptionConfiguration': {'EncryptionOption': 'SSE_S3'}\n",
    "        }\n",
    "    )\n",
    "    return response\n",
    "\n",
    "def get_query_result(query_id, athena):\n",
    "    response = athena.get_query_execution(QueryExecutionId=str(query_id))\n",
    "    while response['QueryExecution']['Status']['State'] != 'SUCCEEDED':\n",
    "        if response['QueryExecution']['Status']['State'] == 'FAILED':\n",
    "            logging.error('QUERY FAILED')\n",
    "            break\n",
    "        time.sleep(5)\n",
    "        response = athena.get_query_execution(QueryExecutionId=str(query_id))\n",
    "    response = athena.get_query_results(QueryExecutionId=str(query_id),MaxResults=1000)\n",
    "    return response\n",
    "\n",
    "def process_data(results):\n",
    "    columns = [col['Label'] for col in results['ResultSet']['ResultSetMetadata']['ColumnInfo']]\n",
    "    listed_results = []\n",
    "    for res in results['ResultSet']['Rows'][1:]:\n",
    "        values = []\n",
    "        for field in res['Data']:\n",
    "            try:\n",
    "                values.append(list(field.values())[0])\n",
    "            except:\n",
    "                values.append(list(' '))\n",
    "        listed_results.append(dict(zip(columns, values)))\n",
    "    return listed_results\n",
    "\n",
    "def insert_row(cursor, data, table):\n",
    "    placeholders = ', '.join(['%s'] * len(data))\n",
    "    columns = ', '.join(data.keys())\n",
    "    key_placeholders = ', '.join(['{0}=%s'.format(k) for k in data.keys()])\n",
    "    sql = \"INSERT INTO %s ( %s ) VALUES ( %s ) ON DUPLICATE KEY UPDATE %s\" % (table, columns, placeholders, key_placeholders)\n",
    "    cursor.execute(sql, list(data.values())*2)\n",
    "    return None\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 코드가 실행이 완료되면 RDS로 돌아가서 related_artists 테이블에서 `select * from related_artists` 쿼리를 날리면 아래와 같이 유사도 정보 결과를 확인할 수 있다.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/41605276/85509081-4aedb800-b630-11ea-8134-7db43f633c7e.png)\n",
    "\n",
    "\n",
    "- 아래 쿼리와 같이 날려서 가장 유사도가 비슷한 아티스트 정보를 뽑을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT p1.name, p2.name, p1.url, p2.url, p2.distance FROM artists p1\n",
    "JOIN (SELECT t1.name, t1.url, t2.y_artist, t2.distance FROM artists t1 JOIN related_artists t2 ON t2.artist_id = t1.id) p2 ON p2.y_artist = p1.id\n",
    "WHERE distance != 0 ORDER BY p2.distance ASC LIMIT 3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/41605276/85510236-124ede00-b632-11ea-9049-ba9947851712.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
