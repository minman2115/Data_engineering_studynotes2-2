{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "Data_Engineering_TIL(20201008)\n",
    "\n",
    "#### # 참고자료\n",
    "\n",
    "1) Airflow에서 Task 병렬처리를 위한 환경설정을 셋팅하는 실습\n",
    "\n",
    "김영현님이 작성한 'Airflow를 이용한 데이터 Workflow 관리' 자료를 참고함\n",
    "\n",
    "2) 'Airflow 구조와 execution_date 이해하기' 블로그 글\n",
    "\n",
    "url : https://bomwo.cc/posts/execution_date/\n",
    "\n",
    "#### # airflow executor\n",
    "\n",
    "executor는 worker라고보 불리며 조건에 따라 여러가지 executor를 제공하고 있다.\n",
    "\n",
    "- sequentialexector(default)\n",
    "\n",
    "1) task 순차처리함\n",
    "\n",
    "2) sqlite를 backend로 설정 \n",
    "\n",
    "3) 아주 심플한 test용도로만 권장\n",
    "\n",
    "- localexecutor\n",
    "\n",
    "1) task 병렬 처리 가능 \n",
    "\n",
    "2) mysql이나 postgresql을 backend로 설정 \n",
    "\n",
    "3) task마다 subprocess를 생성한다.\n",
    "\n",
    "- celeryexecutor\n",
    "\n",
    "1) task를 여러 서버(node)에 분산 처리 가능 (cluster) \n",
    "\n",
    "2) celery backend (rabbitmq, redis, …) 설정이 필요함\n",
    "\n",
    "#### # Airflow에서 Task의 병렬 실행을 위한 celeryexecutor 셋팅조건\n",
    "\n",
    "1) 실제 Task를 실행하는 airflow의 worker를 sequential executor가 아닌 celery executor를 사용해야 함\n",
    "\n",
    "2) celery executor 사용을 위해서는 Broker 가 필요한데 이를 위해 RabbitMQ나 Redis가 필요함\n",
    "\n",
    "3) airflow의 meta store로 sqlite가 아닌 mysql이나 postgresql 을 사용해야 함\n",
    "\n",
    "#### # 실습내용\n",
    "\n",
    "** 실습환경 : Amazon linux AMI 2 \n",
    "\n",
    "step 1) Airflow 설치\n",
    "\n",
    "- 먼저 아래와 같이 airflow와 그것에 의존하는 프로그램들을 설치하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ec2-user@ip-10-1-10-239 ~]$ sudo yum update -y\n",
    "[ec2-user@ip-10-1-10-239 ~]$ sudo yum install python3 -y\n",
    "[ec2-user@ip-10-1-10-239 ~]$ sudo yum install gcc python3-devel -y\n",
    "\n",
    "# airflow 1.10.12 install\n",
    "[ec2-user@ip-10-1-10-239 ~]$ sudo pip3 install apache-airflow==1.10.12  --constraint \"https://raw.githubusercontent.com/apache/airflow/constraints-1.10.12/constraints-3.7.txt\"\n",
    "\n",
    "[ec2-user@ip-10-1-10-239 ~]$ sudo yum install mysql-devel -y\n",
    "[ec2-user@ip-10-1-10-239 ~]$ sudo pip3 install 'apache-airflow[mysql]'\n",
    "[ec2-user@ip-10-1-10-239 ~]$ sudo pip3 install 'apache-airflow[celery]'\n",
    "[ec2-user@ip-10-1-10-239 ~]$ sudo pip3 install boto3\n",
    "[ec2-user@ip-10-1-10-239 ~]$ aws configure\n",
    "AWS Access Key ID [None]: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "AWS Secret Access Key [None]: yyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyyy\n",
    "Default region name [None]: ap-northeast-2\n",
    "Default output format [None]: json\n",
    "    \n",
    "# Meta DB 구동\n",
    "[ec2-user@ip-10-1-10-239 ~]$ airflow initdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 주의사항 : 파이썬 라이브러리 의존도 때문인지 처음 설치할때 Error가 자주 발생했다. airflow에 의존하는 파이썬 라이브러리를 설치할때는 주의해서 설치해야한다. 예를 들어서 airflow initdb를 했을때 celery 모듈이 없다고 해서 그냥 `pip3 install celery ` 를 했다가 Error나서 하루 이상 헤매었다.  \n",
    "\n",
    "airflow에서 어떤 Extra module을 필요로 한다면 `pip3 install apache-airflow[모듈이름]` 으로 설치해봐야 한다.\n",
    "\n",
    "예시) \n",
    "\n",
    "`sudo pip3 install 'apache-airflow[mysql]'`\n",
    "\n",
    "`sudo pip3 install 'apache-airflow[celery]'`\n",
    "\n",
    "step 2) Mysql 설치 및 설정\n",
    "\n",
    "https://minman2115.github.io/DE_TIL134/ 참고할것\n",
    "\n",
    "step 3) Airflow에서 Mysql을 사용할 수 있도록 설정\n",
    "\n",
    "** 참고자료 : '[data] airflow 설치(DB: mysql)' 블로그글 참고 https://m.blog.naver.com/varkiry05/222018641877 \n",
    "\n",
    "먼저 mysql에 database와 계정을 생성한다.\n",
    "\n",
    "root 계정으로 접속해서 아래와 같이 database와 계정을 생성한다(이름, 비밀번호는 직접 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ec2-user@ip-10-1-10-23 ~]$ mysql -uroot -p\n",
    "Enter password:\n",
    "Welcome to the MySQL monitor.  Commands end with ; or \\g.\n",
    "Your MySQL connection id is 14\n",
    "Server version: 8.0.21 MySQL Community Server - GPL\n",
    "\n",
    "Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.\n",
    "\n",
    "Oracle is a registered trademark of Oracle Corporation and/or its\n",
    "affiliates. Other names may be trademarks of their respective\n",
    "owners.\n",
    "\n",
    "Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n",
    "\n",
    "mysql> create database airflow;\n",
    "Query OK, 1 row affected (0.01 sec)\n",
    "\n",
    "mysql> create user 'airflow'@'localhost' identified by 'MyNewStrongP@ssw0d!';\n",
    "Query OK, 0 rows affected (0.00 sec)\n",
    "\n",
    "mysql> ALTER USER 'airflow'@'localhost' IDENTIFIED WITH mysql_native_password BY 'MyNewStrongP@ssw0d!';\n",
    "Query OK, 0 rows affected (0.00 sec)\n",
    "\n",
    "mysql> grant all privileges on airflow.* to 'airflow'@'localhost';\n",
    "Query OK, 0 rows affected (0.00 sec)\n",
    "\n",
    "mysql> create user 'airflow'@'%' identified by 'MyNewStrongP@ssw0d!';\n",
    "Query OK, 0 rows affected (0.01 sec)\n",
    "\n",
    "mysql> ALTER USER 'airflow'@'%' IDENTIFIED WITH mysql_native_password BY 'MyNewStrongP@ssw0d!';\n",
    "Query OK, 0 rows affected (0.00 sec)\n",
    "\n",
    "mysql> grant all privileges on airflow.* to 'airflow'@'%';\n",
    "Query OK, 0 rows affected (0.00 sec)\n",
    "\n",
    "mysql> flush privileges;\n",
    "Query OK, 0 rows affected (0.01 sec)\n",
    "\n",
    "mysql> exit;\n",
    "Bye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mysql의 my.cnf 파일을 수정해줘야 한다.\n",
    "\n",
    "안그러면 airflow initdb 했을때 'Exception: Global variable explicit_defaults_for_timestamp needs to be on (1) for mysql' Error가 발생할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ec2-user@ip-10-1-10-23 airflow]$ sudo vim /etc/my.cnf\n",
    "# 하단에 아래 내용을 추가\n",
    "explicit_defaults_for_timestamp = 1\n",
    "max_allowed_packet = 30M\n",
    "\n",
    "[ec2-user@ip-10-1-10-23 airflow]$ sudo systemctl restart mysqld\n",
    "\n",
    "[ec2-user@ip-10-1-10-23 airflow]$ sudo systemctl status mysqld\n",
    "● mysqld.service - MySQL Server\n",
    "   Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled)\n",
    "   Active: active (running) since Thu 2020-10-08 07:36:23 UTC; 22s ago\n",
    "     Docs: man:mysqld(8)\n",
    "           http://dev.mysql.com/doc/refman/en/using-systemd.html\n",
    "  Process: 10133 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS)\n",
    " Main PID: 10157 (mysqld)\n",
    "   Status: \"Server is operational\"\n",
    "   CGroup: /system.slice/mysqld.service\n",
    "           └─10157 /usr/sbin/mysqld\n",
    "\n",
    "Oct 08 07:36:22 ip-10-1-10-23.ap-northeast-2.compute.internal systemd[1]: Starting MySQL Server...\n",
    "Oct 08 07:36:23 ip-10-1-10-23.ap-northeast-2.compute.internal systemd[1]: Started MySQL Server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 다음에 airflow에서 airflow.cfg를 다음과 같이 수정해줘야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ec2-user@ip-10-1-10-23 ~]$ cd ~/airflow\n",
    "\n",
    "[ec2-user@ip-10-1-10-23 airflow]$ ls\n",
    "airflow.cfg  airflow.db  airflow-webserver.pid  logs  unittests.cfg\n",
    "\n",
    "[ec2-user@ip-10-1-10-23 airflow]$ sudo vim airflow.cfg\n",
    "\n",
    "# sql_alchemy_conn = mysql://[ID]:[PASSWORD]@[IP]:3306/airflow\n",
    "sql_alchemy_conn = mysql://airflow:MyNewStrongP@ssw0d!@localhost:3306/airflow\n",
    "            \n",
    "# 만약 샘플데이터를 원하지 않는다면 airflow.cfg 파일 내 다음 옵션도 False로 변경해야한다\n",
    "load_examples = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "airflow 웹서버와 스케쥴러를 끄고 다음 명령어를 실행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ec2-user@ip-10-1-10-224 airflow]$ airflow initdb\n",
    "DB: mysql://airflow:***@localhost:3306/airflow\n",
    "[2020-10-08 09:24:48,497] {db.py:378} INFO - Creating tables\n",
    "INFO  [alembic.runtime.migration] Context impl MySQLImpl.\n",
    "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
    "INFO  [alembic.runtime.migration] Running upgrade  -> e3a246e0dc1, current schema\n",
    "INFO  [alembic.runtime.migration] Running upgrade e3a246e0dc1 -> 1507a7289a2f, create is_encrypted\n",
    "INFO  [alembic.runtime.migration] Running upgrade 1507a7289a2f -> 13eb55f81627, maintain history for compatibility with earlier migrations\n",
    "INFO  [alembic.runtime.migration] Running upgrade 13eb55f81627 -> 338e90f54d61, More logging into task_instance\n",
    "INFO  [alembic.runtime.migration] Running upgrade 338e90f54d61 -> 52d714495f0, job_id indices\n",
    "INFO  [alembic.runtime.migration] Running upgrade 52d714495f0 -> 502898887f84, Adding extra to Log\n",
    "INFO  [alembic.runtime.migration] Running upgrade 502898887f84 -> 1b38cef5b76e, add dagrun\n",
    "INFO  [alembic.runtime.migration] Running upgrade 1b38cef5b76e -> 2e541a1dcfed, task_duration\n",
    "INFO  [alembic.runtime.migration] Running upgrade 2e541a1dcfed -> 40e67319e3a9, dagrun_config\n",
    "INFO  [alembic.runtime.migration] Running upgrade 40e67319e3a9 -> 561833c1c74b, add password column to user\n",
    "INFO  [alembic.runtime.migration] Running upgrade 561833c1c74b -> 4446e08588, dagrun start end\n",
    "INFO  [alembic.runtime.migration] Running upgrade 4446e08588 -> bbc73705a13e, Add notification_sent column to sla_miss\n",
    "INFO  [alembic.runtime.migration] Running upgrade bbc73705a13e -> bba5a7cfc896, Add a column to track the encryption state of the 'Extra' field in connection\n",
    "INFO  [alembic.runtime.migration] Running upgrade bba5a7cfc896 -> 1968acfc09e3, add is_encrypted column to variable table\n",
    "INFO  [alembic.runtime.migration] Running upgrade 1968acfc09e3 -> 2e82aab8ef20, rename user table\n",
    "INFO  [alembic.runtime.migration] Running upgrade 2e82aab8ef20 -> 211e584da130, add TI state index\n",
    "INFO  [alembic.runtime.migration] Running upgrade 211e584da130 -> 64de9cddf6c9, add task fails journal table\n",
    "INFO  [alembic.runtime.migration] Running upgrade 64de9cddf6c9 -> f2ca10b85618, add dag_stats table\n",
    "INFO  [alembic.runtime.migration] Running upgrade f2ca10b85618 -> 4addfa1236f1, Add fractional seconds to mysql tables\n",
    "INFO  [alembic.runtime.migration] Running upgrade 4addfa1236f1 -> 8504051e801b, xcom dag task indices\n",
    "INFO  [alembic.runtime.migration] Running upgrade 8504051e801b -> 5e7d17757c7a, add pid field to TaskInstance\n",
    "INFO  [alembic.runtime.migration] Running upgrade 5e7d17757c7a -> 127d2bf2dfa7, Add dag_id/state index on dag_run table\n",
    "INFO  [alembic.runtime.migration] Running upgrade 127d2bf2dfa7 -> cc1e65623dc7, add max tries column to task instance\n",
    "INFO  [alembic.runtime.migration] Running upgrade cc1e65623dc7 -> bdaa763e6c56, Make xcom value column a large binary\n",
    "INFO  [alembic.runtime.migration] Running upgrade bdaa763e6c56 -> 947454bf1dff, add ti job_id index\n",
    "INFO  [alembic.runtime.migration] Running upgrade 947454bf1dff -> d2ae31099d61, Increase text size for MySQL (not relevant for other DBs' text types)\n",
    "INFO  [alembic.runtime.migration] Running upgrade d2ae31099d61 -> 0e2a74e0fc9f, Add time zone awareness\n",
    "INFO  [alembic.runtime.migration] Running upgrade d2ae31099d61 -> 33ae817a1ff4, kubernetes_resource_checkpointing\n",
    "INFO  [alembic.runtime.migration] Running upgrade 33ae817a1ff4 -> 27c6a30d7c24, kubernetes_resource_checkpointing\n",
    "INFO  [alembic.runtime.migration] Running upgrade 27c6a30d7c24 -> 86770d1215c0, add kubernetes scheduler uniqueness\n",
    "INFO  [alembic.runtime.migration] Running upgrade 86770d1215c0, 0e2a74e0fc9f -> 05f30312d566, merge heads\n",
    "INFO  [alembic.runtime.migration] Running upgrade 05f30312d566 -> f23433877c24, fix mysql not null constraint\n",
    "INFO  [alembic.runtime.migration] Running upgrade f23433877c24 -> 856955da8476, fix sqlite foreign key\n",
    "INFO  [alembic.runtime.migration] Running upgrade 856955da8476 -> 9635ae0956e7, index-faskfail\n",
    "INFO  [alembic.runtime.migration] Running upgrade 9635ae0956e7 -> dd25f486b8ea, add idx_log_dag\n",
    "INFO  [alembic.runtime.migration] Running upgrade dd25f486b8ea -> bf00311e1990, add index to taskinstance\n",
    "INFO  [alembic.runtime.migration] Running upgrade 9635ae0956e7 -> 0a2a5b66e19d, add task_reschedule table\n",
    "INFO  [alembic.runtime.migration] Running upgrade 0a2a5b66e19d, bf00311e1990 -> 03bc53e68815, merge_heads_2\n",
    "INFO  [alembic.runtime.migration] Running upgrade 03bc53e68815 -> 41f5f12752f8, add superuser field\n",
    "INFO  [alembic.runtime.migration] Running upgrade 41f5f12752f8 -> c8ffec048a3b, add fields to dag\n",
    "INFO  [alembic.runtime.migration] Running upgrade c8ffec048a3b -> dd4ecb8fbee3, Add schedule interval to dag\n",
    "INFO  [alembic.runtime.migration] Running upgrade dd4ecb8fbee3 -> 939bb1e647c8, task reschedule fk on cascade delete\n",
    "INFO  [alembic.runtime.migration] Running upgrade 939bb1e647c8 -> 6e96a59344a4, Make TaskInstance.pool not nullable\n",
    "INFO  [alembic.runtime.migration] Running upgrade 6e96a59344a4 -> d38e04c12aa2, add serialized_dag table\n",
    "Revision ID: xxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "Revises: xxxxxxxxxxxxxxxxxxxxxxx\n",
    "Create Date: 2019-08-01 14:39:35.616417\n",
    "INFO  [alembic.runtime.migration] Running upgrade d38e04c12aa2 -> b3b105409875, add root_dag_id to DAG\n",
    "INFO  [alembic.runtime.migration] Running upgrade 6e96a59344a4 -> 74effc47d867, change datetime to datetime2(6) on MSSQL tables\n",
    "INFO  [alembic.runtime.migration] Running upgrade 939bb1e647c8 -> 004c1210f153, increase queue name size limit\n",
    "INFO  [alembic.runtime.migration] Running upgrade c8ffec048a3b -> a56c9515abdc, Remove dag_stat table\n",
    "INFO  [alembic.runtime.migration] Running upgrade a56c9515abdc, 004c1210f153, 74effc47d867, b3b105409875 -> 08364691d074, Merge the four heads back together\n",
    "INFO  [alembic.runtime.migration] Running upgrade 08364691d074 -> fe461863935f, increase_length_for_connection_password\n",
    "INFO  [alembic.runtime.migration] Running upgrade fe461863935f -> 7939bcff74ba, Add DagTags table\n",
    "INFO  [alembic.runtime.migration] Running upgrade 7939bcff74ba -> a4c2fd67d16b, add pool_slots field to task_instance\n",
    "INFO  [alembic.runtime.migration] Running upgrade a4c2fd67d16b -> 852ae6c715af, Add RenderedTaskInstanceFields table\n",
    "INFO  [alembic.runtime.migration] Running upgrade 852ae6c715af -> 952da73b5eff, add dag_code table\n",
    "INFO  [alembic.runtime.migration] Running upgrade 952da73b5eff -> a66efa278eea, Add Precision to execution_date in RenderedTaskInstanceFields table\n",
    "INFO  [alembic.runtime.migration] Running upgrade a66efa278eea -> da3f683c3a5a, Add dag_hash Column to serialized_dag table\n",
    "WARNI [airflow.models.crypto] cryptography not found - values will not be stored encrypted.\n",
    "Done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xcom으로 전달되는 데이터의 크기 확장을 위해 컬럼 타입을 아래와 같이 변경한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ec2-user@ip-10-1-10-17 airflow]$ mysql -uroot -p\n",
    "Enter password: ## MyNewStrongP@ssw0d! 로 접속\n",
    "Welcome to the MySQL monitor.  Commands end with ; or \\g.\n",
    "Your MySQL connection id is 9\n",
    "Server version: 8.0.21 MySQL Community Server - GPL\n",
    "\n",
    "Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.\n",
    "\n",
    "Oracle is a registered trademark of Oracle Corporation and/or its\n",
    "affiliates. Other names may be trademarks of their respective\n",
    "owners.\n",
    "\n",
    "Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n",
    "\n",
    "mysql> alter table airflow.xcom modify value LONGBLOB;\n",
    "Query OK, 0 rows affected (0.05 sec)\n",
    "Records: 0  Duplicates: 0  Warnings: 0\n",
    "\n",
    "mysql> exit\n",
    "Bye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 3) RabbitMQ 설치 및 설정\n",
    "\n",
    "https://minman2115.github.io/DE_TIL135/ 를 참고해서 설치한다.\n",
    "\n",
    "\n",
    "설치를 완료하면 airflow에서 RabbitMQ를 사용할 수 있도록 아래와 같이 설정해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo rabbitmqctl add_user [아이디] [비번]\n",
    "[ec2-user@ip-10-1-10-40 ~]$ sudo rabbitmqctl add_user airflow airflow\n",
    "Creating user \"airflow\"\n",
    "\n",
    "[ec2-user@ip-10-1-10-40 ~]$ sudo rabbitmqctl add_vhost airflow_vhost\n",
    "Creating vhost \"airflow_vhost\"\n",
    "\n",
    "[ec2-user@ip-10-1-10-40 ~]$ sudo rabbitmqctl set_user_tags airflow airflow\n",
    "Setting tags for user \"airflow\" to [airflow]\n",
    "\n",
    "[ec2-user@ip-10-1-10-40 ~]$ sudo rabbitmqctl set_permissions -p airflow_vhost airflow \".*\" \".*\" \".*\"\n",
    "Setting permissions for user \"airflow\" in vhost \"airflow_vhost\"\n",
    "\n",
    "[ec2-user@ip-10-1-10-33 ~]$ sudo vim ~/airflow/airflow.cfg\n",
    "\n",
    "# executor를 default인 SequentialExecutor에서 CeleryExecutor로 변경\n",
    "executor = CeleryExecutor\n",
    "\n",
    "# db connection을 sqlite에서 mysql로 변경\n",
    "sql_alchemy_conn = mysql://airflow:MyNewStrongP@ssw0d!@localhost:3306/airflow\n",
    "\n",
    "# Celery broker URL을 rabbitmq로 설정\n",
    "broker_url = amqp://airflow:airflow@localhost:5672/airflow_vhost\n",
    "\n",
    "# Celery가 job을 수행한 결과를 저장한 db metastore 설정\n",
    "result_backend = db+mysql://airflow:MyNewStrongP@ssw0d!@localhost:3306/airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 4) airflow 구동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# webserver 구동\n",
    "[ec2-user@ip-10-1-10-239 ~]$ airflow webserver -p 8080\n",
    "  ____________       _____________\n",
    " ____    |__( )_________  __/__  /________      __\n",
    "____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\n",
    "___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\n",
    " _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\n",
    "[2020-10-09 08:57:18,603] {__init__.py:50} INFO - Using executor CeleryExecutor\n",
    "[2020-10-09 08:57:18,604] {dagbag.py:417} INFO - Filling up the DagBag from /home/ec2-user/airflow/dags\n",
    "Running the Gunicorn Server with:\n",
    "Workers: 4 sync\n",
    "Host: 0.0.0.0:8080\n",
    "Timeout: 120\n",
    "Logfiles: - -\n",
    "=================================================================\n",
    "[2020-10-09 08:57:19 +0000] [16042] [INFO] Starting gunicorn 20.0.4\n",
    "[2020-10-09 08:57:19 +0000] [16042] [INFO] Listening at: http://0.0.0.0:8080 (16042)\n",
    "[2020-10-09 08:57:19 +0000] [16042] [INFO] Using worker: sync\n",
    "[2020-10-09 08:57:19 +0000] [16047] [INFO] Booting worker with pid: 16047\n",
    "[2020-10-09 08:57:19 +0000] [16048] [INFO] Booting worker with pid: 16048\n",
    "[2020-10-09 08:57:19 +0000] [16049] [INFO] Booting worker with pid: 16049\n",
    "[2020-10-09 08:57:19 +0000] [16050] [INFO] Booting worker with pid: 16050\n",
    "[2020-10-09 08:57:20,744] {__init__.py:50} INFO - Using executor CeleryExecutor\n",
    "[2020-10-09 08:57:20,745] {dagbag.py:417} INFO - Filling up the DagBag from /home/ec2-user/airflow/dags\n",
    "[2020-10-09 08:57:20,760] {__init__.py:50} INFO - Using executor CeleryExecutor\n",
    "[2020-10-09 08:57:20,765] {dagbag.py:417} INFO - Filling up the DagBag from /home/ec2-user/airflow/dags\n",
    "[2020-10-09 08:57:20,913] {__init__.py:50} INFO - Using executor CeleryExecutor\n",
    "[2020-10-09 08:57:20,921] {dagbag.py:417} INFO - Filling up the DagBag from /home/ec2-user/airflow/dags\n",
    "[2020-10-09 08:57:20,940] {__init__.py:50} INFO - Using executor CeleryExecutor\n",
    "[2020-10-09 08:57:20,946] {dagbag.py:417} INFO - Filling up the DagBag from /home/ec2-user/airflow/dags\n",
    "\n",
    "# 위와 같이 웹서버를 구동하고 나서 웹브라우져로 이동한 다음 [ec2 server public ip]:8080 으로 접속하면 airflow WebUI화면을 확인할 수 있다.\n",
    "\n",
    "# 터미널 새 창을 열어서 아래 커맨드 입력\n",
    "# celeryExecutor는 별도 worker 실행이 필요하다\n",
    "[ec2-user@ip-10-1-10-239 airflow]$ airflow worker\n",
    "\n",
    " -------------- celery@ip-10-1-10-210.ap-northeast-2.compute.internal v4.4.7 (cliffs)\n",
    "--- ***** -----\n",
    "-- ******* ---- Linux-4.14.193-149.317.amzn2.x86_64-x86_64-with-glibc2.2.5 2020-10-10 08:16:42\n",
    "- *** --- * ---\n",
    "- ** ---------- [config]\n",
    "- ** ---------- .> app:         airflow.executors.celery_executor:0x7fba4e143550\n",
    "- ** ---------- .> transport:   amqp://airflow:**@localhost:5672/airflow_vhost\n",
    "- ** ---------- .> results:     mysql://airflow:**@localhost:3306/airflow\n",
    "- *** --- * --- .> concurrency: 16 (prefork)\n",
    "-- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)\n",
    "--- ***** -----\n",
    " -------------- [queues]\n",
    "                .> default          exchange=default(direct) key=default\n",
    "\n",
    "\n",
    "[tasks]\n",
    "  . airflow.executors.celery_executor.execute_command\n",
    "\n",
    "Starting flask\n",
    " * Serving Flask app \"airflow.bin.cli\" (lazy loading)\n",
    " * Environment: production\n",
    "   WARNING: This is a development server. Do not use it in a production deployment.\n",
    "   Use a production WSGI server instead.\n",
    " * Debug mode: off\n",
    "[2020-10-10 08:16:44,044] {_internal.py:122} INFO -  * Running on http://0.0.0.0:8793/ (Press CTRL+C to quit)\n",
    "[2020-10-10 08:16:44,133: INFO/MainProcess] Connected to amqp://airflow:**@127.0.0.1:5672/airflow_vhost\n",
    "[2020-10-10 08:16:44,142: INFO/MainProcess] mingle: searching for neighbors\n",
    "[2020-10-10 08:16:45,166: INFO/MainProcess] mingle: all alone\n",
    "[2020-10-10 08:16:45,192: INFO/MainProcess] celery@ip-10-1-10-210.ap-northeast-2.compute.internal ready.\n",
    "\n",
    "\n",
    "# 터미널 새 창을 열어서 아래 커맨드 입력\n",
    "# scheduler 구동. scheduler는 DAG들의 스케쥴링 및 실행을 담당한다.\n",
    "[ec2-user@ip-10-1-10-239 ~]$ airflow scheduler\n",
    "  ____________       _____________\n",
    " ____    |__( )_________  __/__  /________      __\n",
    "____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\n",
    "___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\n",
    " _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\n",
    "[2020-10-10 08:23:53,580] {__init__.py:51} INFO - Using executor SequentialExecutor\n",
    "[2020-10-10 08:23:53,586] {scheduler_job.py:1346} INFO - Starting the scheduler\n",
    "[2020-10-10 08:23:53,586] {scheduler_job.py:1354} INFO - Running execute loop for -1 seconds\n",
    "[2020-10-10 08:23:53,586] {scheduler_job.py:1355} INFO - Processing each file at most -1 times\n",
    "[2020-10-10 08:23:53,586] {scheduler_job.py:1358} INFO - Searching for files in /home/ec2-user/airflow/dags\n",
    "[2020-10-10 08:23:53,613] {scheduler_job.py:1360} INFO - There are 24 files in /home/ec2-user/airflow/dags\n",
    "[2020-10-10 08:23:53,613] {scheduler_job.py:1411} INFO - Resetting orphaned tasks for active dag runs\n",
    "[2020-10-10 08:23:53,624] {dag_processing.py:556} INFO - Launched DagFileProcessorManager with pid: 16107\n",
    "[2020-10-10 08:23:53,627] {settings.py:54} INFO - Configured default timezone <Timezone [UTC]>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
