{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "Data_Engineering_TIL(20201024)\n",
    "\n",
    "** 베스핀글로벌 최정민님의 'Apache Airflow(SPOF 구성) 및 Amazon EMR을 통한 빅데이터 워크플로 오케스트레이션 - private' 자료를 공부해서 실습한 내용입니다.\n",
    "\n",
    "[실습목표]\n",
    "\n",
    "아래와 같이 cloud native 서비스를 이용하여 airflow CeleryExecutor 아키텍처를 구현한다.\n",
    "\n",
    "(Airflow를 이용하여 transient EMR을 create 하고 terminate를 컨트롤 하는 부분은 생략)\n",
    "\n",
    "![4](https://user-images.githubusercontent.com/41605276/97101458-ebd4a880-16e0-11eb-982b-02b3d31ef9d5.png)\n",
    "\n",
    "[실습내용]\n",
    "\n",
    "#### STEP 1) VPC 생성\n",
    "\n",
    "콘솔에서 아래와 같이 VPC를 생성한다.\n",
    "\n",
    "- name : pms-oregon-vpc\n",
    "\n",
    "\n",
    "- IPv4 CIDR block : 10.0.0.0/16\n",
    "\n",
    "\n",
    "- IPv6 CIDR block : No IPv6 CIDR block\n",
    "\n",
    "\n",
    "- Tenancy : default\n",
    "\n",
    "그러면 아래와 같은 그림으로 vpc가 생성된다.\n",
    "\n",
    "참고로 자동으로 라우팅 테이블도 만들어졌다.\n",
    "\n",
    "![1](https://user-images.githubusercontent.com/41605276/97069119-cecca680-1608-11eb-8fa3-a7c3d0866037.png)\n",
    "\n",
    "\n",
    "** 생성후에 DNS hostnames를 활성화 해줘야 한다.\n",
    "\n",
    "#### STEP 2) subnet 생성\n",
    "\n",
    "콘솔에서 아래와 같이 public subnet, private subnet a와 c를 각각 생성해준다.\n",
    "\n",
    "\n",
    "1) public subnet\n",
    "\n",
    "\n",
    "- Name tag : pms-public-subnet\n",
    "\n",
    "\n",
    "- vpc : pms-oregon-vpc 선택\n",
    "\n",
    "\n",
    "- Availability Zone : No preference\n",
    "\n",
    "\n",
    "- IPv4 CIDR block : 10.0.1.0/24\n",
    "\n",
    "\n",
    "2) private subnet (AZ A)\n",
    "\n",
    "\n",
    "- Name tag : pms-private-subnet-a\n",
    "\n",
    "\n",
    "- vpc : pms-oregon-vpc 선택\n",
    "\n",
    "\n",
    "- Availability Zone : us-west-2a\n",
    "\n",
    "\n",
    "- IPv4 CIDR block : 10.0.2.0/24\n",
    "\n",
    "\n",
    "3) private subnet (AZ C)\n",
    "\n",
    "\n",
    "- Name tag : pms-private-subnet-c\n",
    "\n",
    "\n",
    "- vpc : pms-oregon-vpc 선택\n",
    "\n",
    "\n",
    "- Availability Zone : us-west-2c\n",
    "\n",
    "\n",
    "- IPv4 CIDR block : 10.0.3.0/24\n",
    "\n",
    "\n",
    "\n",
    "#### STEP 3) internet gateway 생성\n",
    "\n",
    "먼저 인터넷 게이트웨이를 아래와 같은 옵션으로 생성\n",
    "\n",
    "\n",
    "- Name tag : pms-ig-test\n",
    "\n",
    "\n",
    "그런 다음에 아래와 같이 `Attach to VPC` 를 클릭하고 `pms-oregon-vpc` attach 해준다.\n",
    "\n",
    "\n",
    "![2](https://user-images.githubusercontent.com/41605276/97069518-e9544f00-160b-11eb-8400-86be48323b5e.png)\n",
    "\n",
    "\n",
    "#### STEP 4) routing table setting\n",
    "\n",
    "VPC 생성시 자동으로 만들어진 route table 에 internet gateway를 등록해준다.\n",
    "\n",
    "route table 콘솔에 가서 VPC 생성시 자동으로 만들어진 route table을 검색해서 지정하고, 아래와 같이 셋팅해준다.\n",
    "\n",
    "(아니면 새로 route table을 생성해서 아래와 같이 셋팅해줘도 된다.)\n",
    "\n",
    "![3](https://user-images.githubusercontent.com/41605276/97069966-050d2480-160f-11eb-96f0-3cbde7ab3f6a.png)\n",
    "\n",
    "그리고 `subnet associations` 클릭 --> `Edit subnet associations` 클릭 --> `pms-public-subnet` 를 추가해준다.\n",
    "\n",
    "\n",
    "그런 다음에 `pms-route-table-for-private` 라는 이름으로 (vpc는 당연히 pms-oregon-vpc), private용으로 라우팅 테이블을 하나 더 만든다.\n",
    "\n",
    "\n",
    "마찬가지로 `subnet associations` 클릭 --> `Edit subnet associations` 클릭 --> `pms-private-subnet-a`와 `pms-private-subnet-c` 를 추가해준다.\n",
    "\n",
    "\n",
    "#### STEP 5) NAT gateway을 위한 EIP 생성\n",
    "\n",
    "`Elastic IPs` 메뉴 --> `Allocate Elastic IP address` 클릭 --> `Allocate` 클릭 --> `Edit Name`해서 pms-eip-test로 명명\n",
    "\n",
    "#### STEP 6) NAT gateway 생성\n",
    "\n",
    "아래와 같은 옵션으로 생성해준다.\n",
    "\n",
    "- Name : pms-ng-test\n",
    "\n",
    "\n",
    "- Subnet : pms-public-subnet\n",
    "\n",
    "\n",
    "- Elastic IP allocation ID : pms-eip-test\n",
    "\n",
    "그런 다음에 라우팅 테이블 메뉴로 가서 `pms-route-table-for-private`를 `edit routes`를 클릭한다.\n",
    "\n",
    "그런다음에 `pms-ng-test` nat gateway를 `0.0.0.0/0` 으로해서 추가해준다.\n",
    "\n",
    "\n",
    "#### STEP 7) security group 생성\n",
    "\n",
    "아래와 같이 세개의 security를 생성해준다.\n",
    "\n",
    "1) public subnet용 sg\n",
    "\n",
    "- Security group name : pms-sg-public\n",
    "\n",
    "\n",
    "- Description : pms-sg-public\n",
    "\n",
    "\n",
    "- VPC : pms-oregon-vpc\n",
    "\n",
    "\n",
    "- inbound rules 를 아래와 같이 하나 추가\n",
    "\n",
    "`Type : all traffic / source :  My IP / Description - optional : myhome ip`\n",
    "\n",
    "\n",
    "2) private subnet용 sg\n",
    "\n",
    "\n",
    "- Security group name : pms-sg-private\n",
    "\n",
    "\n",
    "- Description : pms-sg-private\n",
    "\n",
    "\n",
    "- VPC : pms-oregon-vpc\n",
    "\n",
    "\n",
    "- inbound rules 를 아래와 같이 3개를 추가\n",
    "\n",
    "\n",
    "`Type : all traffic / source :  My IP / Description - optional : myhome ip`\n",
    "\n",
    "\n",
    "`Type : all traffic / source :  10.0.0.0/16 / Description - optional : vpc ip range`\n",
    "\n",
    "\n",
    "3) EFS 용 sg\n",
    "\n",
    "- Security group name : pms-sg-efs\n",
    "\n",
    "\n",
    "- Description : pms-sg-EFS\n",
    "\n",
    "\n",
    "- VPC : pms-oregon-vpc\n",
    "\n",
    "\n",
    "- inbound rules 를 아래와 같이 3개를 추가\n",
    "\n",
    "\n",
    "`Type : TCP / port : 2049 / source : pms-sg-private / Description - optional : pms-sg-private sg`\n",
    "\n",
    "\n",
    "#### STEP 8) key pair 생성\n",
    "\n",
    "\n",
    "서버들이 사용할 키페어를 생성한다.\n",
    "\n",
    "- Name : pms-oregon-key\n",
    "\n",
    "\n",
    "#### STEP 9) Bastion server를 위한 EC2 생성\n",
    "\n",
    "- Name : pms-airflow-bastion\n",
    "\n",
    "\n",
    "- 운영체제 : Amazon linux AMI version 2\n",
    "\n",
    "\n",
    "- 네트워크 : pms-oregon-vpc 의 pms-public-subnet\n",
    "\n",
    "\n",
    "- volume : 30GB\n",
    "\n",
    "\n",
    "- 사양 : t3.micro\n",
    "\n",
    "\n",
    "- Auto-assign Public IP : enable\n",
    "\n",
    "\n",
    "- security group : pms-sg-public\n",
    "\n",
    "\n",
    "- key : pms-oregon-key\n",
    "\n",
    "\n",
    "베스천 생성 후 pms-sg-private 에 아래와 같이 시큐리티 인바운드 규칙을 추가해준다.\n",
    "\n",
    "\n",
    "`Type : all traffic / source :  [bastion public ip] / Description - optional : bastion ip`\n",
    "\n",
    "\n",
    "#### STEP 10) Airflow server를 위한 EC2 생성\n",
    "\n",
    "먼저 default 보안그룹에서 필요한 포트를 개방해주는 설정을 미리해준다.\n",
    "\n",
    "AZ A에 위치하는 airflow server\n",
    "\n",
    "- Name : pms-airflow-a\n",
    "\n",
    "\n",
    "- 운영체제 : Amazon linux AMI version 2\n",
    "\n",
    "\n",
    "- 네트워크 : pms-oregon-vpc 의 pms-private-subnet-a\n",
    "\n",
    "\n",
    "- volume : 30GB\n",
    "\n",
    "\n",
    "- 사양 : t3.large\n",
    "\n",
    "\n",
    "- Auto-assign Public IP : disable\n",
    "\n",
    "\n",
    "- security group : pms-sg-private\n",
    "\n",
    "\n",
    "- key : pms-oregon-key\n",
    "\n",
    "EC2를 생성해서 아래와 같이 bastion과 airflow 서버 접속테스트를 해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bastion에서 사용할 key를 bastion으로 전송\n",
    "# 54.185.194.206은 bastion의 public ip\n",
    "[local pc]$ scp -i pms-oregon-key.pem pms-oregon-key.pem ec2-user@54.185.194.206:~/\n",
    "pms-oregon-key.pem                                                                                   100% 1678     8.8KB/s   00:00\n",
    "    \n",
    "# bastion 접속\n",
    "[local pc]$ ssh -i pms-oregon-key.pem ec2-user@54.185.194.206\n",
    "Last login: Sat Oct 24 09:26:27 2020 from 1.233.58.248\n",
    "\n",
    "       __|  __|_  )\n",
    "       _|  (     /   Amazon Linux 2 AMI\n",
    "      ___|\\___|___|\n",
    "\n",
    "https://aws.amazon.com/amazon-linux-2/\n",
    "2 package(s) needed for security, out of 13 available\n",
    "Run \"sudo yum update\" to apply all updates.\n",
    "[ec2-user@ip-10-0-1-7 ~]$ ls\n",
    "pms-oregon-key.pem\n",
    "            \n",
    "[ec2-user@ip-10-0-1-7 ~]$ sudo chmod 0400 pms-oregon-key.pem\n",
    "            \n",
    "# pms-airflow-a 접속 테스트\n",
    "[ec2-user@ip-10-0-1-7 ~]$ ssh -i pms-oregon-key.pem ec2-user@10.0.2.91\n",
    "\n",
    "       __|  __|_  )\n",
    "       _|  (     /   Amazon Linux 2 AMI\n",
    "      ___|\\___|___|\n",
    "\n",
    "https://aws.amazon.com/amazon-linux-2/\n",
    "2 package(s) needed for security, out of 13 available\n",
    "Run \"sudo yum update\" to apply all updates.\n",
    "\n",
    "[ec2-user@ip-10-0-2-91 ~]$ exit\n",
    "logout\n",
    "Connection to 10.0.2.91 closed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 11) ELB 생성\n",
    "\n",
    "EC2 메뉴 클릭 --> Load Balancers 메뉴 클릭 --> create load balancer 클릭 --> Application Load Balancer 선택\n",
    "\n",
    "아래와 같은 옵션으로 생성\n",
    "\n",
    "\n",
    "- Name : pms-airflow-alb\n",
    "\n",
    "\n",
    "- Scheme : internal\n",
    "\n",
    "\n",
    "- Listeners : HTTP, 80\n",
    "\n",
    "\n",
    "- Availability Zones : pms-oregon-vpc 의 pms-private-subnet-a 와 pms-private-subnet-c\n",
    "\n",
    "\n",
    "- Step 2: Configure Security Settings은 HTTPS일 경우에 설정하므로 그냥 next 클릭해서 넘어간다.\n",
    "\n",
    "\n",
    "- sg : pms-sg-private\n",
    "\n",
    "\n",
    "- target group \n",
    "\n",
    "Name : pms-tg-alb , Health checks path : `/login/?next=http%3A%2F%2F[Bastion Public ip]%2Fhome`\n",
    "\n",
    "\n",
    "- Step 5: Register Targets\n",
    "\n",
    "\n",
    "pms-airflow-a를 `add to registered` 클릭\n",
    "\n",
    "\n",
    "ELB를 생성한 다음에 AWS 콘솔 좌측화면에  `Load Balancing의 Target Groups` 메뉴를 클릭 --> `pms-tg-alb` 클릭 --> `Attributes` 의 Edit 클릭 --> `stickiness` 박스 클릭 --> save\n",
    "\n",
    "\n",
    "그러면 이제부터 airflow 와 Bastion을 구동하면 상태검사를 시작할 수 있다. 그 전까지는 상태검사 fail 상태이다.\n",
    "\n",
    "\n",
    "#### STEP 12) RDS 생성\n",
    "\n",
    "\n",
    "아래와 같은 셋팅으로 RDS를 생성한다.\n",
    "\n",
    "\n",
    "먼저 아래와 같은 셋팅으로 Subnet groups 생성한다.\n",
    "\n",
    "\n",
    "- Name : pms-airflow-rds-subnet-group\n",
    "\n",
    "\n",
    "- Description : pms-airflow-rds-subnet-group\n",
    "\n",
    "\n",
    "- VPC : pms-oregon-vpc\n",
    "\n",
    "\n",
    "- Availability Zones : us-west-2a, us-west-2c\n",
    "\n",
    "\n",
    "- Subnets : pms-private-subnet-a, pms-private-subnet-c\n",
    "\n",
    "\n",
    "그런 다음에 아래와 같은 셋팅으로 RDS를 생성한다.\n",
    "\n",
    "\n",
    "1) 엔진 유형 : MySQL Aurora\n",
    "\n",
    "\n",
    "2) 에디션 : MySQL과 호환되는 Amazon Aurora\n",
    "\n",
    "\n",
    "3) 버전 : Aurora 2.09 (MySQL 5.7)\n",
    "\n",
    "\n",
    "5) 템플릿 : 프로덕션\n",
    "\n",
    "\n",
    "6) DB 인스턴스 식별자 : pms-airflow-rds\n",
    "\n",
    "\n",
    "7) 마스터 사용자 이름 : admin\n",
    "\n",
    "\n",
    "8) 마스터 암호 : 패스워드\n",
    "\n",
    "\n",
    "9) DB 인스턴스 클래스 : db.t3.small\n",
    "\n",
    "\n",
    "10) 다중 AZ 배포 : 대기 인스턴스를 생성하지 마십시오.\n",
    "\n",
    "\n",
    "11) Virtual Private Cloud(VPC) : pms-oregon-vpc\n",
    "\n",
    "\n",
    "12) subnet group : pms-airflow-rds-subnet-group\n",
    "\n",
    "\n",
    "13) security group : pms-sg-private\n",
    "\n",
    "\n",
    "14) 퍼블릭 액세스 가능 : 아니오\n",
    "\n",
    "\n",
    "15) 포트 : 3306\n",
    "\n",
    "\n",
    "그외의 옵션은 Default option\n",
    "\n",
    "\n",
    "#### STEP 13) ElastiCache 생성\n",
    "\n",
    "Elasticache 콘솔로 이동해서 아래와 같이 생성해준다.\n",
    "\n",
    "1) 왼쪽 사이드 바에서 [Redis] > [create] 클릭\n",
    "\n",
    "\n",
    "2) 클러스터 엔진 : Redis (클러스터 모드 활성화는 선택하지 않음)\n",
    "\n",
    "\n",
    "3) 위치선택 : Amazon 클라우드\n",
    "\n",
    "\n",
    "4) Name : pms-airflow-redis\n",
    "\n",
    "\n",
    "5) 엔진 버전 : 5.0.6\n",
    "\n",
    "\n",
    "6) 포트 번호 : 6379\n",
    "\n",
    "\n",
    "7) Node type : cache.r6g.large\n",
    "\n",
    "\n",
    "8) 복제본 갯수 : 0\n",
    "\n",
    "\n",
    "9) 다중 AZ : 체크 해제\n",
    "\n",
    "\n",
    "10) 서브넷 그룹 : 새로 생성\n",
    "\n",
    "\n",
    "Name, Description : pms-redis-subnet-group\n",
    "\n",
    "\n",
    "VPC : pms-oregon-vpc 의 pms-private-subnet-a 와 pms-private-subnet-c\n",
    "\n",
    "\n",
    "11) 보안그룹 : pms-sg-private\n",
    "\n",
    "\n",
    "나머지는 Default option으로 사용\n",
    "\n",
    "** 참고사항 \n",
    "\n",
    "Redis는 airflow.cfg 설정시 password를 요구하지만 현재 Redis 클러스터 생성할때는 password에 대한 설정은 없다. Redis 생성후 왼쪽 사이드바에서 `user management` 로 가서 create 클릭\n",
    "\n",
    "\n",
    "아래와 같이 생성\n",
    "\n",
    "\n",
    "- User id : redisairflowid\n",
    "\n",
    "\n",
    "- User name : redisairflow\n",
    "\n",
    "\n",
    "- password : 패스워드\n",
    "\n",
    "\n",
    "\n",
    "#### STEP 14) S3 생성\n",
    "\n",
    "oregon 으로해서 pms-oregon-bucket 이라는 이름으로 생성\n",
    "\n",
    "\n",
    "#### STEP 15) EFS 생성\n",
    "\n",
    "efs 콘솔가서 아래와 같이 efs를 생성한다.\n",
    "\n",
    "\n",
    "- Name : pms-airflow-efs\n",
    "\n",
    "\n",
    "- VPC : pms-oregon-vpc\n",
    "\n",
    "\n",
    "create 바로 하지말고 중간에 customize 클릭 사용자가 원하는 옵션을 아래와 같이 적용해서 생성\n",
    "\n",
    "\n",
    "VPC 설정: airflow 서버와 같은 VPC로 설정\n",
    "\n",
    "\n",
    "탑재 대상 설정 : airflow 서버가 있는 가용영역과 서브넷에 설정(해당 내용이 있어야 마운트 가능)\n",
    "\n",
    "\n",
    "보안그룹 : EFS 용으로 만든 SG를 선택\n",
    "\n",
    "\n",
    "** 참고사항 : VPC는 DNS 옵션이 활성화 되어있어야 함\n",
    "\n",
    "\n",
    "#### STEP 16) Airflow 서버 셋팅\n",
    "\n",
    "airflow server에 접속해서 아래와 같이 셋팅해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bastion 접속\n",
    "Last login: Sat Oct 24 09:28:34 2020 from 1.233.58.248\n",
    "\n",
    "       __|  __|_  )\n",
    "       _|  (     /   Amazon Linux 2 AMI\n",
    "      ___|\\___|___|\n",
    "\n",
    "https://aws.amazon.com/amazon-linux-2/\n",
    "2 package(s) needed for security, out of 13 available\n",
    "Run \"sudo yum update\" to apply all updates.\n",
    "            \n",
    "# 베스천에서 먼저 아래와 같이 nginx 설정을 해준다.\n",
    "[ec2-user@ip-10-0-1-235 ~]$ sudo yum update -y\n",
    "            \n",
    "[ec2-user@ip-10-0-1-235 ~]$ sudo amazon-linux-extras install nginx1 -y\n",
    "            \n",
    "[ec2-user@ip-10-0-1-235 ~]$ cd /etc/nginx/\n",
    "            \n",
    "[ec2-user@ip-10-0-1-235 nginx]$ sudo vim nginx.conf\n",
    "# 아래와 같이 server의 location 부분만 수정            \n",
    "    \n",
    "# For more information on configuration, see:\n",
    "#   * Official English Documentation: http://nginx.org/en/docs/\n",
    "#   * Official Russian Documentation: http://nginx.org/ru/docs/\n",
    "\n",
    "user nginx;\n",
    "worker_processes auto;\n",
    "error_log /var/log/nginx/error.log;\n",
    "pid /run/nginx.pid;\n",
    "\n",
    "# Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.\n",
    "include /usr/share/nginx/modules/*.conf;\n",
    "\n",
    "events {\n",
    "    worker_connections 1024;\n",
    "}\n",
    "\n",
    "http {\n",
    "    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n",
    "                      '$status $body_bytes_sent \"$http_referer\" '\n",
    "                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n",
    "\n",
    "    access_log  /var/log/nginx/access.log  main;\n",
    "\n",
    "    sendfile            on;\n",
    "    tcp_nopush          on;\n",
    "    tcp_nodelay         on;\n",
    "    keepalive_timeout   65;\n",
    "    types_hash_max_size 4096;\n",
    "\n",
    "    include             /etc/nginx/mime.types;\n",
    "    default_type        application/octet-stream;\n",
    "\n",
    "    # Load modular configuration files from the /etc/nginx/conf.d directory.\n",
    "    # See http://nginx.org/en/docs/ngx_core_module.html#include\n",
    "    # for more information.\n",
    "    include /etc/nginx/conf.d/*.conf;\n",
    "\n",
    "    server {\n",
    "        listen       80;\n",
    "        listen       [::]:80;\n",
    "        server_name  _;\n",
    "        root         /usr/share/nginx/html;\n",
    "\n",
    "        # Load configuration files for the default server block.\n",
    "        include /etc/nginx/default.d/*.conf;\n",
    "\n",
    "        location / {\n",
    "             proxy_redirect off;\n",
    "             proxy_pass_header Server;\n",
    "             proxy_set_header Host $http_host;\n",
    "             proxy_set_header X-Real-IP $remote_addr;\n",
    "             proxy_set_header X-Scheme $scheme;\n",
    "             # Bastion host로 접근하면 내부 ALB로 proxy pass\n",
    "             # proxy_pass http://[내부 ALB DNS]:80;\n",
    "             proxy_pass http://internal-pms-airflow-alb-969054821.us-west-2.elb.amazonaws.com:80;\n",
    "        }\n",
    "\n",
    "        error_page 404 /404.html;\n",
    "            location = /40x.html {\n",
    "        }\n",
    "\n",
    "        error_page 500 502 503 504 /50x.html;\n",
    "            location = /50x.html {\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Settings for a TLS enabled server.\n",
    "#\n",
    "#    server {\n",
    "#        listen       443 ssl http2;\n",
    "#        listen       [::]:443 ssl http2;\n",
    "#        server_name  _;\n",
    "#        root         /usr/share/nginx/html;\n",
    "#\n",
    "#        ssl_certificate \"/etc/pki/nginx/server.crt\";\n",
    "#        ssl_certificate_key \"/etc/pki/nginx/private/server.key\";\n",
    "#        ssl_session_cache shared:SSL:1m;\n",
    "#        ssl_session_timeout  10m;\n",
    "#        ssl_ciphers PROFILE=SYSTEM;\n",
    "#        ssl_prefer_server_ciphers on;\n",
    "#\n",
    "#        # Load configuration files for the default server block.\n",
    "#        include /etc/nginx/default.d/*.conf;\n",
    "#\n",
    "#        error_page 404 /404.html;\n",
    "#            location = /40x.html {\n",
    "#        }\n",
    "#\n",
    "#        error_page 500 502 503 504 /50x.html;\n",
    "#            location = /50x.html {\n",
    "#        }\n",
    "#    }\n",
    "\n",
    "}\n",
    "            \n",
    "# 엔진엑스 구동\n",
    "[ec2-user@ip-10-0-1-235 nginx]$ sudo service nginx start\n",
    "Redirecting to /bin/systemctl start nginx.service\n",
    "            \n",
    "[ec2-user@ip-10-0-1-235 nginx]$ cd ~\n",
    "            \n",
    "# 그런 다음에 pms-oregon-key를 갖고 airflow server a 접속한다.\n",
    "[ec2-user@ip-10-0-1-235 ~]$ ls\n",
    "pms-oregon-key.pem\n",
    "            \n",
    "# 추후에 SPOF 설정을 위해 키복사\n",
    "[ec2-user@ip-10-0-1-235 ~]$ cp pms-oregon-key.pem ~/.ssh/\n",
    "\n",
    "# 10.0.2.169 는 pms-airflow-a의 ip\n",
    "[ec2-user@ip-10-0-1-235 ~]$ sudo scp -i pms-oregon-key.pem pms-oregon-key.pem ec2-user@10.0.2.169:~/.ssh/\n",
    "The authenticity of host '10.0.2.169 (10.0.2.169)' can't be established.\n",
    "ECDSA key fingerprint is SHA256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx.\n",
    "ECDSA key fingerprint is MD5:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx.\n",
    "Are you sure you want to continue connecting (yes/no)? yes\n",
    "Warning: Permanently added '10.0.2.169' (ECDSA) to the list of known hosts.\n",
    "pms-oregon-key.pem                                                                                                                100% 1678   785.0KB/s   00:00\n",
    "\n",
    "# airflow server a 접속\n",
    "[ec2-user@ip-10-0-1-235 ~]$ ssh -i pms-oregon-key.pem ec2-user@10.0.2.91\n",
    "Last login: Sat Oct 24 09:34:03 2020 from 10.0.1.7\n",
    "\n",
    "       __|  __|_  )\n",
    "       _|  (     /   Amazon Linux 2 AMI\n",
    "      ___|\\___|___|\n",
    "\n",
    "https://aws.amazon.com/amazon-linux-2/\n",
    "2 package(s) needed for security, out of 13 available\n",
    "Run \"sudo yum update\" to apply all updates.\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 ~]$ sudo yum update -y\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 ~]$ sudo yum install python3 -y\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 ~]$ sudo yum install gcc python3-devel -y\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 ~]$ sudo pip3 install apache-airflow\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 ~]$ sudo pip3 install boto3\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 ~]$ aws configure\n",
    "AWS Access Key ID [None]: xxxxxxxxxxxxxxxxxxxxxx\n",
    "AWS Secret Access Key [None]: xxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "Default region name [None]: us-west-2\n",
    "Default output format [None]: json\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 ~]$ airflow initdb\n",
    "DB: sqlite:////home/ec2-user/airflow/airflow.db\n",
    "[2020-10-24 11:00:44,331] {db.py:378} INFO - Creating tables\n",
    "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
    "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
    "\n",
    "            ...\n",
    "            \n",
    "Done.\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 ~]$ sudo yum install -y https://dev.mysql.com/get/mysql80-community-release-el7-3.noarch.rpm\n",
    "Loaded plugins: extras_suggestions, langpacks, priorities, update-motd\n",
    "mysql80-community-release-el7-3.noarch.rpm                                                             |  25 kB  00:00:00\n",
    "Examining /var/tmp/yum-root-_ghXkL/mysql80-community-release-el7-3.noarch.rpm: mysql80-community-release-el7-3.noarch\n",
    "Marking /var/tmp/yum-root-_ghXkL/mysql80-community-release-el7-3.noarch.rpm to be installed\n",
    "Resolving Dependencies\n",
    "--> Running transaction check\n",
    "---> Package mysql80-community-release.noarch 0:el7-3 will be installed\n",
    "--> Finished Dependency Resolution\n",
    "amzn2-core/2/x86_64                                                                                    | 3.7 kB  00:00:00\n",
    "\n",
    "Dependencies Resolved\n",
    "\n",
    "==============================================================================================================================\n",
    " Package                             Arch             Version         Repository                                         Size\n",
    "==============================================================================================================================\n",
    "Installing:\n",
    " mysql80-community-release           noarch           el7-3           /mysql80-community-release-el7-3.noarch            31 k\n",
    "\n",
    "Transaction Summary\n",
    "==============================================================================================================================\n",
    "Install  1 Package\n",
    "\n",
    "Total size: 31 k\n",
    "Installed size: 31 k\n",
    "Downloading packages:\n",
    "Running transaction check\n",
    "Running transaction test\n",
    "Transaction test succeeded\n",
    "Running transaction\n",
    "  Installing : mysql80-community-release-el7-3.noarch                                                                     1/1\n",
    "  Verifying  : mysql80-community-release-el7-3.noarch                                                                     1/1\n",
    "\n",
    "Installed:\n",
    "  mysql80-community-release.noarch 0:el7-3\n",
    "\n",
    "Complete!\n",
    "\n",
    "[ec2-user@ip-10-0-2-91 ~]$ sudo yum repolist\n",
    "Loaded plugins: extras_suggestions, langpacks, priorities, update-motd\n",
    "37 packages excluded due to repository priority protections\n",
    "repo id                                                      repo name                                                  status\n",
    "amzn2-core/2/x86_64                                          Amazon Linux 2 core repository                             21,106\n",
    "amzn2extra-docker/2/x86_64                                   Amazon Extras repo for docker                                  28\n",
    "mysql-connectors-community/x86_64                            MySQL Connectors Community                                 138+37\n",
    "mysql-tools-community/x86_64                                 MySQL Tools Community                                         120\n",
    "mysql80-community/x86_64                                     MySQL 8.0 Community Server                                    211\n",
    "repolist: 21,603\n",
    "\n",
    "[ec2-user@ip-10-0-2-91 ~]$ sudo yum install -y mysql-community-server\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 ~]$ sudo systemctl enable --now mysqld\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 ~]$ systemctl status mysqld\n",
    "● mysqld.service - MySQL Server\n",
    "   Loaded: loaded (/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled)\n",
    "   Active: active (running) since Sat 2020-10-24 11:04:58 UTC; 9s ago\n",
    "     Docs: man:mysqld(8)\n",
    "           http://dev.mysql.com/doc/refman/en/using-systemd.html\n",
    "  Process: 8967 ExecStartPre=/usr/bin/mysqld_pre_systemd (code=exited, status=0/SUCCESS)\n",
    " Main PID: 9039 (mysqld)\n",
    "   Status: \"Server is operational\"\n",
    "   CGroup: /system.slice/mysqld.service\n",
    "           └─9039 /usr/sbin/mysqld\n",
    "\n",
    "Oct 24 11:04:51 ip-10-0-2-91.us-west-2.compute.internal systemd[1]: Starting MySQL Server...\n",
    "Oct 24 11:04:58 ip-10-0-2-91.us-west-2.compute.internal systemd[1]: Started MySQL Server.\n",
    "    \n",
    "[ec2-user@ip-10-0-2-91 ~]$ sudo yum install -y mysql-devel\n",
    "\n",
    "[ec2-user@ip-10-0-2-91 ~]$ sudo pip3 install 'apache-airflow[mysql]'\n",
    "            \n",
    "# mysql -u [admin username] -p -h [RDS Endpoint]\n",
    "[ec2-user@ip-10-0-2-91 ~]$ mysql -u admin -p -h pms-airflow-rds-instance-1.cbk472w8gsxf.us-west-2.rds.amazonaws.com\n",
    "Enter password: 패스워드 입력\n",
    "Welcome to the MySQL monitor.  Commands end with ; or \\g.\n",
    "Your MySQL connection id is 8\n",
    "Server version: 5.7.12 MySQL Community Server (GPL)\n",
    "\n",
    "Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.\n",
    "\n",
    "Oracle is a registered trademark of Oracle Corporation and/or its\n",
    "affiliates. Other names may be trademarks of their respective\n",
    "owners.\n",
    "\n",
    "Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n",
    "\n",
    "# RDS에 airflow metadb 생성\n",
    "mysql> create database airflow;\n",
    "Query OK, 1 row affected (0.02 sec)\n",
    "\n",
    "# RDS에 airflow 계정 생성\n",
    "# 로컬\n",
    "mysql> CREATE USER 'airflow'@'localhost' IDENTIFIED BY 'admin1!';\n",
    "Query OK, 0 rows affected (0.01 sec)\n",
    "\n",
    "# 리모트\n",
    "mysql> CREATE USER 'airflow'@'%' IDENTIFIED BY 'admin1!';\n",
    "Query OK, 0 rows affected (0.02 sec)\n",
    "\n",
    "# db에 대한 권한 부여\n",
    "mysql> GRANT ALL privileges on airflow.* to airflow@localhost;\n",
    "Query OK, 0 rows affected, 1 warning (0.02 sec)\n",
    "\n",
    "mysql> GRANT ALL privileges on airflow.* to airflow@'%';\n",
    "Query OK, 0 rows affected (0.02 sec)\n",
    "\n",
    "mysql> flush privileges;\n",
    "Query OK, 0 rows affected (0.00 sec)\n",
    "\n",
    "mysql> exit;\n",
    "Bye\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 ~]$ cd ~/airflow\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 airflow]$ mkdir dags\n",
    "\n",
    "[ec2-user@ip-10-0-2-91 airflow]$ ls\n",
    "airflow.cfg  airflow.db  dags  logs  unittests.cfg\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 airflow]$ sudo vim airflow.cfg\n",
    "\n",
    "아래와 부분을 수정\n",
    "            \n",
    "# sql_alchemy_conn = mysql://[ID]:[PASSWORD]@[rds endpoint]:3306/airflow\n",
    "sql_alchemy_conn = mysql://airflow:admin1!@pms-airflow-rds-instance-1.cbk472w8gsxf.us-west-2.rds.amazonaws.com:3306/airflow\n",
    "\n",
    "load_examples = False\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 airflow]$ airflow initdb\n",
    "DB: mysql://airflow:***@pms-airflow-rds-instance-1.cbk472w8gsxf.us-west-2.rds.amazonaws.com:3306/airflow\n",
    "[2020-10-24 11:27:49,828] {db.py:378} INFO - Creating tables\n",
    "INFO  [alembic.runtime.migration] Context impl MySQLImpl.\n",
    "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
    "            \n",
    "            ...\n",
    "            \n",
    "Done.\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 airflow]$ mysql -u admin -p -h pms-airflow-rds-instance-1.cbk472w8gsxf.us-west-2.rds.amazonaws.com\n",
    "Enter password: 패스워드 입력\n",
    "Welcome to the MySQL monitor.  Commands end with ; or \\g.\n",
    "Your MySQL connection id is 9\n",
    "Server version: 8.0.21 MySQL Community Server - GPL\n",
    "\n",
    "Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.\n",
    "\n",
    "Oracle is a registered trademark of Oracle Corporation and/or its\n",
    "affiliates. Other names may be trademarks of their respective\n",
    "owners.\n",
    "\n",
    "Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n",
    "\n",
    "mysql> alter table airflow.xcom modify value LONGBLOB;\n",
    "Query OK, 0 rows affected (0.05 sec)\n",
    "Records: 0  Duplicates: 0  Warnings: 0\n",
    "\n",
    "mysql> exit\n",
    "Bye\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 airflow]$ sudo pip3 install flask-bcrypt \n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 airflow]$ sudo vim airflow.cfg\n",
    "# 인증 설정을 아이디와 비밀번호로 설정\n",
    "# RBAC는 Role Base Access Control로서 Role에 따라 접근 권한을 설정\n",
    "\n",
    "아래의 부분을 수정\n",
    "\n",
    "[webserver]\n",
    "\n",
    "authenticate = True\n",
    "rbac = True            \n",
    "            \n",
    "[api]\n",
    "\n",
    "auth_backend = airflow.contrib.auth.backends.password_auth\n",
    "\n",
    "#############################  참고사항 ###############################################\n",
    "# 웹 인증을 사용할 경우 Airflow는 플라스크 관리자 기반 웹 UI 전용입니다. \n",
    "# RBAC 기능이있는 FAB 기반 웹 UI를 사용하는 경우 CLI 혹은 UI에서 계정 생성 가능합니다.\n",
    "# 단 최초 관리자 계정 생성은 CLI로만 진행 가능합니다.\n",
    "###############################################################################\n",
    "\n",
    "            \n",
    "# airflow 계정생성\n",
    "# 최초 인증설정 후에는 관리자 계정을 생성해야 웹서버의 문제가 없다.\n",
    "# 관리자 계정이 생성되면 웹서버를 반드시 재부팅 해야함\n",
    "# 웹서버가 실행 중이던 브라우저의 캐시를 날린 후 재 접속하면 로그인 화면에 접근할 수 있음\n",
    "\n",
    "# 관리자 계정 생성\n",
    "# airflow create_user -r [Role] -u [User Name] -e [Email Adress] -f [Family Name] -l [Last Name] -p [Password]\n",
    "[ec2-user@ip-10-0-2-91 airflow]$ airflow create_user -r Admin -u soojung.kim -e soojung.kim@itcompany.com -f soojung -l kim -p password1!\n",
    "[2020-10-24 11:38:19,381] {manager.py:710} WARNING - No user yet created, use flask fab command to do it.\n",
    "[2020-10-24 11:38:22,017] {__init__.py:50} INFO - Using executor SequentialExecutor\n",
    "[2020-10-24 11:38:22,017] {dagbag.py:417} INFO - Filling up the DagBag from /home/ec2-user/airflow/dags\n",
    "[2020-10-24 11:38:27,937] {security.py:477} INFO - Start syncing user roles.\n",
    "[2020-10-24 11:38:28,238] {security.py:209} INFO - Initializing permissions for role:Viewer in the database.\n",
    "[2020-10-24 11:38:28,865] {security.py:209} INFO - Initializing permissions for role:User in the database.\n",
    "[2020-10-24 11:38:29,486] {security.py:209} INFO - Initializing permissions for role:Op in the database.\n",
    "[2020-10-24 11:38:29,931] {security.py:387} INFO - Fetching a set of all permission, view_menu from FAB meta-table\n",
    "[2020-10-24 11:38:30,448] {security.py:330} INFO - Cleaning faulty perms\n",
    "Admin user soojung.kim created.\n",
    "       \n",
    "# 일반사용자 계정 생성\n",
    "[ec2-user@ip-10-0-2-91 airflow]$ airflow create_user -r User -u jisung.park -e jisung.park@manunited.com -f jisung -l park -p password1!\n",
    "[2020-10-24 11:41:12,037] {__init__.py:50} INFO - Using executor SequentialExecutor\n",
    "[2020-10-24 11:41:12,038] {dagbag.py:417} INFO - Filling up the DagBag from /home/ec2-user/airflow/dags\n",
    "[2020-10-24 11:41:12,775] {security.py:477} INFO - Start syncing user roles.\n",
    "[2020-10-24 11:41:13,280] {security.py:387} INFO - Fetching a set of all permission, view_menu from FAB meta-table\n",
    "[2020-10-24 11:41:13,639] {security.py:330} INFO - Cleaning faulty perms\n",
    "User user jisung.park created.\n",
    "            \n",
    "# FERNET_KEY 설정\n",
    "# Airflow는 기본적으로 meta DB에 password 정보를 평문으로 입력한다. 보안을 위해 Fernet 방식(Symmetric key)을 지원한다.\n",
    "# FERNET_KEY를 위한 플러그인 설치\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 airflow]$ sudo pip3 install 'apache-airflow[crypto]'\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 airflow]$ python3\n",
    "Python 3.7.9 (default, Aug 27 2020, 21:59:41)\n",
    "[GCC 7.3.1 20180712 (Red Hat 7.3.1-9)] on linux\n",
    "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
    ">>> from cryptography.fernet import Fernet\n",
    ">>> fernet_key= Fernet.generate_key()\n",
    ">>> print(fernet_key.decode())\n",
    "ZDwacVwTY8LKvlaAgqvTXafxDzXXwI3fIXqIBPKtX5w=   ## 이 비번을 복사\n",
    ">>> exit()\n",
    "\n",
    "[ec2-user@ip-10-0-2-91 airflow]$ sudo vim airflow.cfg\n",
    "\n",
    "아래와 같이 일부분 수정\n",
    "\n",
    "# Secret key to save connection passwords in the db\n",
    "fernet_key = ZDwacVwTY8LKvlaAgqvTXafxDzXXwI3fIXqIBPKtX5w= ## 위에서 복사한 비번\n",
    "\n",
    "############################ 역할별 권한 참고사항 ################################\n",
    "# Admin : 다른 사용자의 권한 부여 또는 취소를 포함하여 가능한 모든 권한\n",
    "# Public : 권한이 없음\n",
    "# Viewer : 제한된 뷰어 권한\n",
    "# User : Viewer권한과 추가 사용자 권한\n",
    "# Op : User권한과 추가 작업 권한\n",
    "###################################################################################\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 airflow]$ airflow initdb\n",
    "DB: mysql://airflow:***@pms-airflow-rds-instance-1.cbk472w8gsxf.us-west-2.rds.amazonaws.com:3306/airflow\n",
    "[2020-10-24 11:46:14,599] {db.py:378} INFO - Creating tables\n",
    "INFO  [alembic.runtime.migration] Context impl MySQLImpl.\n",
    "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
    "Done.\n",
    "\n",
    "[ec2-user@ip-10-0-2-91 airflow]$ airflow list_users\n",
    "[2020-10-24 11:46:35,488] {__init__.py:50} INFO - Using executor SequentialExecutor\n",
    "[2020-10-24 11:46:35,489] {dagbag.py:417} INFO - Filling up the DagBag from /home/ec2-user/airflow/dags\n",
    "[2020-10-24 11:46:36,294] {security.py:477} INFO - Start syncing user roles.\n",
    "[2020-10-24 11:46:36,870] {security.py:387} INFO - Fetching a set of all permission, view_menu from FAB meta-table\n",
    "[2020-10-24 11:46:37,257] {security.py:330} INFO - Cleaning faulty perms\n",
    "╒══════╤═════════════╤═══════════════════════════╤══════════════╤═════════════╤═════════╕\n",
    "│   Id │ Username    │ Email                     │ First name   │ Last name   │ Roles   │\n",
    "╞══════╪═════════════╪═══════════════════════════╪══════════════╪═════════════╪═════════╡\n",
    "│    1 │ soojung.kim │ soojung.kim@itcompany.com │ soojung      │ kim         │ [Admin] │\n",
    "├──────┼─────────────┼────────────────────────\n",
    "│    2 │ jisung.park │ jisung.park@manunited.com │ jisung       │ park        │ [User]  │\n",
    "╘══════╧═════════════╧═══════════════════════════╧══════════════╧═════════════╧═════════╛\n",
    "            \n",
    "            \n",
    "# S3에 로그 적재하도록 설정\n",
    "[ec2-user@ip-10-0-2-91 airflow]$ sudo vim airflow.cfg \n",
    "remote_logging = True\n",
    "remote_log_conn_id = MyS3Conn\n",
    "remote_base_log_folder = s3://pms-oregon-bucket/airflow_log/\n",
    "\n",
    "# airflow 서버에 EFS 마운트 \n",
    "# 먼저 관련된 플러그인 설치\n",
    "[ec2-user@ip-10-0-2-91 airflow]$ sudo yum install -y amazon-efs-utils\n",
    "            \n",
    "# sudo mount -t efs [EFS 파일 시스템 ID]:/ ~/airflow/dags            \n",
    "[ec2-user@ip-10-0-2-91 airflow]$ sudo mount -t efs fs-9ecb899b:/ ~/airflow/dags\n",
    "[ec2-user@ip-10-0-2-91 airflow]$ sudo chown ec2-user ~/airflow/dags\n",
    "\n",
    "\n",
    "# celery executor 설정\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 airflow]$ sudo pip3 install celery\n",
    "\n",
    "[ec2-user@ip-10-0-2-91 airflow]$ sudo pip3 install 'apache-airflow[redis]'\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 airflow]$ sudo pip3 install 'apache-airflow[celery]'\n",
    "\n",
    "[ec2-user@ip-10-0-2-91 airflow]$ sudo vim ~/airflow/airflow.cfg\n",
    "\n",
    "아래와 같은 부분을 수정\n",
    "\n",
    "executor = CeleryExecutor\n",
    "            \n",
    "# broker_url = redis://{액세스 문자열}@{Redis Endpoint}:6379/0\n",
    "broker_url = redis://off -@all@pms-airflow-redis.wwoqjw.0001.usw2.cache.amazonaws.com:6379/0\n",
    "            \n",
    "# result_backend = db+mysql://{DB username}:{DB password}@{DB Endpoint}/0\n",
    "result_backend = db+mysql://airflow:admin1!@pms-airflow-rds-instance-1.cbk472w8gsxf.us-west-2.rds.amazonaws.com:3306/airflow\n",
    "\n",
    "# airflow 디비갱신\n",
    "[ec2-user@ip-10-0-2-91 airflow]$ airflow initdb\n",
    "DB: mysql://airflow:***@pms-airflow-rds-instance-1.cbk472w8gsxf.us-west-2.rds.amazonaws.com:3306/airflow\n",
    "[2020-10-24 12:30:42,211] {db.py:378} INFO - Creating tables\n",
    "INFO  [alembic.runtime.migration] Context impl MySQLImpl.\n",
    "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
    "Done.\n",
    "            \n",
    "\n",
    "# nginx 다운로드 및 설정\n",
    "[ec2-user@ip-10-0-2-91 airflow]$ sudo amazon-linux-extras install nginx1 -y            \n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 airflow]$ cd /etc/nginx/\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 nginx]$ sudo vim nginx.conf\n",
    "\n",
    "# 아래와 같이 server의 location 부분만 수정 \n",
    "\n",
    "# For more information on configuration, see:\n",
    "#   * Official English Documentation: http://nginx.org/en/docs/\n",
    "#   * Official Russian Documentation: http://nginx.org/ru/docs/\n",
    "\n",
    "user nginx;\n",
    "worker_processes auto;\n",
    "error_log /var/log/nginx/error.log;\n",
    "pid /run/nginx.pid;\n",
    "\n",
    "# Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.\n",
    "include /usr/share/nginx/modules/*.conf;\n",
    "\n",
    "events {\n",
    "    worker_connections 1024;\n",
    "}\n",
    "\n",
    "http {\n",
    "    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n",
    "                      '$status $body_bytes_sent \"$http_referer\" '\n",
    "                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n",
    "\n",
    "    access_log  /var/log/nginx/access.log  main;\n",
    "\n",
    "    sendfile            on;\n",
    "    tcp_nopush          on;\n",
    "    tcp_nodelay         on;\n",
    "    keepalive_timeout   65;\n",
    "    types_hash_max_size 4096;\n",
    "\n",
    "    include             /etc/nginx/mime.types;\n",
    "    default_type        application/octet-stream;\n",
    "\n",
    "    # Load modular configuration files from the /etc/nginx/conf.d directory.\n",
    "    # See http://nginx.org/en/docs/ngx_core_module.html#include\n",
    "    # for more information.\n",
    "    include /etc/nginx/conf.d/*.conf;\n",
    "\n",
    "    server {\n",
    "        listen       80;\n",
    "        listen       [::]:80;\n",
    "        server_name  _;\n",
    "        root         /usr/share/nginx/html;\n",
    "\n",
    "        # Load configuration files for the default server block.\n",
    "        include /etc/nginx/default.d/*.conf;\n",
    "\n",
    "        location / {\n",
    "            proxy_pass http://localhost:8080;\n",
    "            # 해당 private ip:80으로 접근하면 localhost:8080으로 proxy\n",
    "            # airflow의 Base_url이 http://localhost:8080이 되는것임\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_redirect off;\n",
    "            proxy_http_version 1.1;\n",
    "            proxy_set_header Upgrade $http_upgrade;\n",
    "            proxy_set_header Connection \"upgrade\";\n",
    "        }\n",
    "\n",
    "        error_page 404 /404.html;\n",
    "            location = /40x.html {\n",
    "        }\n",
    "\n",
    "        error_page 500 502 503 504 /50x.html;\n",
    "            location = /50x.html {\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Settings for a TLS enabled server.\n",
    "#\n",
    "#    server {\n",
    "#        listen       443 ssl http2;\n",
    "#        listen       [::]:443 ssl http2;\n",
    "#        server_name  _;\n",
    "#        root         /usr/share/nginx/html;\n",
    "#\n",
    "#        ssl_certificate \"/etc/pki/nginx/server.crt\";\n",
    "#        ssl_certificate_key \"/etc/pki/nginx/private/server.key\";\n",
    "#        ssl_session_cache shared:SSL:1m;\n",
    "#        ssl_session_timeout  10m;\n",
    "#        ssl_ciphers PROFILE=SYSTEM;\n",
    "#        ssl_prefer_server_ciphers on;\n",
    "#\n",
    "#        # Load configuration files for the default server block.\n",
    "#        include /etc/nginx/default.d/*.conf;\n",
    "#\n",
    "#        error_page 404 /404.html;\n",
    "#            location = /40x.html {\n",
    "#        }\n",
    "#\n",
    "#        error_page 500 502 503 504 /50x.html;\n",
    "#            location = /50x.html {\n",
    "#        }\n",
    "#    }\n",
    "\n",
    "}            \n",
    "            \n",
    "# config를 수정후 nginx start\n",
    "[ec2-user@ip-10-0-2-91 nginx]$ sudo service nginx start\n",
    "Redirecting to /bin/systemctl start nginx.service                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기까지 진행하고 airflow-a를 AMI 이미지를 떠서 아래와 같은 옵션으로 띄운다.\n",
    "\n",
    "pms-airflow-a를 create image한다.\n",
    "\n",
    "- Image name : pms-airflow-image\n",
    "\n",
    "그런 다음에 pms-airflow-image를 갖고 pms-airflow-c를 아래와 같은 옵션으로 구동한다.\n",
    "\n",
    "AZ C에 위치하는 airflow server\n",
    "\n",
    "- Name : pms-airflow-c\n",
    "\n",
    "\n",
    "- 운영체제 : Amazon linux AMI version 2\n",
    "\n",
    "\n",
    "- 네트워크 : pms-oregon-vpc 의 pms-private-subnet-c\n",
    "\n",
    "\n",
    "- volume : 30GB\n",
    "\n",
    "\n",
    "- 사양 : t3.large\n",
    "\n",
    "\n",
    "- Auto-assign Public IP : disable\n",
    "\n",
    "\n",
    "- security group : pms-sg-private\n",
    "\n",
    "\n",
    "- key : pms-oregon-key\n",
    "\n",
    "\n",
    "생성한 다음에 ELB로가서 pms-airflow-c를 target으로 등록해준다.\n",
    "\n",
    "\n",
    "그런 다음에 베스천에 접속해서 아래와 같이 명령어를 실행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이미지를 뜨면서 airflow-a 와 세션이 끊겼기 때문에 다시 airflow-a서버로 접속한다.\n",
    "[ec2-user@ip-10-0-1-235 ~]$ ssh -i pms-oregon-key.pem ec2-user@10.0.2.91\n",
    "Last login: Sun Oct 25 09:08:36 2020 from ip-10-0-1-235.us-west-2.compute.internal\n",
    "\n",
    "       __|  __|_  )\n",
    "       _|  (     /   Amazon Linux 2 AMI\n",
    "      ___|\\___|___|\n",
    "\n",
    "https://aws.amazon.com/amazon-linux-2/\n",
    "            \n",
    "# 엔진엑스 구동\n",
    "[ec2-user@ip-10-0-2-91 airflow]$ sudo service nginx start\n",
    "Redirecting to /bin/systemctl start nginx.service            \n",
    "            \n",
    "## airflow 서비스를 구동한다.\n",
    "[ec2-user@ip-10-0-2-91 airflow]$ airflow webserver -p 8080\n",
    "  ____________       _____________\n",
    " ____    |__( )_________  __/__  /________      __\n",
    "____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\n",
    "___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\n",
    " _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\n",
    "[2020-10-24 12:31:23,510] {__init__.py:50} INFO - Using executor CeleryExecutor\n",
    "[2020-10-24 12:31:23,511] {dagbag.py:417} INFO - Filling up the DagBag from /dev/null\n",
    "[2020-10-24 12:31:24,253] {security.py:477} INFO - Start syncing user roles.\n",
    "[2020-10-24 12:31:24,782] {security.py:387} INFO - Fetching a set of all permission, view_menu from FAB meta-table\n",
    "[2020-10-24 12:31:25,152] {security.py:330} INFO - Cleaning faulty perms\n",
    "Running the Gunicorn Server with:\n",
    "Workers: 4 sync\n",
    "Host: 0.0.0.0:8080\n",
    "Timeout: 120\n",
    "Logfiles: - -\n",
    "=================================================================\n",
    "[2020-10-24 12:31:25 +0000] [12694] [INFO] Starting gunicorn 20.0.4\n",
    "[2020-10-24 12:31:25 +0000] [12694] [INFO] Listening at: http://0.0.0.0:8080 (12694)\n",
    "[2020-10-24 12:31:25 +0000] [12694] [INFO] Using worker: sync\n",
    "[2020-10-24 12:31:25 +0000] [12697] [INFO] Booting worker with pid: 12697\n",
    "[2020-10-24 12:31:25 +0000] [12698] [INFO] Booting worker with pid: 12698\n",
    "[2020-10-24 12:31:25 +0000] [12699] [INFO] Booting worker with pid: 12699\n",
    "[2020-10-24 12:31:26 +0000] [12700] [INFO] Booting worker with pid: 12700\n",
    "[2020-10-24 12:31:28,117] {__init__.py:50} INFO - Using executor CeleryExecutor\n",
    "[2020-10-24 12:31:28,125] {dagbag.py:417} INFO - Filling up the DagBag from /home/ec2-user/airflow/dags\n",
    "[2020-10-24 12:31:28,623] {__init__.py:50} INFO - Using executor CeleryExecutor\n",
    "[2020-10-24 12:31:28,624] {dagbag.py:417} INFO - Filling up the DagBag from /home/ec2-user/airflow/dags\n",
    "[2020-10-24 12:31:28,659] {__init__.py:50} INFO - Using executor CeleryExecutor\n",
    "[2020-10-24 12:31:28,660] {dagbag.py:417} INFO - Filling up the DagBag from /home/ec2-user/airflow/dags\n",
    "[2020-10-24 12:31:28,789] {__init__.py:50} INFO - Using executor CeleryExecutor\n",
    "[2020-10-24 12:31:28,789] {dagbag.py:417} INFO - Filling up the DagBag from /home/ec2-user/airflow/dags\n",
    "\n",
    "...\n",
    "            \n",
    "# 터미널 하나 또 열어서 아래와 같이 실행\n",
    "[ec2-user@ip-10-0-2-91 ~]$ airflow scheduler\n",
    "  ____________       _____________\n",
    " ____    |__( )_________  __/__  /________      __\n",
    "____  /| |_  /__  ___/_  /_ __  /_  __ \\_ | /| / /\n",
    "___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /\n",
    " _/_/  |_/_/  /_/    /_/    /_/  \\____/____/|__/\n",
    "[2020-10-24 12:33:09,670] {__init__.py:50} INFO - Using executor CeleryExecutor\n",
    "[2020-10-24 12:33:09,683] {scheduler_job.py:1367} INFO - Starting the scheduler\n",
    "[2020-10-24 12:33:09,684] {scheduler_job.py:1375} INFO - Running execute loop for -1 seconds\n",
    "[2020-10-24 12:33:09,684] {scheduler_job.py:1376} INFO - Processing each file at most -1 times\n",
    "[2020-10-24 12:33:09,684] {scheduler_job.py:1379} INFO - Searching for files in /home/ec2-user/airflow/dags\n",
    "[2020-10-24 12:33:09,686] {scheduler_job.py:1381} INFO - There are 0 files in /home/ec2-user/airflow/dags\n",
    "[2020-10-24 12:33:09,686] {scheduler_job.py:1438} INFO - Resetting orphaned tasks for active dag runs\n",
    "[2020-10-24 12:33:09,702] {dag_processing.py:562} INFO - Launched DagFileProcessorManager with pid: 12776\n",
    "[2020-10-24 12:33:09,706] {settings.py:55} INFO - Configured default timezone <Timezone [UTC]>\n",
    "\n",
    "# 터미널 하나 또 열어서 아래와 같이 실행\n",
    "[ec2-user@ip-10-0-2-91 airflow]$ airflow worker\n",
    "\n",
    " -------------- celery@ip-10-0-2-91.us-west-2.compute.internal v4.4.7 (cliffs)\n",
    "--- ***** -----\n",
    "-- ******* ---- Linux-4.14.193-149.317.amzn2.x86_64-x86_64-with-glibc2.2.5 2020-10-24 13:04:35\n",
    "- *** --- * ---\n",
    "- ** ---------- [config]\n",
    "- ** ---------- .> app:         airflow.executors.celery_executor:0x7f9259419310\n",
    "- ** ---------- .> transport:   redis://on%20~%2A%20%2B%40all@pms-airflow-redis.wwoqjw.0001.usw2.cache.amazonaws.com:6379/0\n",
    "- ** ---------- .> results:     mysql://airflow:**@pms-airflow-rds-instance-1.cbk472w8gsxf.us-west-2.rds.amazonaws.com:3306/airflow\n",
    "- *** --- * --- .> concurrency: 16 (prefork)\n",
    "-- ******* ---- .> task events: OFF (enable -E to monitor tasks in this worker)\n",
    "--- ***** -----\n",
    " -------------- [queues]\n",
    "                .> default          exchange=default(direct) key=default\n",
    "\n",
    "\n",
    "[tasks]\n",
    "  . airflow.executors.celery_executor.execute_command\n",
    "\n",
    "Starting flask\n",
    "           \n",
    "            \n",
    "# 터미널 하나 또 열어서 아래와 같이 실행\n",
    "[ec2-user@ip-10-0-2-91 airflow]$ airflow flower\n",
    "[I 201024 12:55:41 command:140] Visit me at http://0.0.0.0:5555\n",
    "[I 201024 12:55:41 command:145] Broker: redis://on%20~%2A%20%2B%40all@pms-airflow-redis.wwoqjw.0001.usw2.cache.amazonaws.com:6379/0\n",
    "[I 201024 12:55:41 command:148] Registered tasks:\n",
    "    ['celery.accumulate',\n",
    "     'celery.backend_cleanup',\n",
    "     'celery.chain',\n",
    "     'celery.chord',\n",
    "     'celery.chord_unlock',\n",
    "     'celery.chunks',\n",
    "     'celery.group',\n",
    "     'celery.map',\n",
    "     'celery.starmap']\n",
    "[I 201024 12:55:41 mixins:229] Connected to redis://on%20~%2A%20%2B%40all@pms-airflow-redis.wwoqjw.0001.usw2.cache.amazonaws.com:6379/0\n",
    "\n",
    "            \n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마찬가지로 airflow-c에도 접속해서 airflow 서비스들을 구동시킨다.\n",
    "\n",
    "그런 다음에 airflow-a와 c 모두에서 아래와 같이 설정을 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPOF 설정\n",
    "# 위의 내용중에 Bastion에서 Bastion host의 ~/.ssh/에 airflow server pem key를 복사해 놓았고, airflow-a와 c에도 키를 복사해놨다.\n",
    "# airflow serverA와 serverB가 능동적인 통신을 하기 위해 두 서버에 모두 pem key가 필요한 것이었다.\n",
    "# 그러면 airflow-a와 c 두곳 모두에서 아래와 같이 설정해주자.\n",
    "\n",
    "# # {AIRFLOW_HOME}에 airflow-scheduler-failover-controller라는 툴을 github에서 다운받아 적용할 것이다.\n",
    "[ec2-user@ip-10-0-2-91 nginx]$ cd ~/airflow\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 airflow]$ sudo yum install -y git\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 airflow]$ sudo pip3 install git+https://github.com/teamclairvoyant/airflow-scheduler-failover-controller.git@v1.0.5            \n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 airflow]$ scheduler_failover_controller init\n",
    "Adding Scheduler Failover configs to Airflow config file...\n",
    "Finished adding Scheduler Failover configs to Airflow config file.\n",
    "Finished Initializing Configurations to allow Scheduler Failover Controller to run. Please update the airflow.cfg with your desired configurations.\n",
    "            \n",
    "[ec2-user@ip-10-0-2-91 airflow]$ sudo vim ~/airflow/airflow.cfg\n",
    "\n",
    "아래와 같이 scheduler_nodes_in_cluster 부분을 수정해준다.\n",
    "\n",
    "[scheduler_failover]\n",
    "\n",
    "scheduler_nodes_in_cluster = [다른 airflow server IP]            \n",
    "            \n",
    "\n",
    "# 그런 다음에 scheduler 서버끼리 ssh 터널링이 가능하도록 ssh 키 작업을 해줘야 한다.\n",
    "# scheduler를 동작시킬 webserver1,2 가 있다면 ssh를 통해 webserver 1->2로, webserver 2->1 로 접근 가능하도록 설정해야 한다.\n",
    "# 아래의 명령어 실행하면(실행후 엔터를 세번 누르자) ~/.ssh/에 id_rsa.pub이 생성된다.\n",
    "# airflow-a와 airflow-c를 모두 아래와 같이 설정해준다.\n",
    "[ec2-user@ip-10-0-2-91 airflow]$ cd ~\n",
    "\n",
    "[ec2-user@ip-10-0-2-91 ~]$ ssh-keygen -t rsa\n",
    "Generating public/private rsa key pair.\n",
    "Enter file in which to save the key (/home/ec2-user/.ssh/id_rsa):\n",
    "Enter passphrase (empty for no passphrase):\n",
    "Enter same passphrase again:\n",
    "Your identification has been saved in /home/ec2-user/.ssh/id_rsa.\n",
    "Your public key has been saved in /home/ec2-user/.ssh/id_rsa.pub.\n",
    "The key fingerprint is:\n",
    "SHA256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxx ec2-user@ip-10-0-2-15.us-west-2.compute.internal\n",
    "The key's randomart image is:\n",
    "+---[RSA 2048]----+\n",
    "|                  |\n",
    "+----[SHA256]-----+\n",
    "\n",
    "[ec2-user@ip-10-0-2-91 ~]$ cd ~/.ssh/\n",
    "\n",
    "# cat ~/.ssh/id_rsa.pub | sudo ssh -i [pem key] ec2-user@[다른 airflow server IP] \"cat >>  ~/.ssh/authorized_keys\"\n",
    "[ec2-user@ip-10-0-2-91 .ssh]$ sudo cat ~/.ssh/id_rsa.pub | sudo ssh -i pms-oregon-key.pem ec2-user@[상대방 airflow ip] \"cat >>  ~/.ssh/authorized_keys\"\n",
    "\n",
    "# scheduler_failover_controller 정상작동여부 확인\n",
    "[ec2-user@ip-10-0-2-15 .ssh]$ scheduler_failover_controller test_connection\n",
    "Testing Connection for host '10.0.3.20'\n",
    "The authenticity of host '10.0.3.20 (10.0.3.20)' can't be established.\n",
    "ECDSA key fingerprint is SHA256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx.\n",
    "ECDSA key fingerprint is MD5:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx.\n",
    "Are you sure you want to continue connecting (yes/no)? yes\n",
    "(True, [\"Warning: Permanently added '10.0.3.20' (ECDSA) to the list of known hosts.\\r\\n\", 'Connection Succeeded\\n'])\n",
    "\n",
    "# airflow-a와 c 모두 scheduler_failover_controller를 구동시키면 모든 구현이 완료된다.\n",
    "[ec2-user@ip-10-0-2-91 .ssh]$ scheduler_failover_controller start\n",
    "[2020-10-25 10:25:20,487] {app.py:26} INFO - Scheduler Failover Controller Starting Up!\n",
    "[2020-10-25 10:25:20,487] {app.py:29} INFO - Current Host: ip-10-0-2-15.us-west-2.compute.internal\n",
    "[2020-10-25 10:25:20,487] {sql_metadata_service.py:33} INFO - Creating Metadata Table\n",
    "[2020-10-25 10:25:20,543] {failover_controller.py:30} INFO - --------------------------------------\n",
    "[2020-10-25 10:25:20,544] {failover_controller.py:31} INFO - Started Polling...\n",
    "[2020-10-25 10:25:20,585] {failover_controller.py:37} INFO - Active Failover Node: ip-10-0-3-20.us-west-2.compute.internal\n",
    "[2020-10-25 10:25:20,585] {failover_controller.py:38} INFO - Active Scheduler Node: 10.0.2.15\n",
    "[2020-10-25 10:25:20,586] {failover_controller.py:39} INFO - Last Failover Heartbeat: 2020-10-25 10:25:14. Current time: 2020-10-25 10:25:20.585683.\n",
    "[2020-10-25 10:25:20,586] {failover_controller.py:43} INFO - This Failover Controller is on Standby.\n",
    "[2020-10-25 10:25:20,586] {failover_controller.py:46} INFO - There already is an active Failover Controller 'ip-10-0-3-20.us-west-2.compute.internal'\n",
    "[2020-10-25 10:25:20,586] {failover_controller.py:133} INFO - This Failover Controller on STANDBY\n",
    "[2020-10-25 10:25:20,586] {app.py:36} INFO - Finished Polling. Sleeping for 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[bastion public ip]` 로 웹브라우저에서 접속하면 아래와 같이 airflow 로그인 화면이 나오고 우리가 위에서 생성한 아이디로 접속을 할 수 있다.\n",
    "\n",
    "bastion public ip 로 접속하면 URL이 `http://[bastion public ip]/login/?next=http%3A%2F%2F[bastion public ip]%2Fhome` 형태가 된다.\n",
    "\n",
    "그리고 ELB 의 target group 콘솔메뉴로 가면 두 노드의 상태가 healthy한 것도 확인할 수 있다.\n",
    "\n",
    "![5](https://user-images.githubusercontent.com/41605276/97104664-ff8c0900-16f8-11eb-9a7d-1c5093a064cd.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
