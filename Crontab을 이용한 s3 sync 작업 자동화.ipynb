{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "Data_Engineering_TIL(20200524)\n",
    "\n",
    "#### [구현 목표]\n",
    "\n",
    "![1111](https://user-images.githubusercontent.com/41605276/82745709-69a72780-9dc2-11ea-93e7-3d9935a47dd5.png)\n",
    "\n",
    "STEP 1) 특정 s3 bucket 간 s3 sync 명령을 실행하는 python script(test.py) 작성 및 crontab 등록\n",
    "\n",
    "** 빠른 테스트 결과 확인을 위해 매분 실행하는 것으로 크론텝 설정\n",
    "\n",
    "STEP 2) 매 특정시간마다 python test.py 명령 실행\n",
    "\n",
    "STEP 3) python test.py 실행에 따른 s3 sync\n",
    "\n",
    "\n",
    "#### [구현 과정]\n",
    "\n",
    "STEP 1) python script(test.py) 작성 및 Crontab 등록\n",
    "\n",
    "step 1-1) python3.7 및 boto3 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo yum update -y\n",
    "sudo yum install python37 python37-pip -y\n",
    "sudo pip3 install boto3\n",
    "\n",
    "# 파이썬 기본버전 변경 = ASIS : 2.7 -> TOBE : 3.7\n",
    "sudo alternatives --install /usr/bin/python python /usr/bin/python2.7 1\n",
    "sudo alternatives --install /usr/bin/python python /usr/bin/python3.7 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 1-2) `aws configure` 명령어로 액세스 키 등록\n",
    "\n",
    "step 1-3) test.py 작성 및 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from datetime import datetime\n",
    "import time\n",
    "import boto3\n",
    "import math\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')+'\\n'\n",
    "start_timestamp = timestamp[0:4]+'_'+timestamp[5:7]+'_'+timestamp[8:10]+'_'+timestamp[11:13]+'_'+timestamp[14:16]+'_'+timestamp[17:19]\n",
    "\n",
    "source_bucket = \"[source_bucket]\"\n",
    "source_prefix = \"[prefix]\"\n",
    "source_s3_location = source_bucket+'/'+source_prefix\n",
    "\n",
    "destination_bucket = '[destination_bucket]'\n",
    "destination_prefix = '[prefix2]'\n",
    "destination_s3_location = destination_bucket +'/'+ destination_prefix\n",
    "task_name = \"[task_name]\"\n",
    "\n",
    "sync_command = f\"aws s3 sync s3://{source_s3_location}/ s3://{destination_s3_location}/ --delete --acl bucket-owner-full-control\"\n",
    "\n",
    "file_name = start_timestamp+\" \"+task_name\n",
    "\n",
    "logfile = open(\"{}.txt\".format(file_name), 'wb')\n",
    "start_time = \"start time : {}\".format(timestamp).encode()\n",
    "logfile.write(start_time)\n",
    "\n",
    "try :\n",
    "    log_record = subprocess.check_output(sync_command, stderr=subprocess.STDOUT, shell=True)\n",
    "    print(\"job success\")\n",
    "    logfile.write(log_record)\n",
    "    runtime = \"Runtime: {} sec \\n\".format(time.time()-start).encode()\n",
    "    logfile.write(runtime)\n",
    "    print(runtime)\n",
    "\n",
    "    # check data integrity\n",
    "    client = boto3.client('s3')\n",
    "    paginator = client.get_paginator('list_objects_v2')\n",
    "\n",
    "    operation_parameters = {'Bucket': '{}'.format(source_bucket),'Prefix': '{}/'.format(source_prefix)}\n",
    "    response_iterator = paginator.paginate(**operation_parameters)\n",
    "    source_object_list = []\n",
    "    source_folder_list = []\n",
    "\n",
    "    for page in response_iterator:\n",
    "        for content in page['Contents']:\n",
    "            if (content['Key']+','+str(content['Size']))[-3:] == '/,0':\n",
    "                source_folder_list.append(content['Key']+','+str(content['Size']))\n",
    "            else :\n",
    "                source_object_list.append(content['Key'].split('/').pop()+','+str(content['Size']))\n",
    "\n",
    "\n",
    "    operation_parameters = {'Bucket': '{}'.format(destination_bucket),'Prefix': '{}/'.format(destination_prefix)}\n",
    "    response_iterator = paginator.paginate(**operation_parameters)\n",
    "    destination_object_list = []\n",
    "    destination_folder_list = []\n",
    "\n",
    "    for page in response_iterator:\n",
    "        for content in page['Contents']:\n",
    "            if (content['Key']+','+str(content['Size']))[-3:] == '/,0':\n",
    "                destination_folder_list.append(content['Key']+','+str(content['Size']))\n",
    "            else :\n",
    "                destination_object_list.append(content['Key'].split('/').pop()+','+str(content['Size']))\n",
    "\n",
    "    if source_object_list == destination_object_list :\n",
    "\n",
    "        logfile.write(\"data integrity check success \\n\".encode())\n",
    "        logfile.write(\"{} to {} complete \\n\".format(source_s3_location,destination_s3_location).encode())\n",
    "\n",
    "        source_folder_list_str = \"source_folder_list:\" + str(source_folder_list)+'\\n'\n",
    "        logfile.write(source_folder_list_str.encode())\n",
    "        source_object_list_str = \"source_object_list:\" + str(source_object_list)+'\\n'\n",
    "        logfile.write(source_object_list_str.encode())\n",
    "\n",
    "        destination_folder_list_str = \"destination_folder_list:\"+str(destination_folder_list)+'\\n'\n",
    "        logfile.write(destination_folder_list_str.encode())\n",
    "        destination_object_list_str = \"destination_object_list:\"+str(destination_object_list)+'\\n'\n",
    "        logfile.write(destination_object_list_str.encode())\n",
    "\n",
    "        source_object_list_str = \"number of source_object_list:\" + str(len(source_object_list))+'\\n'\n",
    "        logfile.write(source_object_list_str.encode())\n",
    "        destination_object_list_str = \"number of destination_object_list:\" + str(len(destination_object_list))+'\\n'\n",
    "        logfile.write(destination_object_list_str.encode())\n",
    "\n",
    "        print(\"data integrity check success \\n\")\n",
    "    else:\n",
    "        logfile.write(\"data integrity check fail \\n\".encode())\n",
    "\n",
    "        source_folder_list_str = \"source_folder_list:\" + str(source_folder_list)+'\\n'\n",
    "        logfile.write(source_folder_list_str.encode())\n",
    "        source_object_list_str = \"source_object_list:\" + str(source_object_list)+'\\n'\n",
    "        logfile.write(source_object_list_str.encode())\n",
    "\n",
    "        destination_folder_list_str = \"destination_folder_list:\"+str(destination_folder_list)+'\\n'\n",
    "        logfile.write(destination_folder_list_str.encode())\n",
    "        destination_object_list_str = \"destination_object_list:\"+str(destination_object_list)+'\\n'\n",
    "        logfile.write(destination_object_list_str.encode())\n",
    "\n",
    "        source_object_list_str = \"number of source_object_list:\" + str(len(source_object_list))+'\\n'\n",
    "        logfile.write(source_object_list_str.encode())\n",
    "        destination_object_list_str = \"number of destination_object_list:\" + str(len(destination_object_list))+'\\n'\n",
    "        logfile.write(destination_object_list_str.encode())\n",
    "\n",
    "        print(\"data integrity check fail\")\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"job fail\")\n",
    "    logfile.write(e.output)\n",
    "    runtime = \"Runtime: {} sec\".format(time.time()-start).encode()\n",
    "    logfile.write(runtime)\n",
    "    print(runtime)\n",
    "\n",
    "logfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 1-4) 크론탭 로그 저장을 위한 폴더 및 log 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir /home/ec2-user/log\n",
    "touch /home/ec2-user/log/test.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 1-5) 크론탭 등록\n",
    "\n",
    "- `crontab -e` 명령어 실행 후 아래와 같은 스크립트를 작성하고 저장한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* * * * * python /home/ec2-user/test.py > /home/ec2-user/log/test.log 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wq!로 저장하고 나오면 `crontab: installing new crontab` 메세지를 확인할 수 있다.\n",
    "\n",
    "그리고 1분이 지나면 아래와 같이 `STEP 2)` 및 `STEP 3)` 이 실행완료된 것을 확인할 수 있다.\n",
    "\n",
    "(pms-bucket-test에서 pms-bucket-test2로 s3 sync 완료, pms-bucket-test2의 destination 경로로 가보면 객체들이 sync 되어 있는 것도 확인할 수 있다.)\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/41605276/82746082-e4724180-9dc6-11ea-89a8-95a80f2e362f.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
